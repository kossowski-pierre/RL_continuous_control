{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "This notebook is based on the code of the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "We will use the same Unity ML-Agents environment.<br>\n",
    "In this notebook, we will train 20 parallels agents with DDPG\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Windows_x86_64_one/Reacher_Windows_x86_64/Reacher.exe')\n",
    "\n",
    "#env = UnityEnvironment(file_name='Reacher_Windows_x86_64/Reacher_Windows_x86_64/Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReacherBrain'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "\n",
    "Now, we will train our own PPO agent to solve the environment.<br>  When training the environment, we set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Actor_PPO, Critic_PPO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-bipedal/model.py\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1.0 / np.sqrt(fan_in)\n",
    "    return (-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 512        # minibatch size\n",
    "GAMMA = 0.98            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "LR_CRITIC = 1e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0001   # L2 weight decay\n",
    "NUM_EPOCHS = 20\n",
    "SEED=47\n",
    "LAMBDA=0.5\n",
    "\n",
    "class Agent():\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed, epsilon=0.3, entropy_coef=0.001):\n",
    "        \n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.num_epochs = NUM_EPOCHS\n",
    "        self.seed = random.seed(random_seed)\n",
    "        self.epsilon = epsilon\n",
    "        self.entropy_coef = entropy_coef\n",
    "        \n",
    "        self.actor_local = Actor_PPO(state_size=state_size, action_size=action_size, size1=256, seed=SEED).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR, weight_decay=WEIGHT_DECAY)\n",
    "            \n",
    "        self.critic_local = Critic_PPO(state_size=state_size,size1=256,seed=SEED).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "            \n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "        \n",
    "        self.memory = Memory()\n",
    "        self.train=True\n",
    "        self.actor_loss_history=deque(maxlen=1000)\n",
    "        self.critic_loss_history=deque(maxlen=1000)\n",
    "            \n",
    "    def step(self, states, actions, rewards, next_states, dones, distributions, log_probs):\n",
    "        states = torch.tensor(states, dtype=torch.float, device=device)\n",
    "        \n",
    "        if self.train:\n",
    "            self.actor_local.eval()\n",
    "            with torch.no_grad():\n",
    "                values = self.critic_local(states)\n",
    "                self.memory.add_steps(states, actions, rewards, dones, values, log_probs)# next_states, \n",
    "            self.actor_local.train()\n",
    "        \n",
    "    \n",
    "    def act(self, states, add_noise=False):\n",
    "        states =torch.tensor(states).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            actions, distributions = self.actor_local(states)\n",
    "            actions = actions.cpu().numpy()\n",
    "        \n",
    "            if add_noise:\n",
    "                actions += self.noise.sample()\n",
    "            log_probs = distributions.log_prob(torch.FloatTensor(actions).to(device))\n",
    "            log_probs = torch.sum(log_probs, axis=-1, keepdim=True)\n",
    "        self.actor_local.train()\n",
    "        return np.clip(actions, -1, 1), distributions, log_probs\n",
    "        \n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "        \n",
    "    def learn(self,last_states, gamma):\n",
    "        \"\"\"Update policy and value parameters using given sequences of experience.\n",
    "        where:\n",
    "            self.actor (state) -> action, distribution\n",
    "            self.critic (state) -> State_Value\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            last_states (numpy.array): last \"next_states\" of the sequence  \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        last_values = self.critic_local(torch.FloatTensor(last_states).to(device)).cpu().detach().numpy()\n",
    "        \n",
    "        \n",
    "        returns = self.get_gae(self.memory.rewards, self.memory.values+[last_values], self.memory.dones)\n",
    "        self.returns = returns\n",
    "        actor_losses, critic_losses = [], []\n",
    "        \n",
    "        states = torch.FloatTensor(self.memory.states).to(device)\n",
    "        actions = torch.FloatTensor(self.memory.actions).to(device)\n",
    "        log_probs = torch.FloatTensor(np.array(self.memory.log_probs)).to(device)\n",
    "        values = torch.FloatTensor(self.memory.values).to(device).view(-1,1)\n",
    "        returns = torch.FloatTensor(returns).to(device).view(-1,1)#.squeeze()\n",
    "        assert  returns.shape == values.shape\n",
    "        advantages = returns - values#[:-1]\n",
    "        self.advantages = advantages\n",
    "        \n",
    "        for state, action, return_, old_log_prob, old_value, advantage in trajectories_data_generator(\n",
    "            states=states,\n",
    "            actions=actions,\n",
    "            returns=returns,\n",
    "            log_probs=log_probs,\n",
    "            values=values,\n",
    "            advantages=advantages,\n",
    "            batch_size=self.batch_size,\n",
    "            num_epochs=self.num_epochs,\n",
    "            ):\n",
    "            \n",
    "            \n",
    "            _, new_dist = self.actor_local(state)\n",
    "            cur_log_prob = new_dist.log_prob(action)\n",
    "            cur_log_prob=torch.sum(cur_log_prob, dim=-1, keepdim=False)\n",
    "            ratio = torch.exp(cur_log_prob - old_log_prob.detach())\n",
    "\n",
    "            \n",
    "            assert advantage.shape == old_value.shape\n",
    "            # compute actor loss\n",
    "            entropy = new_dist.entropy().mean(axis=-1, keepdim=False)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            loss =  advantage.detach() * ratio\n",
    "            clipped_loss = (\n",
    "                torch.clamp(ratio, 1. - self.epsilon, 1. + self.epsilon)\n",
    "                 * advantage.detach()\n",
    "                )\n",
    "            actor_loss = (\n",
    "                -torch.min(loss, clipped_loss)\n",
    "                - entropy * self.entropy_coef)\n",
    "            \n",
    "            actor_loss = actor_loss.mean()\n",
    "            \n",
    "            \n",
    "            #compute critic loss\n",
    "            cur_value = self.critic_local(state.view(-1,self.state_size))\n",
    "            critic_loss = F.mse_loss(return_, cur_value)\n",
    "        \n",
    "        \n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 5)\n",
    "            self.critic_optimizer.step()\n",
    "            \n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.actor_local.parameters(), 5)\n",
    "            self.actor_optimizer.step()\n",
    "            actor_losses.append(actor_loss.cpu().detach().numpy())\n",
    "            critic_losses.append(critic_loss.cpu().detach().numpy())\n",
    "            \n",
    "        \n",
    "        self.actor_loss_history.append(np.mean(actor_losses))\n",
    "        self.critic_loss_history.append(np.mean(critic_losses))\n",
    "        \n",
    "\n",
    "        \n",
    "    def get_gae(self, rewards, values, dones):\n",
    "        \"\"\"Computes a list of estimators of the advantage function at each timestep of the episode\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "             rewards: list of rewards\n",
    "             values: list of value function values\n",
    "             dones: list of terminal state flags\n",
    "             \n",
    "        Return\n",
    "        ======\n",
    "            discounted sum of rewards\n",
    "        \"\"\"\n",
    "        gae=0\n",
    "        returns=[]\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            delta = rewards[i]+GAMMA*values[i+1]*(1-dones[i])-values[i]\n",
    "            gae = delta+GAMMA*LAMBDA*(1-dones[i])*gae\n",
    "            returns.insert(0, gae+values[i])\n",
    "        return returns\n",
    "               \n",
    "        \n",
    "        \n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process\"\"\"\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.05):\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "    def sample(self):\n",
    "        x=self.state\n",
    "        dx = self.theta*(self.mu - x)+self.sigma* np.random.normal(loc=0, scale=1, size=len(x))#np.random.normal(loc=0, scale=1, size=len(x)))#np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x+dx\n",
    "        return self.state\n",
    "            \n",
    "\n",
    "class Memory:\n",
    "    \"\"\"Storing the memory of the trajectory (s, a, r ...).\"\"\"\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.log_probs = []\n",
    "        self.values = []\n",
    "    def add_steps(self, states, actions, rewards, dones, values, log_probs):\n",
    "        \n",
    "        self.states.append(states.cpu().detach().numpy())\n",
    "        self.actions.append(actions)\n",
    "        self.rewards.append(np.array(rewards)[:,np.newaxis])\n",
    "        self.dones.append(np.array(dones)[:,np.newaxis])\n",
    "        self.log_probs.append(np.array(log_probs.sum(axis=-1).cpu().detach()))\n",
    "        \n",
    "        self.values.append(values.cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.log_probs = []\n",
    "        self.values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sources : https://github.com/mandrakedrink/PPO-pytorch/blob/master/ppo/utils.py\n",
    "def trajectories_data_generator(\n",
    "    states: torch.Tensor,\n",
    "    actions: torch.Tensor,\n",
    "    returns: torch.Tensor,\n",
    "    log_probs: torch.Tensor,\n",
    "    values: torch.Tensor,\n",
    "    advantages: torch.Tensor,\n",
    "    batch_size,\n",
    "    num_epochs,\n",
    "    ):\n",
    "    \"\"\"data-generator.\"\"\"\n",
    "    data_len = states.size(0)\n",
    "    for _ in range(num_epochs):\n",
    "        for _ in range(data_len // batch_size):\n",
    "            ids = np.random.choice(data_len, batch_size, replace=False)\n",
    "            yield states[ids], actions[ids], returns[ids], log_probs[ids], values[ids], advantages[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 0.71\tScore: 0.71\tLossActor: -0.00686376 \tLossCritic : 0.00007253(tensor([[ 0.2936,  0.0897, -0.3881,  0.0096]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.9932, 0.9010, 1.1222, 0.6513]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 2\tAverage Score: 0.35\tScore: 0.00\tLossActor: -0.00586851 \tLossCritic : 0.00003758(tensor([[-0.1073, -0.1398, -0.1207, -0.1706]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.9803, 0.9973, 0.9491, 0.9685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 3\tAverage Score: 0.33\tScore: 0.28\tLossActor: -0.00563367 \tLossCritic : 0.00003559(tensor([[ 0.0949,  0.1733,  0.0082, -0.1512]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.9720, 0.8996, 0.7761, 0.6295]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 4\tAverage Score: 0.25\tScore: 0.00\tLossActor: -0.00526972 \tLossCritic : 0.00002742(tensor([[-0.0078,  0.0530,  0.1074, -0.0363]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.6633, 0.7004, 0.6135, 0.6014]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 5\tAverage Score: 0.33\tScore: 0.65\tLossActor: -0.00532820 \tLossCritic : 0.00003666(tensor([[ 0.2037, -0.0896,  0.1701,  0.0336]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.6329, 0.6720, 0.6119, 0.5968]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 6\tAverage Score: 0.31\tScore: 0.22\tLossActor: -0.00507758 \tLossCritic : 0.00003454(tensor([[-0.0156,  0.0526,  0.1878,  0.0406]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.5883, 0.5924, 0.5936, 0.6737]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 7\tAverage Score: 0.38\tScore: 0.80\tLossActor: -0.00506969 \tLossCritic : 0.00004065(tensor([[ 0.0505,  0.0256, -0.0939, -0.0614]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4810, 0.5360, 0.4791, 0.4746]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 8\tAverage Score: 0.47\tScore: 1.08\tLossActor: -0.00496053 \tLossCritic : 0.00004869(tensor([[ 0.2736,  0.1438,  0.1170, -0.1280]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.5492, 0.7118, 0.6117, 0.5115]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 9\tAverage Score: 0.54\tScore: 1.11\tLossActor: -0.00496138 \tLossCritic : 0.00005510(tensor([[ 0.1387,  0.0135,  0.2724, -0.0840]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4484, 0.5328, 0.4490, 0.4735]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 10\tAverage Score: 0.59\tScore: 1.09\tLossActor: -0.00490223 \tLossCritic : 0.00006152(tensor([[-0.2427,  0.0102,  0.0781,  0.0096]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4731, 0.4845, 0.4609, 0.4947]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 11\tAverage Score: 0.57\tScore: 0.36\tLossActor: -0.00463138 \tLossCritic : 0.00006022(tensor([[ 0.2075, -0.0316,  0.1440,  0.0619]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4043, 0.4368, 0.4070, 0.3973]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 12\tAverage Score: 0.57\tScore: 0.60\tLossActor: -0.00446913 \tLossCritic : 0.00006096(tensor([[ 0.0895,  0.2080, -0.0995,  0.2925]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4267, 0.4495, 0.4599, 0.3982]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 13\tAverage Score: 0.64\tScore: 1.37\tLossActor: -0.00442906 \tLossCritic : 0.00006696(tensor([[ 0.3503, -0.0570,  0.4760, -0.0787]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3841, 0.3960, 0.3925, 0.3848]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 14\tAverage Score: 0.61\tScore: 0.29\tLossActor: -0.00412975 \tLossCritic : 0.00006689(tensor([[ 0.1818,  0.1694,  0.1047, -0.1411]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3962, 0.4228, 0.4115, 0.3969]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 15\tAverage Score: 0.69\tScore: 1.81\tLossActor: -0.00418128 \tLossCritic : 0.00007364(tensor([[ 0.3012, -0.0498,  0.2466, -0.3445]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3769, 0.3822, 0.3814, 0.3810]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 16\tAverage Score: 0.70\tScore: 0.78\tLossActor: -0.00408791 \tLossCritic : 0.00007447(tensor([[0.1217, 0.1076, 0.0855, 0.0803]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4252, 0.4139, 0.4467, 0.4226]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 17\tAverage Score: 0.67\tScore: 0.18\tLossActor: -0.00392227 \tLossCritic : 0.00007236(tensor([[ 0.0426,  0.1995, -0.2179, -0.4437]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4386, 0.4328, 0.4226, 0.4186]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 18\tAverage Score: 0.68\tScore: 0.95\tLossActor: -0.00386914 \tLossCritic : 0.00007371(tensor([[ 0.0284,  0.1470,  0.4170, -0.4580]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3899, 0.3989, 0.4050, 0.3994]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 19\tAverage Score: 0.69\tScore: 0.78\tLossActor: -0.00379682 \tLossCritic : 0.00007404(tensor([[-0.0581,  0.2857,  0.2600, -0.3623]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3919, 0.3974, 0.3874, 0.4043]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 20\tAverage Score: 0.72\tScore: 1.31\tLossActor: -0.00378070 \tLossCritic : 0.00007763(tensor([[-0.0623,  0.4214,  0.2265, -0.0685]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3845, 0.4074, 0.3877, 0.3866]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 21\tAverage Score: 0.72\tScore: 0.69\tLossActor: -0.00370870 \tLossCritic : 0.00007809(tensor([[0.1785, 0.2891, 0.5724, 0.0451]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3747, 0.3806, 0.3759, 0.3811]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 22\tAverage Score: 0.69\tScore: 0.12\tLossActor: -0.00349681 \tLossCritic : 0.00007565(tensor([[-0.2846,  0.2512, -0.3934,  0.2623]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3763, 0.3787, 0.3780, 0.3761]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 23\tAverage Score: 0.71\tScore: 1.22\tLossActor: -0.00346682 \tLossCritic : 0.00007777(tensor([[ 0.1635,  0.4607,  0.1365, -0.0663]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3841, 0.4025, 0.3820, 0.3815]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 24\tAverage Score: 0.74\tScore: 1.25\tLossActor: -0.00343370 \tLossCritic : 0.00007993(tensor([[0.4457, 0.4085, 0.2386, 0.1520]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3735, 0.3777, 0.3726, 0.3728]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 25\tAverage Score: 0.73\tScore: 0.62\tLossActor: -0.00332026 \tLossCritic : 0.00007924(tensor([[-0.2221,  0.1172,  0.3701,  0.1619]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3953, 0.4056, 0.3949, 0.3992]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 26\tAverage Score: 0.72\tScore: 0.40\tLossActor: 0.00032528 \tLossCritic : 0.00007837(tensor([[-0.8191,  0.9628, -0.7166,  0.9673]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3682, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 27\tAverage Score: 0.69\tScore: 0.00\tLossActor: 0.00057278 \tLossCritic : 0.00007694(tensor([[-0.9867,  0.5481, -0.2712,  0.9372]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3680, 0.3680, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 28\tAverage Score: 0.70\tScore: 1.05\tLossActor: 0.00061897 \tLossCritic : 0.00007919(tensor([[-0.6504,  0.6403, -0.4755,  0.7201]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4036, 0.3857, 0.3828, 0.3794]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 29\tAverage Score: 0.68\tScore: 0.00\tLossActor: 0.00156766 \tLossCritic : 0.00007720(tensor([[-0.5719,  0.4632, -0.3179,  0.0298]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3759, 0.3718, 0.3704, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 30\tAverage Score: 0.69\tScore: 0.89\tLossActor: 0.00161546 \tLossCritic : 0.00007790(tensor([[-0.1349,  0.4272, -0.3867,  0.3205]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3975, 0.3945, 0.3842, 0.3779]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 31\tAverage Score: 0.67\tScore: 0.19\tLossActor: 0.00156031 \tLossCritic : 0.00007624(tensor([[-0.2817, -0.2646, -0.3189, -0.2095]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4833, 0.4036, 0.4039, 0.3888]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 32\tAverage Score: 0.67\tScore: 0.80\tLossActor: 0.00146664 \tLossCritic : 0.00007684(tensor([[-0.2628,  0.4835, -0.3288,  0.6671]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3904, 0.3773, 0.3755, 0.3721]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 33\tAverage Score: 0.66\tScore: 0.28\tLossActor: 0.00147947 \tLossCritic : 0.00007593(tensor([[-0.6274, -0.9825, -0.9076,  0.8191]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3961, 0.3680, 0.3692, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 34\tAverage Score: 0.67\tScore: 0.80\tLossActor: 0.00148100 \tLossCritic : 0.00007635(tensor([[ 0.3397,  0.5145, -0.5362,  0.5862]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4105, 0.3733, 0.3798, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 35\tAverage Score: 0.66\tScore: 0.55\tLossActor: 0.00141437 \tLossCritic : 0.00007561(tensor([[-0.2020, -0.2696, -0.3525, -0.4896]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.5363, 0.4097, 0.4349, 0.4012]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 36\tAverage Score: 0.65\tScore: 0.00\tLossActor: 0.00139956 \tLossCritic : 0.00007417(tensor([[ 0.2392, -0.1388, -0.1760, -0.2116]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.5467, 0.4563, 0.4950, 0.4298]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 37\tAverage Score: 0.64\tScore: 0.61\tLossActor: 0.00132828 \tLossCritic : 0.00007398(tensor([[-0.2709, -0.7425, -0.2551, -0.3301]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.5518, 0.4185, 0.4621, 0.3897]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 38\tAverage Score: 0.65\tScore: 0.74\tLossActor: 0.00126370 \tLossCritic : 0.00007430(tensor([[0.4530, 0.2016, 0.3824, 0.7401]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4008, 0.3751, 0.3773, 0.3735]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 39\tAverage Score: 0.65\tScore: 0.77\tLossActor: 0.00120020 \tLossCritic : 0.00007428(tensor([[ 0.2287, -0.2079, -0.4140, -0.4503]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3811, 0.3774, 0.3775, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 40\tAverage Score: 0.65\tScore: 0.53\tLossActor: 0.00114605 \tLossCritic : 0.00007360(tensor([[0.5147, 0.2802, 0.1143, 0.5447]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3853, 0.3741, 0.3790, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 41\tAverage Score: 0.66\tScore: 1.00\tLossActor: 0.00106950 \tLossCritic : 0.00007397(tensor([[ 1.5907e-01, -5.9541e-02,  2.4134e-01,  9.2931e-05]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4189, 0.4096, 0.4303, 0.3907]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 42\tAverage Score: 0.66\tScore: 0.93\tLossActor: 0.00102493 \tLossCritic : 0.00007446(tensor([[ 0.2802,  0.2680, -0.5492,  0.0266]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4316, 0.3940, 0.3889, 0.3791]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 43\tAverage Score: 0.68\tScore: 1.24\tLossActor: 0.00096454 \tLossCritic : 0.00007530(tensor([[-0.0996,  0.3257,  0.1251,  0.3850]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4205, 0.3855, 0.3862, 0.3898]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 44\tAverage Score: 0.70\tScore: 1.62\tLossActor: 0.00087182 \tLossCritic : 0.00007728(tensor([[-0.1081,  0.2684, -0.1254, -0.0456]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4422, 0.4321, 0.4302, 0.4170]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 45\tAverage Score: 0.69\tScore: 0.27\tLossActor: 0.00090035 \tLossCritic : 0.00007653(tensor([[-0.0729, -0.3758,  0.0420, -0.2503]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4151, 0.3750, 0.3803, 0.3818]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 46\tAverage Score: 0.68\tScore: 0.28\tLossActor: 0.00087678 \tLossCritic : 0.00007567(tensor([[-0.1291,  0.4321,  0.4017,  0.2237]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3743, 0.3707, 0.3720, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 47\tAverage Score: 0.70\tScore: 1.89\tLossActor: 0.00077260 \tLossCritic : 0.00007793(tensor([[-0.2271,  0.3748,  0.0173,  0.1815]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3967, 0.3883, 0.3957, 0.3995]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 48\tAverage Score: 0.70\tScore: 0.67\tLossActor: 0.00075249 \tLossCritic : 0.00007810(tensor([[-0.0359,  0.4228, -0.2942,  0.3971]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3773, 0.3728, 0.3732, 0.3711]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 49\tAverage Score: 0.73\tScore: 1.83\tLossActor: 0.00067052 \tLossCritic : 0.00008037(tensor([[ 0.1654, -0.1258,  0.0624,  0.2010]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4014, 0.3821, 0.3863, 0.3754]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 50\tAverage Score: 0.74\tScore: 1.46\tLossActor: 0.00060963 \tLossCritic : 0.00008228(tensor([[-0.3003, -0.4272, -0.1996, -0.0837]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.4292, 0.3923, 0.3988, 0.3926]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 51\tAverage Score: 0.78\tScore: 2.59\tLossActor: 0.00051203 \tLossCritic : 0.00008547(tensor([[-0.5083,  0.0935, -0.4047,  0.0005]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3741, 0.3718, 0.3722, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 52\tAverage Score: 0.78\tScore: 0.99\tLossActor: 0.00047957 \tLossCritic : 0.00008567(tensor([[-0.4988, -0.0234, -0.3534, -0.0696]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3748, 0.3721, 0.3702, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 53\tAverage Score: 0.78\tScore: 0.81\tLossActor: 0.00047077 \tLossCritic : 0.00008583(tensor([[ 0.0296,  0.2548,  0.4546, -0.1697]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3744, 0.3795, 0.3759, 0.3773]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 54\tAverage Score: 0.78\tScore: 0.85\tLossActor: 0.00046296 \tLossCritic : 0.00008609(tensor([[ 0.2133,  0.3240,  0.2224, -0.0391]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3876, 0.3934, 0.3883, 0.3812]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 55\tAverage Score: 0.79\tScore: 1.37\tLossActor: 0.00047130 \tLossCritic : 0.00008719(tensor([[-0.3219,  0.1941,  0.3009,  0.4783]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3736, 0.3697, 0.3689, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 56\tAverage Score: 0.81\tScore: 1.60\tLossActor: 0.00043830 \tLossCritic : 0.00008846(tensor([[0.0568, 0.1744, 0.3781, 0.1822]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3717, 0.3698, 0.3696, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 57\tAverage Score: 0.80\tScore: 0.50\tLossActor: 0.00043382 \tLossCritic : 0.00008800(tensor([[0.4888, 0.0682, 0.1587, 0.4364]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3681, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 58\tAverage Score: 0.80\tScore: 0.90\tLossActor: 0.00041521 \tLossCritic : 0.00008802(tensor([[-0.2501,  0.1871,  0.2288,  0.0287]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3742, 0.3759, 0.3759, 0.3743]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 59\tAverage Score: 0.84\tScore: 3.08\tLossActor: 0.00032926 \tLossCritic : 0.00009060(tensor([[-0.2329,  0.1614,  0.0179, -0.2791]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3997, 0.3785, 0.3807, 0.3775]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 60\tAverage Score: 0.87\tScore: 2.24\tLossActor: 0.00026883 \tLossCritic : 0.00009250(tensor([[ 0.1140, -0.0541,  0.0891, -0.0725]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3876, 0.3787, 0.3740, 0.3738]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 61\tAverage Score: 0.89\tScore: 2.32\tLossActor: 0.00021717 \tLossCritic : 0.00009418(tensor([[ 0.1483,  0.2245,  0.3162, -0.3963]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3721, 0.3723, 0.3723, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 62\tAverage Score: 0.92\tScore: 2.51\tLossActor: 0.00016973 \tLossCritic : 0.00009591(tensor([[-0.5482,  0.2808, -0.0787, -0.1093]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3866, 0.3781, 0.3796, 0.3807]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 63\tAverage Score: 0.91\tScore: 0.64\tLossActor: 0.00018398 \tLossCritic : 0.00009592(tensor([[-0.5006,  0.2761,  0.0100,  0.0182]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3862, 0.3860, 0.3853, 0.3865]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 64\tAverage Score: 0.93\tScore: 2.20\tLossActor: 0.00014932 \tLossCritic : 0.00009771(tensor([[ 0.1227, -0.0197,  0.2960, -0.4247]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3715, 0.3732, 0.3718, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 65\tAverage Score: 0.96\tScore: 2.64\tLossActor: 0.00009839 \tLossCritic : 0.00010021(tensor([[-0.0765,  0.4167,  0.1217,  0.0845]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3742, 0.3741, 0.3742, 0.3708]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 66\tAverage Score: 0.98\tScore: 2.51\tLossActor: 0.00005683 \tLossCritic : 0.00010238(tensor([[-0.3560, -0.2049,  0.0057, -0.2898]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3899, 0.3842, 0.3795, 0.3787]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 67\tAverage Score: 0.98\tScore: 0.73\tLossActor: 0.00008076 \tLossCritic : 0.00010245(tensor([[-0.2870, -0.0201, -0.0666, -0.4766]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3690, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 68\tAverage Score: 0.97\tScore: 0.57\tLossActor: 0.00009391 \tLossCritic : 0.00010215(tensor([[ 0.5255,  0.1637,  0.5086, -0.1787]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3714, 0.3703, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 69\tAverage Score: 0.99\tScore: 2.24\tLossActor: 0.00005360 \tLossCritic : 0.00010356(tensor([[ 0.0589,  0.3556, -0.0126,  0.3602]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3751, 0.3730, 0.3733, 0.3716]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 70\tAverage Score: 0.99\tScore: 0.89\tLossActor: 0.00006004 \tLossCritic : 0.00010351(tensor([[-0.1990,  0.1133,  0.4776,  0.3453]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3776, 0.3728, 0.3741, 0.3744]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 71\tAverage Score: 1.00\tScore: 1.92\tLossActor: 0.00004537 \tLossCritic : 0.00010477(tensor([[ 0.3564, -0.4481,  0.3307, -0.0466]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3684, 0.3691, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 72\tAverage Score: 1.01\tScore: 1.85\tLossActor: 0.00002732 \tLossCritic : 0.00010547(tensor([[ 0.1544, -0.2035, -0.1419, -0.2939]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3785, 0.3735, 0.3731, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 73\tAverage Score: 1.00\tScore: 0.11\tLossActor: 0.00007100 \tLossCritic : 0.00010452(tensor([[-0.3640,  0.2663,  0.3533,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3709, 0.3710, 0.3713, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 74\tAverage Score: 1.01\tScore: 1.67\tLossActor: 0.00006098 \tLossCritic : 0.00010521(tensor([[-0.2891,  0.2359, -0.1228, -0.0549]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3796, 0.3814, 0.3760, 0.3748]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 75\tAverage Score: 1.02\tScore: 1.64\tLossActor: 0.00004906 \tLossCritic : 0.00010588(tensor([[-0.3790,  0.0615, -0.1004, -0.2512]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3751, 0.3766, 0.3726, 0.3716]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 76\tAverage Score: 1.01\tScore: 0.21\tLossActor: 0.00006960 \tLossCritic : 0.00010499(tensor([[-0.5021,  0.0732,  0.3972, -0.0783]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3697, 0.3698, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 77\tAverage Score: 1.03\tScore: 3.03\tLossActor: 0.00000560 \tLossCritic : 0.00010730(tensor([[-0.2719, -0.0533,  0.3408,  0.0489]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3722, 0.3716, 0.3717, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 78\tAverage Score: 1.03\tScore: 0.90\tLossActor: 0.00000867 \tLossCritic : 0.00010744(tensor([[-0.5071,  0.2535, -0.1108,  0.3377]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3723, 0.3703, 0.3698, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 79\tAverage Score: 1.05\tScore: 2.07\tLossActor: -0.00001565 \tLossCritic : 0.00010835(tensor([[-0.2556, -0.2198, -0.0356, -0.2987]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3870, 0.3866, 0.3786, 0.3769]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 80\tAverage Score: 1.04\tScore: 0.73\tLossActor: 0.00002260 \tLossCritic : 0.00010824(tensor([[ 0.0846, -0.6756, -0.5439, -0.4597]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3712, 0.3729, 0.3705, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 81\tAverage Score: 1.04\tScore: 0.88\tLossActor: 0.00003504 \tLossCritic : 0.00010848(tensor([[ 0.2687, -0.4356, -0.3280, -0.6691]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3704, 0.3687, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 82\tAverage Score: 1.04\tScore: 1.13\tLossActor: 0.00003230 \tLossCritic : 0.00010877(tensor([[ 0.1060, -0.0139,  0.2929, -0.4342]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3735, 0.3700, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 83\tAverage Score: 1.05\tScore: 1.65\tLossActor: 0.00001628 \tLossCritic : 0.00010966(tensor([[-0.0022,  0.3163, -0.0236,  0.0354]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3713, 0.3740, 0.3713, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 84\tAverage Score: 1.06\tScore: 1.78\tLossActor: -0.00000453 \tLossCritic : 0.00011076(tensor([[-0.5355,  0.2408, -0.1216, -0.0718]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3713, 0.3742, 0.3700, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 85\tAverage Score: 1.08\tScore: 3.04\tLossActor: -0.00005107 \tLossCritic : 0.00011255(tensor([[0.1055, 0.2339, 0.0388, 0.1411]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3700, 0.3694, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 86\tAverage Score: 1.12\tScore: 4.38\tLossActor: -0.00012995 \tLossCritic : 0.00011534(tensor([[ 0.3754, -0.0653, -0.0460, -0.1147]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3687, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 87\tAverage Score: 1.13\tScore: 2.32\tLossActor: -0.00014273 \tLossCritic : 0.00011660(tensor([[-0.0340, -0.1814,  0.0479, -0.1776]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3751, 0.3780, 0.3722, 0.3718]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 88\tAverage Score: 1.14\tScore: 1.76\tLossActor: -0.00015152 \tLossCritic : 0.00011726(tensor([[ 0.0016,  0.4329, -0.1111,  0.0845]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3730, 0.3723, 0.3709, 0.3710]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 89\tAverage Score: 1.14\tScore: 0.79\tLossActor: -0.00013450 \tLossCritic : 0.00011767(tensor([[-0.1806, -0.3246, -0.0235,  0.0380]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3764, 0.3786, 0.3748, 0.3730]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 90\tAverage Score: 1.12\tScore: 0.00\tLossActor: -0.00006887 \tLossCritic : 0.00011782(tensor([[-0.3384,  0.2190, -0.5423, -0.0067]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 91\tAverage Score: 1.16\tScore: 4.01\tLossActor: -0.00012721 \tLossCritic : 0.00012048(tensor([[-0.2011,  0.4095, -0.2595, -0.1025]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3729, 0.3710, 0.3706, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 92\tAverage Score: 1.16\tScore: 1.58\tLossActor: -0.00013728 \tLossCritic : 0.00012134(tensor([[-0.4646,  0.4666, -0.4981, -0.3333]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3691, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 93\tAverage Score: 1.17\tScore: 2.20\tLossActor: -0.00015183 \tLossCritic : 0.00012218(tensor([[-0.0876,  0.1309, -0.2389, -0.2888]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3766, 0.3725, 0.3729, 0.3728]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 94\tAverage Score: 1.17\tScore: 1.37\tLossActor: -0.00012709 \tLossCritic : 0.00012226(tensor([[ 0.4113, -0.2905,  0.1230, -0.4902]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3706, 0.3697, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 95\tAverage Score: 1.20\tScore: 3.98\tLossActor: -0.00018203 \tLossCritic : 0.00012437(tensor([[-0.3429,  0.1420, -0.2591,  0.0811]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3788, 0.3766, 0.3728, 0.3729]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 96\tAverage Score: 1.22\tScore: 2.98\tLossActor: -0.00020659 \tLossCritic : 0.00012576(tensor([[-0.3938,  0.0500,  0.0191, -0.1854]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3798, 0.3775, 0.3773, 0.3765]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 97\tAverage Score: 1.25\tScore: 4.29\tLossActor: -0.00026049 \tLossCritic : 0.00012883(tensor([[0.0770, 0.3578, 0.3311, 0.3611]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3692, 0.3692, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 98\tAverage Score: 1.30\tScore: 5.41\tLossActor: -0.00033502 \tLossCritic : 0.00013137(tensor([[-0.4005,  0.1361, -0.2960, -0.2396]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3720, 0.3716, 0.3700, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 99\tAverage Score: 1.30\tScore: 2.26\tLossActor: -0.00033922 \tLossCritic : 0.00013244(tensor([[ 0.0575,  0.1605, -0.3334, -0.2044]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3804, 0.3811, 0.3760, 0.3736]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 100\tAverage Score: 1.30\tScore: 0.88\tLossActor: -0.00031426 \tLossCritic : 0.00013227(tensor([[ 0.2940,  0.1698,  0.1615, -0.1154]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3712, 0.3702, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 100\tAverage Score: 1.30\n",
      "Episode 101\tAverage Score: 1.31\tScore: 1.67\tLossActor: -0.00031065 \tLossCritic : 0.00013285(tensor([[-0.1169,  0.4984, -0.2733,  0.3115]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3716, 0.3705, 0.3699, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 102\tAverage Score: 1.33\tScore: 2.43\tLossActor: -0.00031575 \tLossCritic : 0.00013395(tensor([[-0.1164,  0.3216, -0.1051, -0.1104]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3691, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 103\tAverage Score: 1.36\tScore: 2.80\tLossActor: -0.00033778 \tLossCritic : 0.00013485(tensor([[ 0.1537,  0.1552, -0.5902, -0.4245]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3682, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 104\tAverage Score: 1.39\tScore: 2.62\tLossActor: -0.00034896 \tLossCritic : 0.00013601(tensor([[ 0.0674,  0.3580, -0.6170, -0.4481]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3682, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 105\tAverage Score: 1.43\tScore: 5.35\tLossActor: -0.00039254 \tLossCritic : 0.00013892(tensor([[-0.3122, -0.0444, -0.1799,  0.0773]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3762, 0.3717, 0.3738, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 106\tAverage Score: 1.45\tScore: 1.49\tLossActor: -0.00038077 \tLossCritic : 0.00013889(tensor([[-0.4918,  0.1163, -0.4649,  0.1965]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3800, 0.3743, 0.3748, 0.3717]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 107\tAverage Score: 1.44\tScore: 0.00\tLossActor: -0.00033872 \tLossCritic : 0.00013823(tensor([[-0.2734, -0.0069,  0.6013, -0.2855]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 108\tAverage Score: 1.43\tScore: 0.62\tLossActor: -0.00031611 \tLossCritic : 0.00013797(tensor([[-0.0791, -0.3319, -0.3310, -0.0098]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3739, 0.3720, 0.3714, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 109\tAverage Score: 1.45\tScore: 3.04\tLossActor: -0.00033072 \tLossCritic : 0.00013887(tensor([[ 0.4955, -0.1999, -0.1000, -0.2892]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3695, 0.3691, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 110\tAverage Score: 1.47\tScore: 3.06\tLossActor: -0.00034329 \tLossCritic : 0.00013994(tensor([[-0.1548,  0.0773, -0.0191,  0.4561]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3685, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 111\tAverage Score: 1.49\tScore: 1.94\tLossActor: -0.00031945 \tLossCritic : 0.00014037(tensor([[-0.1468, -0.4310,  0.0875, -0.4390]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3725, 0.3715, 0.3708, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 112\tAverage Score: 1.50\tScore: 1.99\tLossActor: -0.00031614 \tLossCritic : 0.00014107(tensor([[ 0.1009, -0.2039,  0.1442,  0.1260]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3711, 0.3717, 0.3731, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 113\tAverage Score: 1.52\tScore: 3.06\tLossActor: -0.00032637 \tLossCritic : 0.00014228(tensor([[-0.2466, -0.0350, -0.4557,  0.5063]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3698, 0.3700, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 114\tAverage Score: 1.55\tScore: 2.93\tLossActor: -0.00034471 \tLossCritic : 0.00014363(tensor([[0.2438, 0.2382, 0.0334, 0.4503]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3688, 0.3688, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 115\tAverage Score: 1.54\tScore: 1.21\tLossActor: -0.00033277 \tLossCritic : 0.00014388(tensor([[-0.5387, -0.1658, -0.5167,  0.2949]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 116\tAverage Score: 1.58\tScore: 4.51\tLossActor: -0.00037429 \tLossCritic : 0.00014576(tensor([[-0.1116, -0.3437,  0.1006, -0.2487]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3720, 0.3718, 0.3711, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 117\tAverage Score: 1.59\tScore: 1.44\tLossActor: -0.00036185 \tLossCritic : 0.00014629(tensor([[-0.0868,  0.0850, -0.1107,  0.3993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3694, 0.3700, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 118\tAverage Score: 1.62\tScore: 4.00\tLossActor: -0.00038903 \tLossCritic : 0.00014756(tensor([[-0.0724, -0.1952,  0.3451, -0.6211]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3696, 0.3690, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 119\tAverage Score: 1.64\tScore: 2.71\tLossActor: -0.00038971 \tLossCritic : 0.00014856(tensor([[-0.3007, -0.1456, -0.2781, -0.1752]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3817, 0.3836, 0.3786, 0.3735]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 120\tAverage Score: 1.67\tScore: 4.19\tLossActor: -0.00042017 \tLossCritic : 0.00015036(tensor([[-0.2746,  0.3985,  0.1082,  0.5791]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 121\tAverage Score: 1.69\tScore: 2.71\tLossActor: -0.00040945 \tLossCritic : 0.00015162(tensor([[-0.3011, -0.2395, -0.4539, -0.0110]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3692, 0.3686, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 122\tAverage Score: 1.72\tScore: 3.17\tLossActor: -0.00042068 \tLossCritic : 0.00015263(tensor([[-0.1297, -0.2425,  0.1960, -0.0512]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3762, 0.3812, 0.3731, 0.3715]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 123\tAverage Score: 1.72\tScore: 1.57\tLossActor: -0.00039863 \tLossCritic : 0.00015288(tensor([[-0.1869, -0.0444,  0.2321, -0.0194]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 124\tAverage Score: 1.75\tScore: 3.82\tLossActor: -0.00041509 \tLossCritic : 0.00015454(tensor([[ 0.1718,  0.2143,  0.2301, -0.2043]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3690, 0.3682, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 125\tAverage Score: 1.78\tScore: 3.96\tLossActor: -0.00044196 \tLossCritic : 0.00015530(tensor([[0.0540, 0.4088, 0.0740, 0.2200]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3691, 0.3690, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 126\tAverage Score: 1.81\tScore: 3.10\tLossActor: -0.00044559 \tLossCritic : 0.00015625(tensor([[ 0.0650,  0.2634, -0.0517,  0.3818]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3693, 0.3691, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 127\tAverage Score: 1.85\tScore: 4.42\tLossActor: -0.00046439 \tLossCritic : 0.00015811(tensor([[ 0.4441,  0.0930, -0.0402,  0.0439]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3694, 0.3690, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 128\tAverage Score: 1.89\tScore: 4.41\tLossActor: -0.00049058 \tLossCritic : 0.00016039(tensor([[-0.0914, -0.2994, -0.4551, -0.0393]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3776, 0.3788, 0.3737, 0.3721]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 129\tAverage Score: 1.95\tScore: 6.10\tLossActor: -0.00053474 \tLossCritic : 0.00016269(tensor([[ 0.0024, -0.4181, -0.3719,  0.0369]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3741, 0.3732, 0.3714, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 130\tAverage Score: 1.97\tScore: 3.45\tLossActor: -0.00053225 \tLossCritic : 0.00016403(tensor([[-0.2134,  0.4494, -0.1190, -0.0332]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3727, 0.3705, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 131\tAverage Score: 2.00\tScore: 3.10\tLossActor: -0.00053236 \tLossCritic : 0.00016594(tensor([[ 0.3798, -0.1102,  0.3873, -0.1175]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3697, 0.3687, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 132\tAverage Score: 2.03\tScore: 3.88\tLossActor: -0.00054202 \tLossCritic : 0.00016780(tensor([[ 0.1653, -0.3309,  0.1151,  0.0858]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3750, 0.3766, 0.3728, 0.3715]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 133\tAverage Score: 2.08\tScore: 5.07\tLossActor: -0.00057428 \tLossCritic : 0.00017006(tensor([[ 0.3948, -0.0209, -0.0846,  0.0387]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3715, 0.3728, 0.3726, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 134\tAverage Score: 2.13\tScore: 6.06\tLossActor: -0.00061200 \tLossCritic : 0.00017311(tensor([[ 0.2669,  0.3961, -0.1538,  0.4734]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3687, 0.3685, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 135\tAverage Score: 2.16\tScore: 3.60\tLossActor: -0.00060573 \tLossCritic : 0.00017618(tensor([[ 0.0932, -0.4298, -0.3278, -0.2823]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3691, 0.3688, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 136\tAverage Score: 2.19\tScore: 3.05\tLossActor: -0.00060885 \tLossCritic : 0.00017768(tensor([[ 0.0167, -0.0570, -0.2818, -0.1800]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3699, 0.3689, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 137\tAverage Score: 2.20\tScore: 1.18\tLossActor: -0.00057279 \tLossCritic : 0.00017888(tensor([[-0.0529,  0.5044,  0.2138,  0.1429]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3720, 0.3734, 0.3719, 0.3722]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 138\tAverage Score: 2.22\tScore: 2.41\tLossActor: -0.00055421 \tLossCritic : 0.00018025(tensor([[ 0.0167,  0.2625, -0.1033, -0.3312]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3704, 0.3692, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 139\tAverage Score: 2.25\tScore: 4.01\tLossActor: -0.00055524 \tLossCritic : 0.00018195(tensor([[ 0.4137, -0.4713, -0.0400, -0.2837]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3687, 0.3685, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 140\tAverage Score: 2.26\tScore: 2.06\tLossActor: -0.00051560 \tLossCritic : 0.00018343(tensor([[ 0.1363, -0.2937,  0.3811, -0.1377]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 141\tAverage Score: 2.30\tScore: 4.43\tLossActor: -0.00052304 \tLossCritic : 0.00018560(tensor([[ 0.3433, -0.4310, -0.2010, -0.3399]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3709, 0.3699, 0.3694, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 142\tAverage Score: 2.34\tScore: 4.74\tLossActor: -0.00052661 \tLossCritic : 0.00018793(tensor([[-0.1777,  0.3900, -0.0796,  0.2094]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3742, 0.3724, 0.3721, 0.3724]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 143\tAverage Score: 2.38\tScore: 5.92\tLossActor: -0.00054268 \tLossCritic : 0.00018990(tensor([[-0.3085, -0.2691, -0.1909,  0.3996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3690, 0.3695, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 144\tAverage Score: 2.45\tScore: 7.84\tLossActor: -0.00058917 \tLossCritic : 0.00019257(tensor([[-0.1056,  0.4538, -0.0375,  0.2747]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3729, 0.3719, 0.3723, 0.3726]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 145\tAverage Score: 2.50\tScore: 5.58\tLossActor: -0.00061054 \tLossCritic : 0.00019469(tensor([[-0.2035,  0.0110,  0.0518,  0.1518]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3728, 0.3715, 0.3712, 0.3716]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 146\tAverage Score: 2.55\tScore: 5.15\tLossActor: -0.00061189 \tLossCritic : 0.00019662(tensor([[ 0.2134, -0.3115,  0.2249, -0.1013]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3699, 0.3697, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 147\tAverage Score: 2.57\tScore: 4.51\tLossActor: -0.00061236 \tLossCritic : 0.00019798(tensor([[ 0.0474, -0.4521,  0.0649, -0.3922]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3689, 0.3686, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 148\tAverage Score: 2.62\tScore: 5.43\tLossActor: -0.00062865 \tLossCritic : 0.00020023(tensor([[ 0.2800, -0.3940,  0.3214,  0.0904]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3682, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 149\tAverage Score: 2.64\tScore: 3.79\tLossActor: -0.00061756 \tLossCritic : 0.00020203(tensor([[-0.3736, -0.3237, -0.3273,  0.0704]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3738, 0.3706, 0.3706, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 150\tAverage Score: 2.71\tScore: 8.13\tLossActor: -0.00064031 \tLossCritic : 0.00020488(tensor([[0.1244, 0.2157, 0.0905, 0.4613]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3684, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 151\tAverage Score: 2.69\tScore: 1.38\tLossActor: -0.00058499 \tLossCritic : 0.00020693(tensor([[-0.2218, -0.7578, -0.6796, -0.4290]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3681, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 152\tAverage Score: 2.76\tScore: 7.49\tLossActor: -0.00062159 \tLossCritic : 0.00020956(tensor([[-0.3810, -0.5185, -0.1223, -0.4111]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3682, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 153\tAverage Score: 2.79\tScore: 3.39\tLossActor: -0.00039994 \tLossCritic : 0.00021198(tensor([[-0.3100, -0.3493,  0.0256, -0.1466]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3729, 0.3711, 0.3715, 0.3705]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 154\tAverage Score: 2.83\tScore: 5.27\tLossActor: -0.00037435 \tLossCritic : 0.00021519(tensor([[-0.4750,  0.0061,  0.0286,  0.2885]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3715, 0.3708, 0.3706, 0.3708]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 155\tAverage Score: 2.84\tScore: 2.44\tLossActor: -0.00018816 \tLossCritic : 0.00021695(tensor([[ 0.1387,  0.1681,  0.0578, -0.2920]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3697, 0.3692, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 156\tAverage Score: 2.84\tScore: 1.08\tLossActor: -0.00013576 \tLossCritic : 0.00021733(tensor([[-0.6921,  0.5908,  0.0663,  0.3303]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3681, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 157\tAverage Score: 2.86\tScore: 2.66\tLossActor: -0.00009541 \tLossCritic : 0.00021890(tensor([[-0.4816,  0.5939,  0.5346, -0.1606]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3681, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 158\tAverage Score: 2.87\tScore: 1.80\tLossActor: -0.00005860 \tLossCritic : 0.00021996(tensor([[-0.5399,  0.4798, -0.2436, -0.5905]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 159\tAverage Score: 2.88\tScore: 4.72\tLossActor: -0.00006006 \tLossCritic : 0.00022194(tensor([[ 0.3307, -0.0682, -0.2620, -0.3903]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3697, 0.3691, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 160\tAverage Score: 2.89\tScore: 3.19\tLossActor: -0.00004361 \tLossCritic : 0.00022328(tensor([[-0.5613,  0.3391, -0.2254,  0.2865]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3712, 0.3699, 0.3700, 0.3703]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 161\tAverage Score: 2.90\tScore: 3.61\tLossActor: -0.00001265 \tLossCritic : 0.00022440(tensor([[0.2376, 0.2440, 0.4220, 0.0199]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3688, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 162\tAverage Score: 2.92\tScore: 4.04\tLossActor: 0.00000617 \tLossCritic : 0.00022677(tensor([[ 0.1049,  0.1129, -0.0924, -0.2173]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3693, 0.3687, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 163\tAverage Score: 2.95\tScore: 3.76\tLossActor: 0.00000489 \tLossCritic : 0.00022804(tensor([[ 0.0027,  0.3627,  0.3086, -0.0976]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3700, 0.3709, 0.3712]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 164\tAverage Score: 2.97\tScore: 4.33\tLossActor: 0.00000946 \tLossCritic : 0.00022914(tensor([[ 0.1277,  0.5123, -0.1453, -0.0848]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3694, 0.3698, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 165\tAverage Score: 2.97\tScore: 2.32\tLossActor: 0.00003424 \tLossCritic : 0.00022972(tensor([[-0.7459, -0.0571,  0.1653,  0.2449]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3682, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 166\tAverage Score: 2.96\tScore: 1.98\tLossActor: 0.00006791 \tLossCritic : 0.00023013(tensor([[ 0.2516, -0.2347, -0.2546, -0.1116]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3694, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 167\tAverage Score: 2.99\tScore: 3.07\tLossActor: 0.00008296 \tLossCritic : 0.00023088(tensor([[-0.4141, -0.1909,  0.0152, -0.1536]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3721, 0.3693, 0.3695, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 168\tAverage Score: 3.01\tScore: 3.31\tLossActor: 0.00009142 \tLossCritic : 0.00023156(tensor([[-0.0598, -0.1455, -0.2556, -0.0872]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3733, 0.3705, 0.3701, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 169\tAverage Score: 3.03\tScore: 3.83\tLossActor: 0.00008868 \tLossCritic : 0.00023303(tensor([[-0.3853,  0.2544, -0.0348,  0.4788]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3682, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 170\tAverage Score: 3.08\tScore: 5.66\tLossActor: 0.00006837 \tLossCritic : 0.00023473(tensor([[ 0.1849, -0.3572, -0.0190, -0.0519]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3740, 0.3706, 0.3711, 0.3711]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 171\tAverage Score: 3.10\tScore: 4.12\tLossActor: 0.00006383 \tLossCritic : 0.00023636(tensor([[-0.5367, -0.0630, -0.1630,  0.0027]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3720, 0.3691, 0.3695, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 172\tAverage Score: 3.12\tScore: 3.60\tLossActor: 0.00007390 \tLossCritic : 0.00023714(tensor([[ 0.3273,  0.3885,  0.1977, -0.2869]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3691, 0.3692, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 173\tAverage Score: 3.16\tScore: 4.63\tLossActor: 0.00006246 \tLossCritic : 0.00023841(tensor([[ 0.2287,  0.4740,  0.1168, -0.2803]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3697, 0.3699, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 174\tAverage Score: 3.20\tScore: 5.33\tLossActor: 0.00005238 \tLossCritic : 0.00023963(tensor([[ 0.0916, -0.3694, -0.0851,  0.0395]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3741, 0.3705, 0.3698, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 175\tAverage Score: 3.24\tScore: 5.66\tLossActor: 0.00004121 \tLossCritic : 0.00024179(tensor([[-0.2466, -0.4707,  0.0649,  0.0912]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3686, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 176\tAverage Score: 3.28\tScore: 4.64\tLossActor: 0.00003284 \tLossCritic : 0.00024355(tensor([[-0.1305, -0.1881, -0.3210,  0.6076]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 177\tAverage Score: 3.27\tScore: 1.11\tLossActor: 0.00007898 \tLossCritic : 0.00024480(tensor([[ 0.0910, -0.0427, -0.1476, -0.0998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3691, 0.3693, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 178\tAverage Score: 3.28\tScore: 2.43\tLossActor: 0.00010171 \tLossCritic : 0.00024574(tensor([[ 0.3088, -0.5730, -0.4377,  0.3833]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3682, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 179\tAverage Score: 3.30\tScore: 4.31\tLossActor: 0.00009452 \tLossCritic : 0.00024743(tensor([[-0.0217, -0.1190, -0.0595,  0.0440]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3763, 0.3720, 0.3714, 0.3714]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 180\tAverage Score: 3.34\tScore: 3.97\tLossActor: 0.00009382 \tLossCritic : 0.00024802(tensor([[-0.2472,  0.4441,  0.0420,  0.3042]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3685, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 181\tAverage Score: 3.36\tScore: 2.91\tLossActor: 0.00012832 \tLossCritic : 0.00024954(tensor([[ 0.4412, -0.1169,  0.6454,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3681, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 182\tAverage Score: 3.39\tScore: 4.66\tLossActor: 0.00013104 \tLossCritic : 0.00025085(tensor([[ 0.0479,  0.3016, -0.1054, -0.3949]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3682, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 183\tAverage Score: 3.41\tScore: 4.03\tLossActor: 0.00013510 \tLossCritic : 0.00025218(tensor([[-0.1516,  0.1116, -0.5566, -0.0914]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3711, 0.3686, 0.3689, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 184\tAverage Score: 3.43\tScore: 3.43\tLossActor: 0.00014385 \tLossCritic : 0.00025239(tensor([[ 0.3302, -0.3231,  0.0671,  0.2835]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 185\tAverage Score: 3.44\tScore: 3.70\tLossActor: 0.00014262 \tLossCritic : 0.00025316(tensor([[-0.4555,  0.2557, -0.2498,  0.2155]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3697, 0.3696, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 186\tAverage Score: 3.45\tScore: 5.82\tLossActor: 0.00012684 \tLossCritic : 0.00025490(tensor([[-0.2691,  0.2311,  0.0724, -0.0471]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3697, 0.3695, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 187\tAverage Score: 3.46\tScore: 3.38\tLossActor: 0.00013152 \tLossCritic : 0.00025544(tensor([[-0.0194,  0.2147, -0.2435, -0.1131]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3729, 0.3711, 0.3714, 0.3723]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 188\tAverage Score: 3.50\tScore: 5.36\tLossActor: 0.00011673 \tLossCritic : 0.00025668(tensor([[-0.1046, -0.0864, -0.0967,  0.1505]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3784, 0.3731, 0.3722, 0.3731]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 189\tAverage Score: 3.53\tScore: 4.30\tLossActor: 0.00012238 \tLossCritic : 0.00025788(tensor([[-0.3120,  0.5861,  0.0043,  0.1312]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3683, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 190\tAverage Score: 3.59\tScore: 5.15\tLossActor: 0.00011548 \tLossCritic : 0.00025859(tensor([[ 0.2230, -0.1336,  0.2793, -0.4731]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3685, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 191\tAverage Score: 3.58\tScore: 3.20\tLossActor: 0.00014309 \tLossCritic : 0.00026027(tensor([[-0.1862, -0.1044,  0.0872, -0.1160]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3686, 0.3690, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 192\tAverage Score: 3.62\tScore: 5.63\tLossActor: 0.00013630 \tLossCritic : 0.00026174(tensor([[ 3.1588e-01,  1.0028e-01, -2.3006e-01, -1.0340e-04]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3683, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 193\tAverage Score: 3.63\tScore: 2.99\tLossActor: 0.00014652 \tLossCritic : 0.00026342(tensor([[ 0.2486,  0.5122, -0.2132,  0.1922]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3683, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 194\tAverage Score: 3.67\tScore: 6.24\tLossActor: 0.00012504 \tLossCritic : 0.00026510(tensor([[-0.2885, -0.0724,  0.1396,  0.2724]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3693, 0.3701, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 195\tAverage Score: 3.70\tScore: 6.48\tLossActor: 0.00020490 \tLossCritic : 0.00026732(tensor([[-0.1945, -0.1310,  0.0598, -0.4107]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3683, 0.3688, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 196\tAverage Score: 3.70\tScore: 3.50\tLossActor: 0.00021565 \tLossCritic : 0.00026857(tensor([[ 0.0598, -0.0740, -0.0460, -0.5243]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 197\tAverage Score: 3.69\tScore: 2.47\tLossActor: 0.00023536 \tLossCritic : 0.00026939(tensor([[0.2714, 0.2488, 0.2437, 0.0270]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3687, 0.3694, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 198\tAverage Score: 3.68\tScore: 4.93\tLossActor: 0.00026924 \tLossCritic : 0.00027022(tensor([[ 0.2971, -0.3071,  0.3139, -0.0543]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3687, 0.3696, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 199\tAverage Score: 3.72\tScore: 5.70\tLossActor: 0.00025961 \tLossCritic : 0.00027149(tensor([[-0.4663,  0.1135,  0.0791, -0.0238]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3735, 0.3716, 0.3732, 0.3718]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 200\tAverage Score: 3.76\tScore: 5.32\tLossActor: 0.00024378 \tLossCritic : 0.00027240(tensor([[-0.1630, -0.4776,  0.1782, -0.4165]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3680, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 200\tAverage Score: 3.76\n",
      "Episode 201\tAverage Score: 3.78\tScore: 3.92\tLossActor: 0.00024444 \tLossCritic : 0.00027335(tensor([[ 0.6891,  0.3833, -0.1454, -0.2841]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 202\tAverage Score: 3.81\tScore: 4.66\tLossActor: 0.00023537 \tLossCritic : 0.00027429(tensor([[ 0.0297, -0.1736, -0.0409,  0.0820]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3761, 0.3720, 0.3737, 0.3720]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 203\tAverage Score: 3.78\tScore: 0.42\tLossActor: 0.00027307 \tLossCritic : 0.00027471(tensor([[ 0.3452, -0.2642,  0.1296,  0.3034]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3682, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 204\tAverage Score: 3.76\tScore: 0.73\tLossActor: 0.00030747 \tLossCritic : 0.00027481(tensor([[ 0.0334, -0.0384, -0.2420,  0.3519]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3682, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 205\tAverage Score: 3.76\tScore: 5.34\tLossActor: 0.00029225 \tLossCritic : 0.00027716(tensor([[-0.1303, -0.0442,  0.1710, -0.0377]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3686, 0.3688, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 206\tAverage Score: 3.81\tScore: 6.09\tLossActor: 0.00028975 \tLossCritic : 0.00027819(tensor([[ 0.2646,  0.1303, -0.1806,  0.1974]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3689, 0.3693, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 207\tAverage Score: 3.83\tScore: 2.61\tLossActor: 0.00030162 \tLossCritic : 0.00027886(tensor([[0.0708, 0.2292, 0.2106, 0.1239]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3688, 0.3693, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 208\tAverage Score: 3.88\tScore: 5.36\tLossActor: 0.00029377 \tLossCritic : 0.00028076(tensor([[ 0.4716,  0.2232, -0.4430, -0.2883]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3688, 0.3690, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 209\tAverage Score: 3.89\tScore: 4.07\tLossActor: 0.00029696 \tLossCritic : 0.00028226(tensor([[ 0.0068,  0.1946,  0.2196, -0.1331]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3693, 0.3699, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 210\tAverage Score: 3.92\tScore: 5.74\tLossActor: 0.00027845 \tLossCritic : 0.00028399(tensor([[-0.4825, -0.0767,  0.0492, -0.0335]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3683, 0.3687, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 211\tAverage Score: 3.96\tScore: 6.14\tLossActor: 0.00026073 \tLossCritic : 0.00028550(tensor([[ 0.1023,  0.0267, -0.3786,  0.1340]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3690, 0.3692, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 212\tAverage Score: 3.99\tScore: 5.01\tLossActor: 0.00026284 \tLossCritic : 0.00028779(tensor([[ 0.3339,  0.2941,  0.5185, -0.0241]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3686, 0.3687, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 213\tAverage Score: 4.00\tScore: 3.75\tLossActor: 0.00026826 \tLossCritic : 0.00028973(tensor([[-0.3000,  0.0982,  0.2144,  0.3867]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3690, 0.3695, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 214\tAverage Score: 4.04\tScore: 7.56\tLossActor: 0.00024045 \tLossCritic : 0.00029190(tensor([[-0.0353,  0.0978, -0.2368, -0.5419]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3683, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 215\tAverage Score: 4.06\tScore: 2.56\tLossActor: 0.00027460 \tLossCritic : 0.00029352(tensor([[ 0.3752, -0.3338, -0.1223,  0.0005]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3681, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 216\tAverage Score: 4.10\tScore: 8.69\tLossActor: 0.00024218 \tLossCritic : 0.00029558(tensor([[-0.4049,  0.3812,  0.1043,  0.4924]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 217\tAverage Score: 4.11\tScore: 2.38\tLossActor: 0.00028546 \tLossCritic : 0.00029655(tensor([[ 0.4446,  0.4478,  0.1884, -0.5182]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3680, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 218\tAverage Score: 4.10\tScore: 3.11\tLossActor: 0.00029969 \tLossCritic : 0.00029811(tensor([[-0.1837,  0.0192, -0.1078, -0.2544]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3733, 0.3697, 0.3704, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 219\tAverage Score: 4.12\tScore: 4.41\tLossActor: 0.00030509 \tLossCritic : 0.00030084(tensor([[ 0.2038,  0.0390, -0.2438, -0.1861]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3716, 0.3705, 0.3704, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 220\tAverage Score: 4.14\tScore: 6.68\tLossActor: 0.00029371 \tLossCritic : 0.00030374(tensor([[-0.0903,  0.1108, -0.2550,  0.0818]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3690, 0.3692, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 221\tAverage Score: 4.19\tScore: 7.25\tLossActor: 0.00028190 \tLossCritic : 0.00030524(tensor([[ 0.4646, -0.3638, -0.4791,  0.0107]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3679, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 222\tAverage Score: 4.22\tScore: 6.40\tLossActor: 0.00027157 \tLossCritic : 0.00030686(tensor([[ 0.0408, -0.6311,  0.1357, -0.7457]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3679, 0.3680, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 223\tAverage Score: 4.27\tScore: 6.24\tLossActor: 0.00026356 \tLossCritic : 0.00030887(tensor([[ 0.4675, -0.2546, -0.3286,  0.0184]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3686, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 224\tAverage Score: 4.29\tScore: 6.23\tLossActor: 0.00025378 \tLossCritic : 0.00031086(tensor([[ 0.3570, -0.4467, -0.3859, -0.2337]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3679, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 225\tAverage Score: 4.31\tScore: 6.14\tLossActor: 0.00025008 \tLossCritic : 0.00031280(tensor([[-0.3015, -0.2070, -0.0634, -0.3457]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3693, 0.3697, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 226\tAverage Score: 4.32\tScore: 4.12\tLossActor: 0.00028072 \tLossCritic : 0.00031515(tensor([[ 0.2246, -0.5848,  0.3092, -0.6765]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 227\tAverage Score: 4.32\tScore: 4.54\tLossActor: 0.00028633 \tLossCritic : 0.00031645(tensor([[ 0.1181, -0.1127,  0.2492,  0.0675]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3686, 0.3687, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 228\tAverage Score: 4.36\tScore: 8.12\tLossActor: 0.00026237 \tLossCritic : 0.00031842(tensor([[ 0.1940, -0.3325,  0.0543, -0.5551]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 229\tAverage Score: 4.35\tScore: 4.99\tLossActor: 0.00026381 \tLossCritic : 0.00031954(tensor([[-0.2150,  0.0673,  0.0513,  0.1462]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3693, 0.3696, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 230\tAverage Score: 4.37\tScore: 5.82\tLossActor: 0.00025666 \tLossCritic : 0.00032114(tensor([[-0.3712,  0.0349, -0.0098, -0.1827]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3738, 0.3705, 0.3711, 0.3718]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 231\tAverage Score: 4.42\tScore: 7.81\tLossActor: 0.00025264 \tLossCritic : 0.00032266(tensor([[0.1055, 0.1303, 0.0618, 0.4487]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3683, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 232\tAverage Score: 4.40\tScore: 1.94\tLossActor: 0.00028412 \tLossCritic : 0.00032420(tensor([[ 0.2158,  0.0666, -0.2269, -0.0647]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3702, 0.3706, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 233\tAverage Score: 4.36\tScore: 1.41\tLossActor: 0.00032795 \tLossCritic : 0.00032579(tensor([[-0.1178,  0.2915, -0.0585,  0.0898]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3691, 0.3693, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 234\tAverage Score: 4.37\tScore: 6.34\tLossActor: 0.00033687 \tLossCritic : 0.00032671(tensor([[-0.0900,  0.0331,  0.1360,  0.6284]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 235\tAverage Score: 4.39\tScore: 5.97\tLossActor: 0.00033338 \tLossCritic : 0.00032885(tensor([[ 0.0593,  0.1530,  0.0190, -0.3695]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 236\tAverage Score: 4.39\tScore: 3.04\tLossActor: 0.00036171 \tLossCritic : 0.00033034(tensor([[-0.2060, -0.2646, -0.0108, -0.3311]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3683, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 237\tAverage Score: 4.44\tScore: 5.78\tLossActor: 0.00038230 \tLossCritic : 0.00033199(tensor([[-0.2175,  0.0016, -0.1849, -0.4820]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3688, 0.3695, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 238\tAverage Score: 4.47\tScore: 5.99\tLossActor: 0.00041258 \tLossCritic : 0.00033371(tensor([[-0.0083,  0.2057, -0.1447,  0.2034]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3681, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 239\tAverage Score: 4.48\tScore: 5.00\tLossActor: 0.00042964 \tLossCritic : 0.00033564(tensor([[0.3555, 0.1909, 0.3481, 0.0365]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3687, 0.3687, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 240\tAverage Score: 4.53\tScore: 7.03\tLossActor: 0.00041442 \tLossCritic : 0.00033729(tensor([[ 0.1809,  0.3469,  0.0380, -0.1412]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3687, 0.3687, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 241\tAverage Score: 4.55\tScore: 5.96\tLossActor: 0.00040637 \tLossCritic : 0.00033842(tensor([[-0.1122,  0.0560,  0.0147,  0.2891]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3746, 0.3729, 0.3729, 0.3734]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 242\tAverage Score: 4.60\tScore: 9.76\tLossActor: 0.00038891 \tLossCritic : 0.00034066(tensor([[ 0.2576,  0.3966, -0.1266,  0.6129]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3692, 0.3690, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 243\tAverage Score: 4.60\tScore: 5.81\tLossActor: 0.00038518 \tLossCritic : 0.00034171(tensor([[ 0.2988, -0.0719,  0.3960, -0.3695]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 244\tAverage Score: 4.61\tScore: 8.78\tLossActor: 0.00036493 \tLossCritic : 0.00034367(tensor([[0.1605, 0.0568, 0.1708, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 245\tAverage Score: 4.68\tScore: 12.79\tLossActor: 0.00032475 \tLossCritic : 0.00034645(tensor([[-0.1060, -0.0479, -0.1583,  0.4403]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 246\tAverage Score: 4.68\tScore: 5.22\tLossActor: 0.00034223 \tLossCritic : 0.00034808(tensor([[0.1757, 0.1796, 0.3397, 0.0121]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3682, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 247\tAverage Score: 4.71\tScore: 7.12\tLossActor: 0.00032747 \tLossCritic : 0.00035138(tensor([[0.0707, 0.0630, 0.4871, 0.6560]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 248\tAverage Score: 4.73\tScore: 7.94\tLossActor: 0.00032532 \tLossCritic : 0.00035457(tensor([[ 0.1711, -0.3974, -0.0129, -0.2246]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 249\tAverage Score: 4.79\tScore: 10.12\tLossActor: 0.00030290 \tLossCritic : 0.00035716(tensor([[-0.1777, -0.1277, -0.4339, -0.1323]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 250\tAverage Score: 4.83\tScore: 11.32\tLossActor: 0.00028435 \tLossCritic : 0.00035955(tensor([[-0.1199, -0.1932, -0.3029, -0.0643]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3681, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 251\tAverage Score: 4.85\tScore: 3.69\tLossActor: 0.00031042 \tLossCritic : 0.00036213(tensor([[-0.0899,  0.0434,  0.1669, -0.2313]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 252\tAverage Score: 4.85\tScore: 7.90\tLossActor: 0.00029519 \tLossCritic : 0.00036470(tensor([[-0.4425, -0.0140,  0.3379, -0.4360]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 253\tAverage Score: 4.92\tScore: 10.32\tLossActor: 0.00027055 \tLossCritic : 0.00036662(tensor([[ 0.1588, -0.0680,  0.5387, -0.1059]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 254\tAverage Score: 4.96\tScore: 9.07\tLossActor: 0.00025762 \tLossCritic : 0.00036929(tensor([[-0.2531,  0.1827,  0.1165,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3707, 0.3707, 0.3700, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 255\tAverage Score: 5.04\tScore: 10.30\tLossActor: 0.00022966 \tLossCritic : 0.00037144(tensor([[ 0.0181, -0.2792, -0.2454, -0.0576]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3685, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 256\tAverage Score: 5.13\tScore: 9.79\tLossActor: 0.00022600 \tLossCritic : 0.00037354(tensor([[-0.2514, -0.3817, -0.3571, -0.0541]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3684, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 257\tAverage Score: 5.14\tScore: 4.43\tLossActor: 0.00025790 \tLossCritic : 0.00037502(tensor([[-0.3106, -0.0970, -0.0271, -0.0902]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3712, 0.3707, 0.3704, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 258\tAverage Score: 5.16\tScore: 3.30\tLossActor: 0.00032080 \tLossCritic : 0.00037693(tensor([[-0.1174,  0.2950, -0.4865, -0.5132]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 259\tAverage Score: 5.15\tScore: 4.16\tLossActor: 0.00035899 \tLossCritic : 0.00037847(tensor([[ 0.3396,  0.5101, -0.3239, -0.6052]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 260\tAverage Score: 5.14\tScore: 1.78\tLossActor: 0.00039884 \tLossCritic : 0.00037931(tensor([[ 0.1968, -0.3435,  0.2225,  0.0116]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3685, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 261\tAverage Score: 5.14\tScore: 3.32\tLossActor: 0.00042491 \tLossCritic : 0.00038086(tensor([[-0.1975,  0.3792, -0.3012, -0.2692]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 262\tAverage Score: 5.13\tScore: 3.42\tLossActor: 0.00045311 \tLossCritic : 0.00038237(tensor([[ 0.3049,  0.0796,  0.0907, -0.4235]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3687, 0.3685, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 263\tAverage Score: 5.13\tScore: 3.65\tLossActor: 0.00046373 \tLossCritic : 0.00038311(tensor([[ 0.2809, -0.4207,  0.2032, -0.1253]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 264\tAverage Score: 5.15\tScore: 6.50\tLossActor: 0.00046633 \tLossCritic : 0.00038402(tensor([[-0.6041, -0.1148, -0.0217,  0.0326]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3697, 0.3702, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 265\tAverage Score: 5.18\tScore: 4.95\tLossActor: 0.00048741 \tLossCritic : 0.00038576(tensor([[ 0.5398,  0.4066, -0.0186,  0.4203]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 266\tAverage Score: 5.20\tScore: 4.34\tLossActor: 0.00049366 \tLossCritic : 0.00038552(tensor([[-0.5777, -0.0684, -0.0216, -0.0598]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3684, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 267\tAverage Score: 5.19\tScore: 2.23\tLossActor: 0.00051661 \tLossCritic : 0.00038589(tensor([[-0.1902, -0.2677,  0.0371, -0.0008]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 268\tAverage Score: 5.20\tScore: 4.40\tLossActor: 0.00052316 \tLossCritic : 0.00038692(tensor([[-0.1143, -0.1173, -0.3761, -0.1685]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3686, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 269\tAverage Score: 5.21\tScore: 4.70\tLossActor: 0.00055370 \tLossCritic : 0.00038828(tensor([[-0.2803,  0.3586, -0.1179, -0.1505]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3697, 0.3690, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 270\tAverage Score: 5.23\tScore: 7.71\tLossActor: 0.00054466 \tLossCritic : 0.00039021(tensor([[ 0.1988,  0.1761, -0.3381, -0.1633]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3682, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 271\tAverage Score: 5.22\tScore: 3.30\tLossActor: 0.00057538 \tLossCritic : 0.00039244(tensor([[ 0.1560, -0.1645,  0.3213,  0.2687]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 272\tAverage Score: 5.26\tScore: 7.47\tLossActor: 0.00056828 \tLossCritic : 0.00039409(tensor([[ 0.0971,  0.0676,  0.2729, -0.3695]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3687, 0.3684, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 273\tAverage Score: 5.32\tScore: 9.96\tLossActor: 0.00053425 \tLossCritic : 0.00039583(tensor([[ 0.2581,  0.4609,  0.3510, -0.1065]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3688, 0.3683, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 274\tAverage Score: 5.30\tScore: 3.84\tLossActor: 0.00055483 \tLossCritic : 0.00039609(tensor([[-0.2392,  0.0858, -0.1849,  0.1997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 275\tAverage Score: 5.31\tScore: 6.41\tLossActor: 0.00056937 \tLossCritic : 0.00039703(tensor([[-0.3687,  0.4100,  0.6079,  0.2762]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 276\tAverage Score: 5.34\tScore: 7.78\tLossActor: 0.00055339 \tLossCritic : 0.00039757(tensor([[-0.1657,  0.3279, -0.2989,  0.3485]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3691, 0.3687, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 277\tAverage Score: 5.41\tScore: 8.24\tLossActor: 0.00054140 \tLossCritic : 0.00039880(tensor([[ 0.0201, -0.0220,  0.1994,  0.3275]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3684, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 278\tAverage Score: 5.44\tScore: 5.05\tLossActor: 0.00053099 \tLossCritic : 0.00039905(tensor([[ 0.0920,  0.4124, -0.7314,  0.2331]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 279\tAverage Score: 5.44\tScore: 4.98\tLossActor: 0.00055161 \tLossCritic : 0.00040192(tensor([[-0.2738,  0.2561, -0.0429, -0.1219]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 280\tAverage Score: 5.47\tScore: 7.10\tLossActor: 0.00055660 \tLossCritic : 0.00040316(tensor([[-0.1915,  0.7485, -0.1140, -0.2541]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3702, 0.3692, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 281\tAverage Score: 5.50\tScore: 5.23\tLossActor: 0.00057138 \tLossCritic : 0.00040552(tensor([[-0.0778, -0.0548, -0.4991,  0.0678]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 282\tAverage Score: 5.52\tScore: 7.07\tLossActor: 0.00056400 \tLossCritic : 0.00040672(tensor([[ 0.2684, -0.5236,  0.2922, -0.4164]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 283\tAverage Score: 5.63\tScore: 15.02\tLossActor: 0.00051112 \tLossCritic : 0.00040865(tensor([[0.2432, 0.5169, 0.0177, 0.0171]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3685, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 284\tAverage Score: 5.74\tScore: 13.79\tLossActor: 0.00046519 \tLossCritic : 0.00041096(tensor([[-0.2416,  0.2779, -0.0890,  0.1097]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3696, 0.3695, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 285\tAverage Score: 5.73\tScore: 3.08\tLossActor: 0.00049015 \tLossCritic : 0.00041258(tensor([[-0.3112,  0.3522,  0.0804,  0.0276]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 286\tAverage Score: 5.70\tScore: 2.91\tLossActor: 0.00052893 \tLossCritic : 0.00041473(tensor([[-0.4789, -0.1116, -0.4459, -0.3660]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 287\tAverage Score: 5.72\tScore: 5.21\tLossActor: 0.00054060 \tLossCritic : 0.00041644(tensor([[ 0.3138, -0.2166,  0.0337,  0.5483]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3704, 0.3703, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 288\tAverage Score: 5.75\tScore: 8.72\tLossActor: 0.00054182 \tLossCritic : 0.00041780(tensor([[-0.3374, -0.1796, -0.4814,  0.1355]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3691, 0.3691, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 289\tAverage Score: 5.88\tScore: 16.59\tLossActor: 0.00048580 \tLossCritic : 0.00041925(tensor([[ 0.0868,  0.2227, -0.4734, -0.0850]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3692, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 290\tAverage Score: 5.97\tScore: 14.37\tLossActor: 0.00042712 \tLossCritic : 0.00042304(tensor([[0.1681, 0.6401, 0.2366, 0.2047]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 291\tAverage Score: 5.96\tScore: 2.58\tLossActor: 0.00047118 \tLossCritic : 0.00042505(tensor([[-0.2896,  0.0439,  0.2222,  0.5044]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 292\tAverage Score: 5.97\tScore: 6.28\tLossActor: 0.00047513 \tLossCritic : 0.00042647(tensor([[ 0.0082,  0.3072, -0.1295,  0.1814]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 293\tAverage Score: 6.13\tScore: 18.91\tLossActor: 0.00040444 \tLossCritic : 0.00042851(tensor([[-0.1284,  0.0266, -0.2452,  0.1032]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 294\tAverage Score: 6.25\tScore: 18.31\tLossActor: 0.00033853 \tLossCritic : 0.00043062(tensor([[-0.5275,  0.1312,  0.0992,  0.2318]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3693, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 295\tAverage Score: 6.29\tScore: 10.94\tLossActor: 0.00032461 \tLossCritic : 0.00043366(tensor([[ 0.1864,  0.1322,  0.0435, -0.4963]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3691, 0.3687, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 296\tAverage Score: 6.37\tScore: 11.00\tLossActor: 0.00030522 \tLossCritic : 0.00043589(tensor([[ 0.2888, -0.1754, -0.0185,  0.1628]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3687, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 297\tAverage Score: 6.56\tScore: 21.48\tLossActor: 0.00022123 \tLossCritic : 0.00043866(tensor([[-0.2451, -0.5579,  0.3027, -0.6058]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 298\tAverage Score: 6.62\tScore: 10.93\tLossActor: 0.00021401 \tLossCritic : 0.00044052(tensor([[-0.3819,  0.4676, -0.4863, -0.3090]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 299\tAverage Score: 6.59\tScore: 2.87\tLossActor: 0.00024417 \tLossCritic : 0.00044275(tensor([[ 0.3414, -0.1267,  0.3232,  0.2138]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 300\tAverage Score: 6.66\tScore: 12.62\tLossActor: 0.00021894 \tLossCritic : 0.00044523(tensor([[-0.7611, -0.0995,  0.3024, -0.2102]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3694, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 300\tAverage Score: 6.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 301\tAverage Score: 6.80\tScore: 18.02\tLossActor: 0.00018254 \tLossCritic : 0.00044834(tensor([[-0.3831,  0.1161, -0.4556,  0.2056]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 302\tAverage Score: 6.83\tScore: 7.24\tLossActor: 0.00020553 \tLossCritic : 0.00045241(tensor([[ 0.3603, -0.1169, -0.0282, -0.0761]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3689, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 303\tAverage Score: 6.87\tScore: 4.08\tLossActor: 0.00024881 \tLossCritic : 0.00045532(tensor([[-0.1943,  0.1080,  0.1948,  0.3849]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 304\tAverage Score: 7.04\tScore: 18.16\tLossActor: 0.00019942 \tLossCritic : 0.00045779(tensor([[-0.3243,  0.1372, -0.0672,  0.2054]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3703, 0.3692, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 305\tAverage Score: 7.16\tScore: 17.75\tLossActor: 0.00013955 \tLossCritic : 0.00046017(tensor([[ 0.2133, -0.4157,  0.3347, -0.1574]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3686, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 306\tAverage Score: 7.30\tScore: 20.12\tLossActor: 0.00008019 \tLossCritic : 0.00046198(tensor([[ 0.2182, -0.1755,  0.0214, -0.0279]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3688, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 307\tAverage Score: 7.52\tScore: 23.73\tLossActor: 0.00000694 \tLossCritic : 0.00046432(tensor([[-0.3803,  0.3995, -0.3744,  0.1511]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3694, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 308\tAverage Score: 7.53\tScore: 6.84\tLossActor: 0.00001650 \tLossCritic : 0.00046685(tensor([[ 0.2045, -0.1656,  0.4017,  0.5514]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 309\tAverage Score: 7.51\tScore: 2.28\tLossActor: 0.00006772 \tLossCritic : 0.00046970(tensor([[ 0.0165,  0.3311, -0.1075,  0.0821]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 310\tAverage Score: 7.68\tScore: 22.60\tLossActor: -0.00000079 \tLossCritic : 0.00047171(tensor([[0.1806, 0.4981, 0.1442, 0.0947]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 311\tAverage Score: 7.78\tScore: 15.88\tLossActor: 0.00000328 \tLossCritic : 0.00047506(tensor([[-0.2384, -0.0824, -0.0196,  0.1059]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3694, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 312\tAverage Score: 7.86\tScore: 12.78\tLossActor: -0.00000470 \tLossCritic : 0.00047756(tensor([[-0.5814,  0.1827,  0.0845,  0.0764]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3702, 0.3694, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 313\tAverage Score: 7.98\tScore: 15.81\tLossActor: -0.00000452 \tLossCritic : 0.00048100(tensor([[-0.0870, -0.3315, -0.1817,  0.0817]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3696, 0.3693, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 314\tAverage Score: 8.05\tScore: 14.80\tLossActor: -0.00003334 \tLossCritic : 0.00048401(tensor([[ 0.1906, -0.3927, -0.1710, -0.0203]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3691, 0.3691, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 315\tAverage Score: 8.18\tScore: 15.80\tLossActor: -0.00005822 \tLossCritic : 0.00048804(tensor([[-0.2929,  0.0936,  0.1346,  0.1356]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3697, 0.3695, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 316\tAverage Score: 8.30\tScore: 20.18\tLossActor: -0.00011163 \tLossCritic : 0.00049088(tensor([[ 0.4900, -0.2750,  0.2017,  0.1034]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 317\tAverage Score: 8.44\tScore: 16.90\tLossActor: -0.00013055 \tLossCritic : 0.00049353(tensor([[0.2995, 0.2888, 0.3023, 0.1059]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 318\tAverage Score: 8.43\tScore: 1.97\tLossActor: -0.00007112 \tLossCritic : 0.00049642(tensor([[-0.0401, -0.2446, -0.1304, -0.0624]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 319\tAverage Score: 8.61\tScore: 21.91\tLossActor: -0.00013337 \tLossCritic : 0.00049907(tensor([[ 0.2539, -0.1922, -0.3753, -0.1208]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3683, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 320\tAverage Score: 8.69\tScore: 14.84\tLossActor: -0.00013167 \tLossCritic : 0.00050170(tensor([[-0.4258, -0.0638, -0.2527, -0.3678]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 321\tAverage Score: 8.71\tScore: 9.78\tLossActor: -0.00009971 \tLossCritic : 0.00050506(tensor([[ 0.1224, -0.1789,  0.2777, -0.0047]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 322\tAverage Score: 8.82\tScore: 17.51\tLossActor: -0.00009466 \tLossCritic : 0.00050778(tensor([[-0.5094,  0.2953, -0.4877, -0.4860]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 323\tAverage Score: 8.98\tScore: 21.56\tLossActor: -0.00014485 \tLossCritic : 0.00051026(tensor([[-0.4733,  0.0530,  0.3599,  0.1820]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3689, 0.3685, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 324\tAverage Score: 9.03\tScore: 11.37\tLossActor: -0.00012801 \tLossCritic : 0.00051519(tensor([[ 0.0908, -0.0755,  0.7340,  0.1647]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 325\tAverage Score: 9.14\tScore: 17.45\tLossActor: -0.00013672 \tLossCritic : 0.00051757(tensor([[-0.1315,  0.2634,  0.2519,  0.6674]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3681, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 326\tAverage Score: 9.26\tScore: 15.70\tLossActor: -0.00013184 \tLossCritic : 0.00051970(tensor([[ 0.0345, -0.1446,  0.4756,  0.5824]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3679, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 327\tAverage Score: 9.39\tScore: 18.28\tLossActor: -0.00016403 \tLossCritic : 0.00052307(tensor([[-0.5122,  0.3441, -0.5272, -0.4927]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 328\tAverage Score: 9.52\tScore: 20.37\tLossActor: -0.00019163 \tLossCritic : 0.00052697(tensor([[-0.1674,  0.8384, -0.5690, -0.5635]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3680, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 329\tAverage Score: 9.79\tScore: 32.26\tLossActor: -0.00028431 \tLossCritic : 0.00052955(tensor([[-0.2368, -0.2758,  0.5020, -0.4587]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 330\tAverage Score: 10.00\tScore: 27.19\tLossActor: -0.00035339 \tLossCritic : 0.00053283(tensor([[ 0.1541, -0.5899, -0.4724, -0.0362]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 331\tAverage Score: 10.15\tScore: 22.77\tLossActor: -0.00038968 \tLossCritic : 0.00053621(tensor([[-0.2312,  0.1417, -0.2876,  0.3129]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 332\tAverage Score: 10.43\tScore: 29.90\tLossActor: -0.00046701 \tLossCritic : 0.00053801(tensor([[-0.1989, -0.2532, -0.1601, -0.1367]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3688, 0.3685, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 333\tAverage Score: 10.45\tScore: 3.05\tLossActor: -0.00039457 \tLossCritic : 0.00054164(tensor([[-0.1173, -0.0899, -0.3443,  0.4556]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3700, 0.3692, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 334\tAverage Score: 10.56\tScore: 17.19\tLossActor: -0.00040356 \tLossCritic : 0.00054498(tensor([[-0.0960,  0.1182,  0.4411,  0.1252]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3679, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 335\tAverage Score: 10.62\tScore: 11.78\tLossActor: -0.00037034 \tLossCritic : 0.00054883(tensor([[-0.3728,  0.0964,  0.0924,  0.2520]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3697, 0.3689, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 336\tAverage Score: 10.77\tScore: 18.81\tLossActor: -0.00039444 \tLossCritic : 0.00055174(tensor([[ 0.2134, -0.1533, -0.1614,  0.5849]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 337\tAverage Score: 10.99\tScore: 27.18\tLossActor: -0.00039136 \tLossCritic : 0.00055437(tensor([[ 0.4016, -0.4647,  0.3024, -0.7328]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3688, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 338\tAverage Score: 11.03\tScore: 10.68\tLossActor: -0.00035400 \tLossCritic : 0.00055806(tensor([[ 0.1868, -0.1384, -0.4451, -0.4491]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3704, 0.3693, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 339\tAverage Score: 11.11\tScore: 12.23\tLossActor: -0.00031027 \tLossCritic : 0.00056055(tensor([[ 0.2407,  0.3323, -0.0250, -0.2885]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 340\tAverage Score: 11.16\tScore: 12.64\tLossActor: -0.00029836 \tLossCritic : 0.00056298(tensor([[-0.3951, -0.3303,  0.5011, -0.1731]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 341\tAverage Score: 11.20\tScore: 9.31\tLossActor: -0.00026688 \tLossCritic : 0.00056662(tensor([[ 0.3162,  0.3262,  0.0963, -0.5156]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3684, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 342\tAverage Score: 11.29\tScore: 19.61\tLossActor: -0.00028982 \tLossCritic : 0.00056861(tensor([[-0.2695,  0.0007,  0.6497, -0.0602]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3688, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 343\tAverage Score: 11.32\tScore: 8.56\tLossActor: -0.00023821 \tLossCritic : 0.00057196(tensor([[ 0.4160,  0.3496, -0.4415,  0.5430]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3682, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 344\tAverage Score: 11.32\tScore: 8.35\tLossActor: -0.00017140 \tLossCritic : 0.00057665(tensor([[-0.0311, -0.1509,  0.1901, -0.2391]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3684, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 345\tAverage Score: 11.27\tScore: 8.26\tLossActor: -0.00012404 \tLossCritic : 0.00058079(tensor([[-0.2469, -0.2093, -0.3066,  0.1526]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3711, 0.3697, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 346\tAverage Score: 11.29\tScore: 7.51\tLossActor: -0.00006924 \tLossCritic : 0.00058382(tensor([[-0.3388, -0.3279,  0.0032,  0.1571]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3705, 0.3694, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 347\tAverage Score: 11.48\tScore: 25.15\tLossActor: -0.00013922 \tLossCritic : 0.00058615(tensor([[0.3412, 0.0971, 0.5259, 0.3732]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 348\tAverage Score: 11.59\tScore: 19.35\tLossActor: -0.00016485 \tLossCritic : 0.00058767(tensor([[ 0.2624, -0.4704, -0.5348, -0.3045]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 349\tAverage Score: 11.67\tScore: 18.18\tLossActor: -0.00017682 \tLossCritic : 0.00059052(tensor([[ 0.2361,  0.0067, -0.2150,  0.6637]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 350\tAverage Score: 11.79\tScore: 23.28\tLossActor: -0.00021693 \tLossCritic : 0.00059308(tensor([[-0.4877,  0.2563,  0.3890,  0.2304]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3682, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 351\tAverage Score: 12.02\tScore: 27.19\tLossActor: -0.00026428 \tLossCritic : 0.00059458(tensor([[0.1443, 0.4380, 0.0928, 0.1909]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 352\tAverage Score: 12.17\tScore: 22.40\tLossActor: -0.00028296 \tLossCritic : 0.00059853(tensor([[-0.0009, -0.0944, -0.5591,  0.1693]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 353\tAverage Score: 12.30\tScore: 22.94\tLossActor: -0.00032008 \tLossCritic : 0.00060215(tensor([[-0.3471,  0.0780, -0.0772, -0.3108]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3688, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 354\tAverage Score: 12.48\tScore: 27.80\tLossActor: -0.00035279 \tLossCritic : 0.00060516(tensor([[0.4508, 0.1479, 0.1725, 0.2716]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 355\tAverage Score: 12.53\tScore: 15.40\tLossActor: -0.00033619 \tLossCritic : 0.00060804(tensor([[-0.6018, -0.5016,  0.3108,  0.2206]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 356\tAverage Score: 12.74\tScore: 30.58\tLossActor: -0.00038002 \tLossCritic : 0.00061059(tensor([[ 0.0761, -0.6574, -0.2812, -0.1814]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 357\tAverage Score: 12.88\tScore: 18.43\tLossActor: -0.00037197 \tLossCritic : 0.00061418(tensor([[-0.0720, -0.2752,  0.1537, -0.5493]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3690, 0.3687, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 358\tAverage Score: 12.95\tScore: 10.31\tLossActor: -0.00033699 \tLossCritic : 0.00061780(tensor([[ 0.1459, -0.1342,  0.3083,  0.4998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 359\tAverage Score: 13.17\tScore: 26.01\tLossActor: -0.00037734 \tLossCritic : 0.00061991(tensor([[ 0.4252,  0.3565, -0.2065,  0.1029]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 360\tAverage Score: 13.47\tScore: 31.70\tLossActor: -0.00045152 \tLossCritic : 0.00062204(tensor([[-0.0311,  0.3612, -0.2513,  0.4139]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 361\tAverage Score: 13.80\tScore: 36.43\tLossActor: -0.00053662 \tLossCritic : 0.00062326(tensor([[ 0.5229,  0.2440, -0.5620,  0.2274]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 362\tAverage Score: 14.13\tScore: 36.59\tLossActor: -0.00062166 \tLossCritic : 0.00062411(tensor([[0.4708, 0.3372, 0.1004, 0.0831]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 363\tAverage Score: 14.34\tScore: 24.04\tLossActor: -0.00064120 \tLossCritic : 0.00062718(tensor([[0.4379, 0.1414, 0.0554, 0.4201]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 364\tAverage Score: 14.38\tScore: 11.29\tLossActor: -0.00057519 \tLossCritic : 0.00063049(tensor([[0.1382, 0.1600, 0.2098, 0.5153]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 365\tAverage Score: 14.64\tScore: 30.75\tLossActor: -0.00063334 \tLossCritic : 0.00063214(tensor([[-0.0276,  0.3278, -0.5429,  0.0657]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 366\tAverage Score: 14.93\tScore: 32.78\tLossActor: -0.00070670 \tLossCritic : 0.00063407(tensor([[0.3217, 0.0662, 0.4916, 0.5363]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 367\tAverage Score: 15.26\tScore: 35.69\tLossActor: -0.00077754 \tLossCritic : 0.00063497(tensor([[-0.1664, -0.1975, -0.2578,  0.0661]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3697, 0.3693, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 368\tAverage Score: 15.50\tScore: 28.74\tLossActor: -0.00079989 \tLossCritic : 0.00063699(tensor([[-2.9607e-01, -4.2633e-01,  9.9802e-05, -5.1271e-01]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 369\tAverage Score: 15.78\tScore: 32.06\tLossActor: -0.00084073 \tLossCritic : 0.00063899(tensor([[-0.1527, -0.0942, -0.7201,  0.1678]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 370\tAverage Score: 16.08\tScore: 38.21\tLossActor: -0.00091514 \tLossCritic : 0.00063969(tensor([[ 0.0982, -0.3513,  0.6204,  0.0752]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 371\tAverage Score: 16.42\tScore: 36.53\tLossActor: -0.00097389 \tLossCritic : 0.00064015(tensor([[ 0.4620,  0.2802, -0.3184,  0.5440]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 372\tAverage Score: 16.67\tScore: 33.37\tLossActor: -0.00101861 \tLossCritic : 0.00064101(tensor([[-0.0674, -0.6017, -0.0925,  0.0171]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3684, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 373\tAverage Score: 16.76\tScore: 18.69\tLossActor: -0.00096979 \tLossCritic : 0.00064449(tensor([[ 0.1991, -0.0596,  0.2864, -0.3670]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3679, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 374\tAverage Score: 17.07\tScore: 34.63\tLossActor: -0.00101070 \tLossCritic : 0.00064633(tensor([[-0.2613, -0.1203, -0.2879,  0.3818]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 375\tAverage Score: 17.24\tScore: 23.69\tLossActor: -0.00100421 \tLossCritic : 0.00064911(tensor([[ 0.3527, -0.0872,  0.1057,  0.4356]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 376\tAverage Score: 17.43\tScore: 26.04\tLossActor: -0.00099187 \tLossCritic : 0.00065127(tensor([[-0.1210, -0.4344, -0.0876, -0.2972]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3687, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 377\tAverage Score: 17.70\tScore: 35.94\tLossActor: -0.00104266 \tLossCritic : 0.00065358(tensor([[-0.4710,  0.3655, -0.5759,  0.2330]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 378\tAverage Score: 18.01\tScore: 35.49\tLossActor: -0.00109162 \tLossCritic : 0.00065579(tensor([[-0.1429,  0.2838,  0.3060,  0.6873]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 379\tAverage Score: 18.33\tScore: 37.36\tLossActor: -0.00112641 \tLossCritic : 0.00065594(tensor([[-0.3437, -0.1422,  0.0789, -0.4144]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3688, 0.3685, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 380\tAverage Score: 18.52\tScore: 26.31\tLossActor: -0.00111546 \tLossCritic : 0.00065840(tensor([[-0.3954,  0.0330,  0.1083,  0.6777]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 381\tAverage Score: 18.79\tScore: 31.82\tLossActor: -0.00114240 \tLossCritic : 0.00066009(tensor([[-0.0229,  0.3461, -0.2403, -0.0739]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 382\tAverage Score: 19.10\tScore: 37.74\tLossActor: -0.00119321 \tLossCritic : 0.00066082(tensor([[ 0.3019, -0.3280,  0.0785, -0.3826]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3687, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 383\tAverage Score: 19.27\tScore: 32.53\tLossActor: -0.00121526 \tLossCritic : 0.00066149(tensor([[ 0.0015, -0.3065, -0.2613, -0.2662]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 384\tAverage Score: 19.34\tScore: 20.82\tLossActor: -0.00117650 \tLossCritic : 0.00066405(tensor([[-0.2282, -0.3019, -0.3409, -0.2260]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 385\tAverage Score: 19.68\tScore: 37.06\tLossActor: -0.00122144 \tLossCritic : 0.00066441(tensor([[ 0.4651, -0.0065,  0.2477, -0.0601]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 386\tAverage Score: 19.95\tScore: 30.37\tLossActor: -0.00123665 \tLossCritic : 0.00066615(tensor([[-0.0136, -0.1105,  0.5444,  0.1383]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 387\tAverage Score: 20.26\tScore: 35.73\tLossActor: -0.00125993 \tLossCritic : 0.00066670(tensor([[-0.0126,  0.2140,  0.7092,  0.1803]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 388\tAverage Score: 20.52\tScore: 34.63\tLossActor: -0.00128024 \tLossCritic : 0.00066730(tensor([[-0.1755,  0.0769, -0.3402, -0.0556]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 389\tAverage Score: 20.74\tScore: 39.13\tLossActor: -0.00133061 \tLossCritic : 0.00066700(tensor([[ 0.2765, -0.0212,  0.3834, -0.3220]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 390\tAverage Score: 20.97\tScore: 37.05\tLossActor: -0.00136780 \tLossCritic : 0.00066710(tensor([[0.4946, 0.1237, 0.1261, 0.0259]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 391\tAverage Score: 21.33\tScore: 38.77\tLossActor: -0.00140270 \tLossCritic : 0.00066629(tensor([[-0.1752, -0.2191, -0.1349, -0.0547]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3685, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 392\tAverage Score: 21.47\tScore: 20.08\tLossActor: -0.00134745 \tLossCritic : 0.00066911(tensor([[ 0.1157,  0.2866, -0.4136,  0.3997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 393\tAverage Score: 21.54\tScore: 26.06\tLossActor: -0.00132827 \tLossCritic : 0.00067157(tensor([[-0.2093,  0.1522,  0.2309, -0.5235]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3686, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 394\tAverage Score: 21.58\tScore: 21.75\tLossActor: -0.00127546 \tLossCritic : 0.00067329(tensor([[ 0.2379, -0.1895, -0.2530, -0.6953]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 395\tAverage Score: 21.68\tScore: 21.38\tLossActor: -0.00123795 \tLossCritic : 0.00067495(tensor([[ 0.0659, -0.2989,  0.5372,  0.2470]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 396\tAverage Score: 21.83\tScore: 26.24\tLossActor: -0.00120937 \tLossCritic : 0.00067670(tensor([[ 0.2339, -0.0053,  0.2999,  0.1710]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 397\tAverage Score: 21.87\tScore: 24.65\tLossActor: -0.00119389 \tLossCritic : 0.00067926(tensor([[0.1796, 0.4188, 0.3040, 0.5571]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 398\tAverage Score: 22.09\tScore: 33.29\tLossActor: -0.00121735 \tLossCritic : 0.00067998(tensor([[-0.0091, -0.1702,  0.1468, -0.4700]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 399\tAverage Score: 22.31\tScore: 24.98\tLossActor: -0.00117029 \tLossCritic : 0.00068138(tensor([[-0.0597, -0.1173, -0.2645,  0.6131]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 400\tAverage Score: 22.55\tScore: 36.36\tLossActor: -0.00119910 \tLossCritic : 0.00068159(tensor([[-0.1328, -0.1217, -0.1917,  0.3683]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3691, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 400\tAverage Score: 22.55\n",
      "Episode 401\tAverage Score: 22.76\tScore: 39.08\tLossActor: -0.00123424 \tLossCritic : 0.00068101(tensor([[ 0.5339, -0.0146,  0.4075,  0.0028]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 402\tAverage Score: 23.07\tScore: 38.71\tLossActor: -0.00127668 \tLossCritic : 0.00068075(tensor([[ 0.2924, -0.4689, -0.2582, -0.1997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 403\tAverage Score: 23.39\tScore: 36.17\tLossActor: -0.00129920 \tLossCritic : 0.00068081(tensor([[ 0.2595, -0.0856, -0.0922,  0.1743]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 404\tAverage Score: 23.60\tScore: 38.97\tLossActor: -0.00133481 \tLossCritic : 0.00068050(tensor([[ 0.3237,  0.0628,  0.5176, -0.2529]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 405\tAverage Score: 23.81\tScore: 38.50\tLossActor: -0.00137236 \tLossCritic : 0.00068026(tensor([[-0.3046, -0.0175,  0.0629,  0.0745]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 406\tAverage Score: 23.98\tScore: 36.78\tLossActor: -0.00140480 \tLossCritic : 0.00068000(tensor([[ 0.2538,  0.5257,  0.3875, -0.0268]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 407\tAverage Score: 24.11\tScore: 37.55\tLossActor: -0.00142820 \tLossCritic : 0.00067957(tensor([[ 0.0361,  0.2058, -0.0087,  0.3533]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 408\tAverage Score: 24.28\tScore: 23.74\tLossActor: -0.00137527 \tLossCritic : 0.00068241(tensor([[0.0450, 0.6066, 0.1516, 0.0963]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 409\tAverage Score: 24.59\tScore: 32.68\tLossActor: -0.00136532 \tLossCritic : 0.00068351(tensor([[ 0.0498, -0.1703, -0.7668, -0.6120]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 410\tAverage Score: 24.65\tScore: 28.89\tLossActor: -0.00134402 \tLossCritic : 0.00068471(tensor([[-0.2039,  0.1088, -0.1557, -0.2444]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3698, 0.3690, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 411\tAverage Score: 24.85\tScore: 35.88\tLossActor: -0.00136067 \tLossCritic : 0.00068477(tensor([[0.0115, 0.5124, 0.3082, 0.4047]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 412\tAverage Score: 25.09\tScore: 37.08\tLossActor: -0.00137852 \tLossCritic : 0.00068411(tensor([[0.2953, 0.0630, 0.3050, 0.2513]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 413\tAverage Score: 25.22\tScore: 28.35\tLossActor: -0.00135383 \tLossCritic : 0.00068551(tensor([[-0.0223,  0.1606,  0.0309,  0.0627]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 414\tAverage Score: 25.39\tScore: 32.10\tLossActor: -0.00135255 \tLossCritic : 0.00068631(tensor([[-0.0649,  0.1896,  0.6653,  0.4633]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 415\tAverage Score: 25.62\tScore: 38.36\tLossActor: -0.00137769 \tLossCritic : 0.00068571(tensor([[ 0.3970, -0.0818, -0.1645, -0.5560]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 416\tAverage Score: 25.80\tScore: 38.09\tLossActor: -0.00139693 \tLossCritic : 0.00068570(tensor([[-0.4119,  0.1015,  0.2356,  0.5288]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 417\tAverage Score: 25.87\tScore: 24.52\tLossActor: -0.00136320 \tLossCritic : 0.00068764(tensor([[ 0.3522, -0.4504, -0.5818,  0.0472]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 418\tAverage Score: 26.25\tScore: 39.41\tLossActor: -0.00139512 \tLossCritic : 0.00068702(tensor([[-0.1052,  0.3038,  0.1685,  0.4253]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 419\tAverage Score: 26.37\tScore: 33.95\tLossActor: -0.00139851 \tLossCritic : 0.00068679(tensor([[0.3864, 0.1292, 0.4317, 0.4931]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 420\tAverage Score: 26.40\tScore: 17.75\tLossActor: -0.00132756 \tLossCritic : 0.00068838(tensor([[ 0.1332, -0.0946,  0.5288,  0.0011]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 421\tAverage Score: 26.64\tScore: 33.85\tLossActor: -0.00133742 \tLossCritic : 0.00068843(tensor([[ 0.0871, -0.2177, -0.3703, -0.3839]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3688, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 422\tAverage Score: 26.85\tScore: 38.81\tLossActor: -0.00136375 \tLossCritic : 0.00068758(tensor([[ 0.5231, -0.1415,  0.3041,  0.0405]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 423\tAverage Score: 26.90\tScore: 26.88\tLossActor: -0.00133001 \tLossCritic : 0.00068831(tensor([[ 0.0942, -0.1753, -0.3804, -0.3965]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 424\tAverage Score: 27.15\tScore: 36.35\tLossActor: -0.00135175 \tLossCritic : 0.00068825(tensor([[ 0.2008, -0.4337,  0.3211,  0.0172]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3691, 0.3689, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 425\tAverage Score: 27.33\tScore: 35.62\tLossActor: -0.00137751 \tLossCritic : 0.00068867(tensor([[-0.2983,  0.4262,  0.2461,  0.6454]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 426\tAverage Score: 27.57\tScore: 39.19\tLossActor: -0.00140930 \tLossCritic : 0.00068786(tensor([[ 0.1081, -0.2523, -0.2702, -0.2212]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 427\tAverage Score: 27.76\tScore: 37.76\tLossActor: -0.00142888 \tLossCritic : 0.00068721(tensor([[ 0.2335,  0.0872,  0.4047, -0.1128]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 428\tAverage Score: 27.93\tScore: 37.30\tLossActor: -0.00144752 \tLossCritic : 0.00068643(tensor([[-0.0499, -0.6548, -0.0159, -0.4786]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 429\tAverage Score: 27.96\tScore: 34.46\tLossActor: -0.00144341 \tLossCritic : 0.00068624(tensor([[-0.2547,  0.2236,  0.4028,  0.6632]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 430\tAverage Score: 28.06\tScore: 37.32\tLossActor: -0.00146685 \tLossCritic : 0.00068571(tensor([[ 0.2112, -0.2538,  0.3655, -0.0267]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3687, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 431\tAverage Score: 28.21\tScore: 38.39\tLossActor: -0.00149107 \tLossCritic : 0.00068496(tensor([[-0.2923,  0.4605,  0.3076, -0.0525]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 432\tAverage Score: 28.28\tScore: 36.36\tLossActor: -0.00150687 \tLossCritic : 0.00068432(tensor([[ 0.3454,  0.1760,  0.0407, -0.0947]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 433\tAverage Score: 28.60\tScore: 35.59\tLossActor: -0.00151138 \tLossCritic : 0.00068417(tensor([[ 0.2836, -0.4223,  0.0699, -0.0091]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 434\tAverage Score: 28.82\tScore: 38.74\tLossActor: -0.00153428 \tLossCritic : 0.00068320(tensor([[-0.4759,  0.4011, -0.1301, -0.1039]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 435\tAverage Score: 29.06\tScore: 36.13\tLossActor: -0.00154433 \tLossCritic : 0.00068276(tensor([[-0.1514, -0.1897, -0.2646,  0.3806]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 436\tAverage Score: 29.25\tScore: 37.16\tLossActor: -0.00156923 \tLossCritic : 0.00068231(tensor([[-0.2752,  0.4259, -0.0740,  0.2774]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 437\tAverage Score: 29.36\tScore: 38.29\tLossActor: -0.00158462 \tLossCritic : 0.00068159(tensor([[-0.1388,  0.4020,  0.1217,  0.2506]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3686, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 438\tAverage Score: 29.59\tScore: 33.86\tLossActor: -0.00158139 \tLossCritic : 0.00068147(tensor([[ 0.4459,  0.3053,  0.1757, -0.1843]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3689, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 439\tAverage Score: 29.85\tScore: 38.81\tLossActor: -0.00159976 \tLossCritic : 0.00068059(tensor([[ 0.2444,  0.1617,  0.1190, -0.1275]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 440\tAverage Score: 30.12\tScore: 38.89\tLossActor: -0.00161148 \tLossCritic : 0.00067981(tensor([[-0.1826,  0.3422, -0.3261,  0.5815]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3685, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 441\tAverage Score: 30.25\tScore: 22.89\tLossActor: -0.00155000 \tLossCritic : 0.00068155(tensor([[-0.3016,  0.2622, -0.2350,  0.0744]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3697, 0.3686, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 442\tAverage Score: 30.35\tScore: 28.95\tLossActor: -0.00152135 \tLossCritic : 0.00068204(tensor([[-0.1350, -0.2130,  0.1707,  0.1058]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 443\tAverage Score: 30.55\tScore: 29.16\tLossActor: -0.00149288 \tLossCritic : 0.00068263(tensor([[-0.3018,  0.1276, -0.2082,  0.3177]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3692, 0.3686, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 444\tAverage Score: 30.84\tScore: 37.01\tLossActor: -0.00149803 \tLossCritic : 0.00068201(tensor([[-0.2539,  0.3405,  0.1317,  0.4173]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3694, 0.3687, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 445\tAverage Score: 31.15\tScore: 39.17\tLossActor: -0.00152154 \tLossCritic : 0.00068137(tensor([[-0.4748, -0.1911, -0.3549, -0.1037]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3686, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 446\tAverage Score: 31.37\tScore: 30.13\tLossActor: -0.00149896 \tLossCritic : 0.00068207(tensor([[-0.2261, -0.5887, -0.1188, -0.0179]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3690, 0.3686, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 447\tAverage Score: 31.36\tScore: 23.67\tLossActor: -0.00145221 \tLossCritic : 0.00068337(tensor([[ 0.0074, -0.1195,  0.6548, -0.1781]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3683, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 448\tAverage Score: 31.43\tScore: 26.40\tLossActor: -0.00141921 \tLossCritic : 0.00068520(tensor([[-0.5829, -0.0535,  0.6554,  0.4056]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 449\tAverage Score: 31.62\tScore: 37.54\tLossActor: -0.00143784 \tLossCritic : 0.00068450(tensor([[-0.1349, -0.1976, -0.4284, -0.2695]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3691, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 450\tAverage Score: 31.78\tScore: 39.05\tLossActor: -0.00145711 \tLossCritic : 0.00068337(tensor([[ 0.6017, -0.0428,  0.4883, -0.0096]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 451\tAverage Score: 31.86\tScore: 34.69\tLossActor: -0.00145393 \tLossCritic : 0.00068340(tensor([[-0.1071, -0.1747, -0.3849,  0.4178]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 452\tAverage Score: 31.94\tScore: 31.16\tLossActor: -0.00144828 \tLossCritic : 0.00068406(tensor([[-0.2183,  0.1398, -0.3082,  0.6444]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 453\tAverage Score: 32.06\tScore: 34.69\tLossActor: -0.00145404 \tLossCritic : 0.00068380(tensor([[ 0.3583,  0.0073, -0.2123,  0.4851]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 454\tAverage Score: 32.17\tScore: 38.56\tLossActor: -0.00147358 \tLossCritic : 0.00068295(tensor([[ 0.0037,  0.2047, -0.1401,  0.3581]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 455\tAverage Score: 32.30\tScore: 28.22\tLossActor: -0.00143499 \tLossCritic : 0.00068330(tensor([[ 0.4234, -0.2593,  0.3388, -0.5643]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 456\tAverage Score: 32.38\tScore: 38.50\tLossActor: -0.00144774 \tLossCritic : 0.00068257(tensor([[-0.2518, -0.3511,  0.1469, -0.1642]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3689, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 457\tAverage Score: 32.57\tScore: 37.69\tLossActor: -0.00145331 \tLossCritic : 0.00068187(tensor([[-0.3220, -0.1248, -0.4944,  0.0271]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3692, 0.3694, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 458\tAverage Score: 32.85\tScore: 37.93\tLossActor: -0.00146935 \tLossCritic : 0.00068144(tensor([[0.2592, 0.1466, 0.5704, 0.4873]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 459\tAverage Score: 32.96\tScore: 37.69\tLossActor: -0.00147971 \tLossCritic : 0.00068075(tensor([[-0.0685, -0.3719,  0.3191, -0.4297]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3690, 0.3689, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 460\tAverage Score: 33.03\tScore: 38.64\tLossActor: -0.00149836 \tLossCritic : 0.00068007(tensor([[-0.1088,  0.0193, -0.4361,  0.0007]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 461\tAverage Score: 32.87\tScore: 20.40\tLossActor: -0.00140885 \tLossCritic : 0.00068116(tensor([[-0.2549, -0.1940, -0.2283,  0.4821]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3688, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 462\tAverage Score: 32.82\tScore: 31.63\tLossActor: -0.00139425 \tLossCritic : 0.00068116(tensor([[ 0.2509, -0.0265,  0.3432,  0.1425]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3687, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 463\tAverage Score: 32.93\tScore: 34.72\tLossActor: -0.00139520 \tLossCritic : 0.00068106(tensor([[ 0.0491, -0.3686,  0.1128, -0.3111]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3687, 0.3688, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 464\tAverage Score: 33.16\tScore: 34.79\tLossActor: -0.00139697 \tLossCritic : 0.00068112(tensor([[ 0.2419,  0.6294, -0.0067,  0.4951]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 465\tAverage Score: 33.19\tScore: 33.74\tLossActor: -0.00139922 \tLossCritic : 0.00068119(tensor([[0.3119, 0.1378, 0.6636, 0.0956]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3691, 0.3688, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 466\tAverage Score: 33.24\tScore: 37.58\tLossActor: -0.00141002 \tLossCritic : 0.00068107(tensor([[-0.0381,  0.0519,  0.3525,  0.6675]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 467\tAverage Score: 33.27\tScore: 39.07\tLossActor: -0.00143218 \tLossCritic : 0.00068036(tensor([[-0.0132, -0.1651, -0.5347, -0.2215]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3691, 0.3689, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 468\tAverage Score: 33.33\tScore: 34.62\tLossActor: -0.00143027 \tLossCritic : 0.00068032(tensor([[-0.0555, -0.2208, -0.1754, -0.3305]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3687, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 469\tAverage Score: 33.40\tScore: 38.61\tLossActor: -0.00144639 \tLossCritic : 0.00067963(tensor([[-0.0448,  0.3529, -0.5459,  0.6741]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 470\tAverage Score: 33.31\tScore: 28.80\tLossActor: -0.00140974 \tLossCritic : 0.00068020(tensor([[ 0.2269, -0.1908, -0.4717,  0.6537]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 471\tAverage Score: 33.32\tScore: 38.50\tLossActor: -0.00142275 \tLossCritic : 0.00067945(tensor([[-0.2814,  0.1279, -0.2819,  0.2436]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 472\tAverage Score: 33.34\tScore: 35.33\tLossActor: -0.00141866 \tLossCritic : 0.00067904(tensor([[ 0.4112,  0.1823,  0.3085, -0.2761]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 473\tAverage Score: 33.53\tScore: 37.06\tLossActor: -0.00141840 \tLossCritic : 0.00067852(tensor([[ 0.1273,  0.3028, -0.1366,  0.3085]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 474\tAverage Score: 33.56\tScore: 38.12\tLossActor: -0.00142964 \tLossCritic : 0.00067800(tensor([[ 0.1182,  0.4078, -0.4593, -0.0337]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3686, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 475\tAverage Score: 33.55\tScore: 22.72\tLossActor: -0.00136915 \tLossCritic : 0.00067916(tensor([[0.0813, 0.1238, 0.5368, 0.0832]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 476\tAverage Score: 33.61\tScore: 31.77\tLossActor: -0.00134347 \tLossCritic : 0.00067923(tensor([[ 0.1778, -0.0076, -0.2294,  0.0147]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3688, 0.3682, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 477\tAverage Score: 33.64\tScore: 39.33\tLossActor: -0.00135901 \tLossCritic : 0.00067834(tensor([[ 0.0019,  0.0801, -0.0217,  0.4736]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3688, 0.3682, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 478\tAverage Score: 33.67\tScore: 37.78\tLossActor: -0.00135985 \tLossCritic : 0.00067750(tensor([[0.3223, 0.0270, 0.5270, 0.7298]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3682, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 479\tAverage Score: 33.66\tScore: 36.89\tLossActor: -0.00136699 \tLossCritic : 0.00067673(tensor([[-0.1434, -0.5938, -0.1068,  0.0094]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3701, 0.3690, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 480\tAverage Score: 33.68\tScore: 27.60\tLossActor: -0.00131507 \tLossCritic : 0.00067738(tensor([[-0.2477, -0.2313,  0.0952,  0.1459]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 481\tAverage Score: 33.66\tScore: 30.56\tLossActor: -0.00129031 \tLossCritic : 0.00067757(tensor([[ 0.3325, -0.2148,  0.3465,  0.0932]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3689, 0.3684, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 482\tAverage Score: 33.60\tScore: 31.62\tLossActor: -0.00128176 \tLossCritic : 0.00067826(tensor([[ 0.3500, -0.0172,  0.4497, -0.6502]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3684, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 483\tAverage Score: 33.60\tScore: 32.03\tLossActor: -0.00126083 \tLossCritic : 0.00067860(tensor([[-0.0027,  0.1341,  0.0416,  0.0189]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3684, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 484\tAverage Score: 33.72\tScore: 32.91\tLossActor: -0.00124873 \tLossCritic : 0.00067897(tensor([[0.0457, 0.0348, 0.2939, 0.1773]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3686, 0.3684, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 485\tAverage Score: 33.72\tScore: 36.87\tLossActor: -0.00125279 \tLossCritic : 0.00067871(tensor([[ 0.1449, -0.1727, -0.1622, -0.2232]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3695, 0.3691, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 486\tAverage Score: 33.80\tScore: 38.85\tLossActor: -0.00127212 \tLossCritic : 0.00067819(tensor([[-0.2425, -0.0033,  0.0233, -0.4550]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3699, 0.3694, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 487\tAverage Score: 33.83\tScore: 38.27\tLossActor: -0.00128708 \tLossCritic : 0.00067753(tensor([[-0.0751,  0.6445, -0.2745, -0.0705]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3687, 0.3685, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 488\tAverage Score: 33.83\tScore: 35.41\tLossActor: -0.00128522 \tLossCritic : 0.00067715(tensor([[-0.2082, -0.1458, -0.1723,  0.0938]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3693, 0.3690, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 489\tAverage Score: 33.82\tScore: 38.17\tLossActor: -0.00129007 \tLossCritic : 0.00067628(tensor([[ 0.4329,  0.0796,  0.1950, -0.6203]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 490\tAverage Score: 33.56\tScore: 10.82\tLossActor: -0.00117577 \tLossCritic : 0.00067803(tensor([[ 0.3049, -0.3723, -0.6048, -0.4384]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3685, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 491\tAverage Score: 33.27\tScore: 9.18\tLossActor: -0.00104917 \tLossCritic : 0.00068167(tensor([[-0.2853,  0.0458,  0.2596,  0.2303]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3699, 0.3699, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 492\tAverage Score: 33.26\tScore: 19.32\tLossActor: -0.00097516 \tLossCritic : 0.00068431(tensor([[ 0.7738,  0.3266, -0.4005, -0.9755]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 493\tAverage Score: 33.20\tScore: 20.06\tLossActor: -0.00091324 \tLossCritic : 0.00068696(tensor([[ 0.0567, -0.1216, -0.6500, -0.6475]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3687, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 494\tAverage Score: 33.32\tScore: 33.82\tLossActor: -0.00090868 \tLossCritic : 0.00068694(tensor([[-0.0650,  0.2862, -0.3043,  0.5317]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3690, 0.3688, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 495\tAverage Score: 33.20\tScore: 9.51\tLossActor: -0.00082036 \tLossCritic : 0.00068910(tensor([[-0.2988,  0.6219, -0.4675, -0.4080]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3689, 0.3689, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 496\tAverage Score: 33.21\tScore: 27.69\tLossActor: -0.00080001 \tLossCritic : 0.00068948(tensor([[-0.0909, -0.1700, -0.5025, -0.1836]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3689, 0.3690, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 497\tAverage Score: 33.30\tScore: 32.77\tLossActor: -0.00079290 \tLossCritic : 0.00068970(tensor([[-0.4880, -0.2122,  0.1661, -0.0431]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3688, 0.3687, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 498\tAverage Score: 33.27\tScore: 30.29\tLossActor: -0.00078902 \tLossCritic : 0.00068966(tensor([[-0.1026,  0.0094, -0.3398, -0.4425]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3691, 0.3689, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 499\tAverage Score: 33.34\tScore: 32.51\tLossActor: -0.00076797 \tLossCritic : 0.00068948(tensor([[-0.0562, -0.3298, -0.5512,  0.0679]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3690, 0.3691, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 500\tAverage Score: 33.20\tScore: 22.08\tLossActor: -0.00072786 \tLossCritic : 0.00069066(tensor([[0.2015, 0.0450, 0.2787, 0.2203]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 500\tAverage Score: 33.20\n",
      "Episode 501\tAverage Score: 33.03\tScore: 21.82\tLossActor: -0.00069235 \tLossCritic : 0.00069157(tensor([[0.2922, 0.0838, 0.5369, 0.5960]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 502\tAverage Score: 32.99\tScore: 35.01\tLossActor: -0.00071059 \tLossCritic : 0.00069213(tensor([[-0.2346, -0.5025, -0.4042, -0.2363]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3689, 0.3689, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 503\tAverage Score: 32.97\tScore: 34.51\tLossActor: -0.00072867 \tLossCritic : 0.00069226(tensor([[ 0.2636, -0.0255, -0.0385,  0.4006]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 504\tAverage Score: 32.75\tScore: 16.83\tLossActor: -0.00063843 \tLossCritic : 0.00069342(tensor([[ 0.0446, -0.2495,  0.2348, -0.1792]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 505\tAverage Score: 32.56\tScore: 18.91\tLossActor: -0.00058500 \tLossCritic : 0.00069536(tensor([[ 0.3144, -0.1204,  0.6882, -0.1505]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 506\tAverage Score: 32.37\tScore: 18.71\tLossActor: -0.00054012 \tLossCritic : 0.00069681(tensor([[ 0.0401,  0.5715, -0.3518,  0.0662]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 507\tAverage Score: 32.14\tScore: 13.77\tLossActor: -0.00046475 \tLossCritic : 0.00069884(tensor([[-0.1864,  0.3501,  0.8280,  0.2079]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 508\tAverage Score: 32.20\tScore: 29.59\tLossActor: -0.00045225 \tLossCritic : 0.00069908(tensor([[ 0.1730,  0.1742,  0.0722, -0.6703]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3686, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 509\tAverage Score: 32.13\tScore: 26.33\tLossActor: -0.00044144 \tLossCritic : 0.00069944(tensor([[-0.0138,  0.1621, -0.1788,  0.1588]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 510\tAverage Score: 31.99\tScore: 14.62\tLossActor: -0.00037815 \tLossCritic : 0.00070054(tensor([[-0.0667,  0.2158, -0.3699, -0.4807]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3690, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 511\tAverage Score: 31.96\tScore: 32.71\tLossActor: -0.00039616 \tLossCritic : 0.00070068(tensor([[ 0.4602, -0.0280,  0.7559, -0.2829]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 512\tAverage Score: 31.96\tScore: 37.24\tLossActor: -0.00043128 \tLossCritic : 0.00070053(tensor([[-0.3956, -0.0906,  0.2315, -0.2747]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 513\tAverage Score: 32.06\tScore: 38.53\tLossActor: -0.00046992 \tLossCritic : 0.00070013(tensor([[-0.1715,  0.1888,  0.0654,  0.0808]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3686, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 514\tAverage Score: 32.11\tScore: 37.03\tLossActor: -0.00049227 \tLossCritic : 0.00069971(tensor([[ 0.0101,  0.0598,  0.4215, -0.1291]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 515\tAverage Score: 31.97\tScore: 23.91\tLossActor: -0.00044779 \tLossCritic : 0.00070017(tensor([[-0.7386,  0.1315, -0.5057,  0.4003]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3693, 0.3690, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 516\tAverage Score: 31.92\tScore: 33.93\tLossActor: -0.00045966 \tLossCritic : 0.00070083(tensor([[-0.1797, -0.0023, -0.0968, -0.4602]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3696, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 517\tAverage Score: 32.00\tScore: 31.84\tLossActor: -0.00045929 \tLossCritic : 0.00070104(tensor([[-0.2857, -0.2112, -0.1947, -0.2082]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3704, 0.3693, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 518\tAverage Score: 32.00\tScore: 39.32\tLossActor: -0.00049343 \tLossCritic : 0.00070058(tensor([[-0.5850,  0.0605, -0.0764, -0.1933]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3689, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 519\tAverage Score: 32.04\tScore: 37.99\tLossActor: -0.00051622 \tLossCritic : 0.00070007(tensor([[0.6187, 0.0840, 0.3401, 0.0735]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3686, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 520\tAverage Score: 32.21\tScore: 35.47\tLossActor: -0.00053392 \tLossCritic : 0.00070001(tensor([[ 0.0581, -0.1093, -0.0246,  0.0057]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3686, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 521\tAverage Score: 32.26\tScore: 38.26\tLossActor: -0.00055527 \tLossCritic : 0.00069920(tensor([[ 0.0099, -0.3047, -0.4423, -0.1408]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3693, 0.3688, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 522\tAverage Score: 32.25\tScore: 38.45\tLossActor: -0.00058500 \tLossCritic : 0.00069852(tensor([[0.6595, 0.1316, 0.5703, 0.3020]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 523\tAverage Score: 32.36\tScore: 37.79\tLossActor: -0.00060671 \tLossCritic : 0.00069792(tensor([[ 0.2321,  0.1549,  0.2723, -0.5263]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3685, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 524\tAverage Score: 32.39\tScore: 39.38\tLossActor: -0.00063341 \tLossCritic : 0.00069699(tensor([[0.0408, 0.5659, 0.1199, 0.3932]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3686, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 525\tAverage Score: 32.30\tScore: 25.94\tLossActor: -0.00059622 \tLossCritic : 0.00069731(tensor([[ 0.0401, -0.2046, -0.4435, -0.5460]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 526\tAverage Score: 32.28\tScore: 37.87\tLossActor: -0.00060691 \tLossCritic : 0.00069665(tensor([[-0.0535,  0.8533,  0.4037, -0.0912]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 527\tAverage Score: 32.21\tScore: 30.02\tLossActor: -0.00059102 \tLossCritic : 0.00069648(tensor([[-0.4219, -0.0509,  0.4036, -0.5652]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3691, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 528\tAverage Score: 32.14\tScore: 31.11\tLossActor: -0.00058701 \tLossCritic : 0.00069656(tensor([[-0.2061, -0.3869,  0.3886, -0.2837]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 529\tAverage Score: 32.19\tScore: 39.04\tLossActor: -0.00060893 \tLossCritic : 0.00069576(tensor([[-0.2097, -0.3973, -0.0643, -0.0603]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 530\tAverage Score: 32.20\tScore: 38.06\tLossActor: -0.00061571 \tLossCritic : 0.00069550(tensor([[-0.1565, -0.1273, -0.1977, -0.5785]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3693, 0.3690, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 531\tAverage Score: 32.11\tScore: 29.20\tLossActor: -0.00059442 \tLossCritic : 0.00069592(tensor([[ 0.0051,  0.3282, -0.1986,  0.5535]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3685, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 532\tAverage Score: 32.06\tScore: 31.57\tLossActor: -0.00058149 \tLossCritic : 0.00069576(tensor([[-0.4967, -0.0320,  0.7341, -0.3072]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3689, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 533\tAverage Score: 31.79\tScore: 8.47\tLossActor: -0.00047829 \tLossCritic : 0.00069780(tensor([[ 0.0198,  0.0024, -0.3692,  0.2546]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 534\tAverage Score: 31.73\tScore: 32.61\tLossActor: -0.00047225 \tLossCritic : 0.00069840(tensor([[-0.2449,  0.3482, -0.4042,  0.3181]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3685, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 535\tAverage Score: 31.70\tScore: 34.01\tLossActor: -0.00048117 \tLossCritic : 0.00069846(tensor([[0.3412, 0.3664, 0.4495, 0.3145]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 536\tAverage Score: 31.68\tScore: 34.82\tLossActor: -0.00050680 \tLossCritic : 0.00069865(tensor([[ 0.1565, -0.1771,  0.1686, -0.3978]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 537\tAverage Score: 31.69\tScore: 38.91\tLossActor: -0.00053213 \tLossCritic : 0.00069810(tensor([[-0.1460,  0.1303,  0.0040,  0.0392]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3686, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 538\tAverage Score: 31.66\tScore: 31.63\tLossActor: -0.00052863 \tLossCritic : 0.00069833(tensor([[ 0.1063, -0.0023, -0.6187, -0.4346]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 539\tAverage Score: 31.66\tScore: 38.78\tLossActor: -0.00054549 \tLossCritic : 0.00069774(tensor([[-0.0296, -0.0475, -0.0791, -0.1191]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3686, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 540\tAverage Score: 31.56\tScore: 28.39\tLossActor: -0.00053032 \tLossCritic : 0.00069841(tensor([[ 0.4778, -0.2759, -0.0763,  0.5095]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 541\tAverage Score: 31.60\tScore: 26.79\tLossActor: -0.00050607 \tLossCritic : 0.00069916(tensor([[0.2958, 0.1119, 0.4936, 0.1909]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 542\tAverage Score: 31.56\tScore: 25.53\tLossActor: -0.00047327 \tLossCritic : 0.00069978(tensor([[-0.1637, -0.0998, -0.1318,  0.1701]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 543\tAverage Score: 31.65\tScore: 37.54\tLossActor: -0.00049540 \tLossCritic : 0.00069964(tensor([[-0.1605, -0.4803,  0.4201, -0.2078]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3700, 0.3692, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 544\tAverage Score: 31.66\tScore: 38.50\tLossActor: -0.00051751 \tLossCritic : 0.00069912(tensor([[ 0.2139,  0.5262, -0.0939,  0.0360]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3687, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 545\tAverage Score: 31.66\tScore: 39.40\tLossActor: -0.00053382 \tLossCritic : 0.00069858(tensor([[-0.3607, -0.2006, -0.0517,  0.3800]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3700, 0.3692, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 546\tAverage Score: 31.70\tScore: 33.42\tLossActor: -0.00052864 \tLossCritic : 0.00069903(tensor([[-0.0094, -0.2984, -0.3997, -0.5122]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3694, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 547\tAverage Score: 31.80\tScore: 33.66\tLossActor: -0.00052152 \tLossCritic : 0.00069917(tensor([[ 0.0220, -0.4024,  0.0294,  0.1671]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 548\tAverage Score: 31.87\tScore: 33.61\tLossActor: -0.00052414 \tLossCritic : 0.00069955(tensor([[-0.1494, -0.4949,  0.1963,  0.4103]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3695, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 549\tAverage Score: 31.88\tScore: 38.27\tLossActor: -0.00053753 \tLossCritic : 0.00069894(tensor([[-0.0647,  0.1978,  0.2161, -0.1093]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3689, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 550\tAverage Score: 31.87\tScore: 38.83\tLossActor: -0.00055262 \tLossCritic : 0.00069842(tensor([[ 0.1608, -0.2019, -0.3288,  0.0235]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3701, 0.3694, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 551\tAverage Score: 31.88\tScore: 35.03\tLossActor: -0.00054148 \tLossCritic : 0.00069821(tensor([[0.4386, 0.1283, 0.7592, 0.3875]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3686, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 552\tAverage Score: 31.81\tScore: 24.68\tLossActor: -0.00051249 \tLossCritic : 0.00069928(tensor([[-0.4199, -0.0254, -0.5890, -0.7462]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 553\tAverage Score: 31.81\tScore: 34.49\tLossActor: -0.00051942 \tLossCritic : 0.00069919(tensor([[-0.1145,  0.0028, -0.4690,  0.0180]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3698, 0.3690, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 554\tAverage Score: 31.79\tScore: 36.19\tLossActor: -0.00051830 \tLossCritic : 0.00069917(tensor([[-0.1170,  0.5161,  0.2497, -0.2097]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3686, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 555\tAverage Score: 31.77\tScore: 26.17\tLossActor: -0.00048288 \tLossCritic : 0.00070041(tensor([[ 0.2742,  0.3401, -0.6816,  0.8165]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3687, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 556\tAverage Score: 31.64\tScore: 25.50\tLossActor: -0.00044919 \tLossCritic : 0.00070205(tensor([[-0.4578,  0.1921, -0.6081, -0.6109]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 557\tAverage Score: 31.47\tScore: 21.44\tLossActor: -0.00040319 \tLossCritic : 0.00070435(tensor([[-0.0898, -0.4343,  0.5673, -0.1266]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3684, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 558\tAverage Score: 31.29\tScore: 19.83\tLossActor: -0.00031173 \tLossCritic : 0.00070585(tensor([[0.3827, 0.0330, 0.2996, 0.1617]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3689, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 559\tAverage Score: 31.03\tScore: 11.80\tLossActor: -0.00021953 \tLossCritic : 0.00070897(tensor([[ 0.0562, -0.0553, -0.0846,  0.2602]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3691, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 560\tAverage Score: 30.75\tScore: 10.19\tLossActor: -0.00014272 \tLossCritic : 0.00071174(tensor([[-0.7475,  0.5899,  0.9422, -0.9725]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3684, 0.3680, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 561\tAverage Score: 30.74\tScore: 19.08\tLossActor: -0.00009590 \tLossCritic : 0.00071346(tensor([[ 0.0688,  0.6036, -0.5484,  0.4289]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3689, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 562\tAverage Score: 30.61\tScore: 18.81\tLossActor: -0.00005803 \tLossCritic : 0.00071516(tensor([[-0.0241, -0.3503,  0.0180, -0.1738]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3698, 0.3690, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 563\tAverage Score: 30.55\tScore: 29.11\tLossActor: -0.00005733 \tLossCritic : 0.00071549(tensor([[ 0.4096,  0.2035,  0.1463, -0.0362]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3687, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 564\tAverage Score: 30.52\tScore: 31.03\tLossActor: -0.00006554 \tLossCritic : 0.00071582(tensor([[-0.1209, -0.2978,  0.3118, -0.0925]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3700, 0.3691, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 565\tAverage Score: 30.44\tScore: 25.79\tLossActor: -0.00005396 \tLossCritic : 0.00071700(tensor([[-0.5275, -0.0799,  0.2081,  0.6028]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3683, 0.3681, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 566\tAverage Score: 30.41\tScore: 35.40\tLossActor: -0.00007614 \tLossCritic : 0.00071707(tensor([[ 0.2884, -0.5176, -0.2368, -0.3844]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3683, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 567\tAverage Score: 30.38\tScore: 35.67\tLossActor: -0.00010215 \tLossCritic : 0.00071734(tensor([[-0.1654,  0.2977,  0.1513,  0.3512]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3687, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 568\tAverage Score: 30.16\tScore: 12.55\tLossActor: -0.00002529 \tLossCritic : 0.00071913(tensor([[ 0.0265, -0.2424,  0.6168,  0.0750]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3680, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 569\tAverage Score: 30.13\tScore: 35.81\tLossActor: -0.00004822 \tLossCritic : 0.00071937(tensor([[ 0.1609, -0.2657,  0.6072, -0.3871]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3696, 0.3691, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 570\tAverage Score: 30.01\tScore: 17.03\tLossActor: 0.00001752 \tLossCritic : 0.00072064(tensor([[-0.0972, -0.3112, -0.4981,  0.4531]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 571\tAverage Score: 29.97\tScore: 34.41\tLossActor: 0.00000143 \tLossCritic : 0.00072089(tensor([[-0.0103,  0.0630, -0.2805,  0.0968]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3688, 0.3687, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 572\tAverage Score: 29.93\tScore: 30.81\tLossActor: 0.00000305 \tLossCritic : 0.00072104(tensor([[0.3504, 0.1301, 0.3767, 0.3705]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3680, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 573\tAverage Score: 29.95\tScore: 39.01\tLossActor: -0.00002394 \tLossCritic : 0.00072047(tensor([[-0.0390,  0.2033,  0.1023,  0.0870]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3687, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 574\tAverage Score: 29.96\tScore: 39.21\tLossActor: -0.00005651 \tLossCritic : 0.00072013(tensor([[ 0.2503, -0.1796, -0.1443, -0.2786]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3691, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 575\tAverage Score: 30.06\tScore: 32.72\tLossActor: -0.00006153 \tLossCritic : 0.00072007(tensor([[-0.0988,  0.4023, -0.4581, -0.1163]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3686, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 576\tAverage Score: 30.13\tScore: 39.07\tLossActor: -0.00008947 \tLossCritic : 0.00071940(tensor([[ 0.1436, -0.1960,  0.2875, -0.2209]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 577\tAverage Score: 30.06\tScore: 32.62\tLossActor: -0.00004299 \tLossCritic : 0.00071972(tensor([[-0.2561, -0.4363, -0.9199,  0.3468]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 578\tAverage Score: 29.83\tScore: 14.14\tLossActor: 0.00004403 \tLossCritic : 0.00072191(tensor([[ 0.1957, -0.3781, -0.2141, -0.2014]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3689, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 579\tAverage Score: 29.60\tScore: 13.79\tLossActor: 0.00010131 \tLossCritic : 0.00072512(tensor([[-0.6679,  0.1744,  0.4492,  0.4370]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 580\tAverage Score: 29.59\tScore: 27.07\tLossActor: 0.00011238 \tLossCritic : 0.00072636(tensor([[-0.3420, -0.3557,  0.1785, -0.5663]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3693, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 581\tAverage Score: 29.63\tScore: 34.76\tLossActor: 0.00010163 \tLossCritic : 0.00072688(tensor([[ 0.4850,  0.7407, -0.6169,  0.5438]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 582\tAverage Score: 29.56\tScore: 23.86\tLossActor: 0.00011686 \tLossCritic : 0.00072832(tensor([[-0.0710,  0.1366, -0.2242, -0.0502]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3686, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 583\tAverage Score: 29.52\tScore: 28.97\tLossActor: 0.00012150 \tLossCritic : 0.00072888(tensor([[ 0.2579,  0.3767, -0.5894,  0.7440]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3683, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 584\tAverage Score: 29.49\tScore: 29.29\tLossActor: 0.00011991 \tLossCritic : 0.00072915(tensor([[ 0.0271, -0.0542,  0.7682, -0.3412]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3683, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 585\tAverage Score: 29.44\tScore: 31.73\tLossActor: 0.00012430 \tLossCritic : 0.00072948(tensor([[ 0.2437, -0.0639,  0.0459, -0.0016]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3688, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 586\tAverage Score: 29.39\tScore: 34.09\tLossActor: 0.00010880 \tLossCritic : 0.00072960(tensor([[-0.2318, -0.1170, -0.3893,  0.3683]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3683, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 587\tAverage Score: 29.22\tScore: 21.43\tLossActor: 0.00014435 \tLossCritic : 0.00073039(tensor([[-0.1156, -0.0197, -0.7752,  0.4094]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 588\tAverage Score: 29.26\tScore: 39.07\tLossActor: 0.00011353 \tLossCritic : 0.00072973(tensor([[ 0.1831,  0.4950, -0.3027, -0.0183]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3690, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 589\tAverage Score: 29.26\tScore: 38.04\tLossActor: 0.00008395 \tLossCritic : 0.00072914(tensor([[-0.1721,  0.4087,  0.5328,  0.0696]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3684, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 590\tAverage Score: 29.51\tScore: 36.17\tLossActor: 0.00006702 \tLossCritic : 0.00072876(tensor([[-0.2789,  0.2164,  0.1157, -0.1131]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 591\tAverage Score: 29.81\tScore: 39.25\tLossActor: 0.00003689 \tLossCritic : 0.00072800(tensor([[4.6741e-01, 7.5388e-02, 2.0301e-04, 2.7492e-01]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 592\tAverage Score: 29.95\tScore: 32.99\tLossActor: 0.00003494 \tLossCritic : 0.00072782(tensor([[ 0.0415, -0.2657,  0.1285,  0.2911]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 593\tAverage Score: 30.13\tScore: 38.35\tLossActor: -0.00000187 \tLossCritic : 0.00072743(tensor([[-0.2328, -0.1214, -0.0279,  0.3709]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3694, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 594\tAverage Score: 30.07\tScore: 27.85\tLossActor: 0.00004159 \tLossCritic : 0.00072793(tensor([[ 0.1301, -0.5363,  0.4267, -0.3283]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 595\tAverage Score: 30.17\tScore: 19.43\tLossActor: 0.00006506 \tLossCritic : 0.00072903(tensor([[-0.3000, -0.2183, -0.0152,  0.3118]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 596\tAverage Score: 30.01\tScore: 12.01\tLossActor: 0.00086914 \tLossCritic : 0.00073093(tensor([[ 0.4073, -0.3056, -0.4348,  0.1657]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 597\tAverage Score: 29.71\tScore: 2.76\tLossActor: 0.00098068 \tLossCritic : 0.00073379(tensor([[ 0.9199,  0.2542, -0.7726, -0.8597]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3679, 0.3679, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 598\tAverage Score: 29.47\tScore: 5.59\tLossActor: 0.00107931 \tLossCritic : 0.00073592(tensor([[ 0.1324, -0.3569, -0.5827,  0.7361]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 599\tAverage Score: 29.31\tScore: 16.91\tLossActor: 0.00110955 \tLossCritic : 0.00073725(tensor([[-0.1615, -0.2751, -0.2909, -0.0548]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3695, 0.3692, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 600\tAverage Score: 29.28\tScore: 18.61\tLossActor: 0.00116964 \tLossCritic : 0.00073823(tensor([[ 0.2748, -0.6225,  0.2661,  0.6043]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3686, 0.3685, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 600\tAverage Score: 29.28\n",
      "Episode 601\tAverage Score: 29.27\tScore: 21.03\tLossActor: 0.00119618 \tLossCritic : 0.00073950(tensor([[-0.0879,  0.3104,  0.2199,  0.0665]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3687, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 602\tAverage Score: 29.16\tScore: 24.10\tLossActor: 0.00120737 \tLossCritic : 0.00073979(tensor([[ 0.0114, -0.5802,  0.1834, -0.1269]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3690, 0.3688, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 603\tAverage Score: 28.96\tScore: 15.09\tLossActor: 0.00124993 \tLossCritic : 0.00074032(tensor([[ 0.1243, -0.1606, -0.1486, -0.3041]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3681, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 604\tAverage Score: 29.02\tScore: 22.35\tLossActor: 0.00125889 \tLossCritic : 0.00074109(tensor([[0.0828, 0.0867, 0.6473, 0.0924]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 605\tAverage Score: 29.20\tScore: 37.32\tLossActor: 0.00121852 \tLossCritic : 0.00074092(tensor([[-0.5181, -0.0146, -0.0238, -0.1484]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 606\tAverage Score: 29.10\tScore: 8.33\tLossActor: 0.00128258 \tLossCritic : 0.00074159(tensor([[ 0.4352, -0.4166,  0.2015,  0.4658]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3688, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 607\tAverage Score: 29.34\tScore: 37.91\tLossActor: 0.00125371 \tLossCritic : 0.00074090(tensor([[-0.1513,  0.1789,  0.5191, -0.0855]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 608\tAverage Score: 29.35\tScore: 30.74\tLossActor: 0.00123852 \tLossCritic : 0.00074113(tensor([[ 0.1932,  0.0144,  0.6890, -0.3568]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 609\tAverage Score: 29.45\tScore: 36.53\tLossActor: 0.00120828 \tLossCritic : 0.00074084(tensor([[-0.1401,  0.5860, -0.3924,  0.3298]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 610\tAverage Score: 29.70\tScore: 39.06\tLossActor: 0.00116899 \tLossCritic : 0.00074026(tensor([[-0.1847,  0.2125,  0.0884,  0.0929]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 611\tAverage Score: 29.71\tScore: 33.48\tLossActor: 0.00115085 \tLossCritic : 0.00074019(tensor([[ 0.2579, -0.3022, -0.0595, -0.1171]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3693, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 612\tAverage Score: 29.72\tScore: 38.94\tLossActor: 0.00110970 \tLossCritic : 0.00073968(tensor([[ 3.2821e-01,  1.0784e-02, -1.3189e-04,  6.1994e-02]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 613\tAverage Score: 29.72\tScore: 38.46\tLossActor: 0.00107791 \tLossCritic : 0.00073905(tensor([[-0.1452,  0.1222, -0.2459,  0.1519]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 614\tAverage Score: 29.68\tScore: 32.92\tLossActor: 0.00105904 \tLossCritic : 0.00073908(tensor([[-0.0808,  0.2314, -0.0169, -0.0046]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3696, 0.3691, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 615\tAverage Score: 29.82\tScore: 37.50\tLossActor: 0.00102967 \tLossCritic : 0.00073848(tensor([[0.6086, 0.1966, 0.1256, 0.2963]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 616\tAverage Score: 29.87\tScore: 39.20\tLossActor: 0.00099560 \tLossCritic : 0.00073780(tensor([[-0.5283,  0.2422, -0.2213,  0.2236]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3685, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 617\tAverage Score: 29.61\tScore: 5.51\tLossActor: 0.00109300 \tLossCritic : 0.00073857(tensor([[ 0.0823, -0.0101,  0.2574,  0.5122]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3684, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 618\tAverage Score: 29.34\tScore: 12.36\tLossActor: 0.00114204 \tLossCritic : 0.00073898(tensor([[-0.5080, -0.1871,  0.0650,  0.6058]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 619\tAverage Score: 29.24\tScore: 28.62\tLossActor: 0.00113805 \tLossCritic : 0.00073889(tensor([[-0.0502,  0.4454,  0.3226, -0.0503]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 620\tAverage Score: 29.15\tScore: 26.28\tLossActor: 0.00113939 \tLossCritic : 0.00073865(tensor([[ 0.3422, -0.3701, -0.4837, -0.0779]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3683, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 621\tAverage Score: 29.09\tScore: 32.55\tLossActor: 0.00112240 \tLossCritic : 0.00073839(tensor([[-0.3037,  0.1018, -0.5741, -0.1338]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 622\tAverage Score: 28.99\tScore: 27.92\tLossActor: 0.00113387 \tLossCritic : 0.00073811(tensor([[ 0.2914,  0.1243,  0.2551, -0.1636]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 623\tAverage Score: 28.92\tScore: 31.18\tLossActor: 0.00112992 \tLossCritic : 0.00073818(tensor([[-0.3992,  0.2809, -0.3085,  0.1059]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3686, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 624\tAverage Score: 28.88\tScore: 34.73\tLossActor: 0.00113022 \tLossCritic : 0.00073803(tensor([[-0.1874, -0.3230, -0.3485, -0.4454]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3684, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 625\tAverage Score: 28.95\tScore: 33.20\tLossActor: 0.00111729 \tLossCritic : 0.00073800(tensor([[-0.2755,  0.5575, -0.0937, -0.1999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3686, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 626\tAverage Score: 28.92\tScore: 35.27\tLossActor: 0.00110301 \tLossCritic : 0.00073800(tensor([[ 0.0336,  0.2949, -0.3999, -0.5076]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3687, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 627\tAverage Score: 29.01\tScore: 38.85\tLossActor: 0.00107664 \tLossCritic : 0.00073735(tensor([[0.0221, 0.4433, 0.1167, 0.1040]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3687, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 628\tAverage Score: 29.06\tScore: 36.08\tLossActor: 0.00105872 \tLossCritic : 0.00073678(tensor([[-0.5101, -0.1774, -0.4376, -0.0172]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 629\tAverage Score: 29.03\tScore: 35.47\tLossActor: 0.00103568 \tLossCritic : 0.00073662(tensor([[ 0.0506,  0.0305, -0.5182,  0.0044]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3691, 0.3690, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 630\tAverage Score: 29.03\tScore: 38.12\tLossActor: 0.00101383 \tLossCritic : 0.00073608(tensor([[-0.0161,  0.0295,  0.0188,  0.7126]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3688, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 631\tAverage Score: 29.11\tScore: 37.78\tLossActor: 0.00098644 \tLossCritic : 0.00073558(tensor([[-0.0133, -0.3864, -0.4897,  0.0407]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3686, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 632\tAverage Score: 29.19\tScore: 39.17\tLossActor: 0.00096783 \tLossCritic : 0.00073465(tensor([[ 0.0341,  0.3266, -0.2277,  0.0584]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3689, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 633\tAverage Score: 29.49\tScore: 38.85\tLossActor: 0.00094016 \tLossCritic : 0.00073400(tensor([[ 0.1452, -0.3910, -0.4270,  0.1270]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3687, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 634\tAverage Score: 29.44\tScore: 27.79\tLossActor: 0.00094769 \tLossCritic : 0.00073412(tensor([[-0.1773, -0.2412, -0.3352, -0.4615]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 635\tAverage Score: 29.45\tScore: 34.81\tLossActor: 0.00094217 \tLossCritic : 0.00073375(tensor([[-0.1485, -0.1896,  0.4308,  0.3236]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3696, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 636\tAverage Score: 29.35\tScore: 24.76\tLossActor: 0.00099564 \tLossCritic : 0.00073418(tensor([[-0.0664, -0.1850, -0.3741, -0.4800]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3681, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 637\tAverage Score: 29.16\tScore: 19.54\tLossActor: 0.00103835 \tLossCritic : 0.00073471(tensor([[ 0.4245, -0.1722,  0.0648,  0.8087]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 638\tAverage Score: 29.11\tScore: 27.36\tLossActor: 0.00104691 \tLossCritic : 0.00073448(tensor([[ 0.3062, -0.1461, -0.0786, -0.5391]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 639\tAverage Score: 29.02\tScore: 29.67\tLossActor: 0.00104961 \tLossCritic : 0.00073410(tensor([[ 0.0113, -0.3000, -0.4275, -0.3370]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3686, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 640\tAverage Score: 29.09\tScore: 35.38\tLossActor: 0.00103484 \tLossCritic : 0.00073372(tensor([[-0.1801,  0.4225,  0.3318,  0.0516]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3688, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 641\tAverage Score: 29.19\tScore: 36.02\tLossActor: 0.00101756 \tLossCritic : 0.00073321(tensor([[ 0.0011, -0.0182, -0.4491, -0.5603]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3687, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 642\tAverage Score: 29.31\tScore: 38.16\tLossActor: 0.00099238 \tLossCritic : 0.00073272(tensor([[-0.3280,  0.3101,  0.1651,  0.4527]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 643\tAverage Score: 29.32\tScore: 38.38\tLossActor: 0.00096657 \tLossCritic : 0.00073207(tensor([[-0.2598,  0.0756, -0.2835,  0.0825]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3695, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 644\tAverage Score: 29.33\tScore: 39.18\tLossActor: 0.00094360 \tLossCritic : 0.00073143(tensor([[-0.2325,  0.1612, -0.6391,  0.1894]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 645\tAverage Score: 29.27\tScore: 34.02\tLossActor: 0.00093953 \tLossCritic : 0.00073126(tensor([[-0.2319,  0.0015,  0.1872,  0.4179]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3695, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 646\tAverage Score: 29.33\tScore: 39.06\tLossActor: 0.00091887 \tLossCritic : 0.00073051(tensor([[-0.5404, -0.1909, -0.0560,  0.1215]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 647\tAverage Score: 29.39\tScore: 39.33\tLossActor: 0.00089373 \tLossCritic : 0.00072977(tensor([[ 0.0968, -0.0930,  0.5447,  0.1234]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 648\tAverage Score: 29.43\tScore: 37.56\tLossActor: 0.00088252 \tLossCritic : 0.00072942(tensor([[ 0.2245, -0.3786, -0.1583, -0.2998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 649\tAverage Score: 29.43\tScore: 39.07\tLossActor: 0.00086774 \tLossCritic : 0.00072862(tensor([[0.1953, 0.3703, 0.4660, 0.2736]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 650\tAverage Score: 29.40\tScore: 35.30\tLossActor: 0.00089210 \tLossCritic : 0.00072800(tensor([[-0.1078,  0.5470, -0.0773,  0.4215]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3688, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 651\tAverage Score: 29.43\tScore: 37.73\tLossActor: 0.00088048 \tLossCritic : 0.00072745(tensor([[ 0.2285,  0.3988,  0.2481, -0.1399]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 652\tAverage Score: 29.46\tScore: 28.20\tLossActor: 0.00092390 \tLossCritic : 0.00072764(tensor([[-0.3281,  0.1384, -0.3428,  0.0052]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 653\tAverage Score: 29.33\tScore: 21.81\tLossActor: 0.00097188 \tLossCritic : 0.00072802(tensor([[-0.1748,  0.2582,  0.3248,  0.2726]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3691, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 654\tAverage Score: 29.31\tScore: 33.81\tLossActor: 0.00097090 \tLossCritic : 0.00072784(tensor([[-0.6583, -0.2022, -0.0020,  0.0719]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3687, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 655\tAverage Score: 29.41\tScore: 35.72\tLossActor: 0.00096896 \tLossCritic : 0.00072740(tensor([[-0.3984, -0.1004, -0.5216,  0.2685]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3688, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 656\tAverage Score: 29.50\tScore: 35.20\tLossActor: 0.00095958 \tLossCritic : 0.00072705(tensor([[-0.3607,  0.2415, -0.4371,  0.0448]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 657\tAverage Score: 29.66\tScore: 36.86\tLossActor: 0.00095027 \tLossCritic : 0.00072658(tensor([[ 0.0099, -0.3864, -0.3122,  0.1215]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3686, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 658\tAverage Score: 29.84\tScore: 38.25\tLossActor: 0.00093629 \tLossCritic : 0.00072601(tensor([[ 0.0743, -0.5633,  0.3535,  0.2670]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3683, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 659\tAverage Score: 30.12\tScore: 39.18\tLossActor: 0.00091899 \tLossCritic : 0.00072519(tensor([[-0.0247, -0.3899,  0.3946, -0.5606]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3683, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 660\tAverage Score: 30.37\tScore: 35.98\tLossActor: 0.00090990 \tLossCritic : 0.00072475(tensor([[ 0.1022,  0.2767,  0.1511, -0.0080]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3682, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 661\tAverage Score: 30.57\tScore: 39.19\tLossActor: 0.00088951 \tLossCritic : 0.00072388(tensor([[-0.0828, -0.2952, -0.0289, -0.1049]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3691, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 662\tAverage Score: 30.78\tScore: 39.18\tLossActor: 0.00087257 \tLossCritic : 0.00072306(tensor([[-0.0993, -0.1355, -0.4270, -0.2442]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3689, 0.3687, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 663\tAverage Score: 30.88\tScore: 39.11\tLossActor: 0.00086093 \tLossCritic : 0.00072214(tensor([[0.0100, 0.3095, 0.4466, 0.0891]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 664\tAverage Score: 30.96\tScore: 39.33\tLossActor: 0.00084571 \tLossCritic : 0.00072125(tensor([[ 0.1060, -0.3075,  0.4658, -0.4105]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 665\tAverage Score: 31.10\tScore: 39.37\tLossActor: 0.00083086 \tLossCritic : 0.00072039(tensor([[ 0.0047, -0.1047,  0.0376, -0.4233]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3689, 0.3687, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 666\tAverage Score: 31.14\tScore: 39.39\tLossActor: 0.00081689 \tLossCritic : 0.00071947(tensor([[-0.2123,  0.0612, -0.1696,  0.1881]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 667\tAverage Score: 31.16\tScore: 38.47\tLossActor: 0.00080775 \tLossCritic : 0.00071856(tensor([[-0.1529,  0.1796, -0.0050,  0.3722]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 668\tAverage Score: 31.43\tScore: 38.61\tLossActor: 0.00080435 \tLossCritic : 0.00071780(tensor([[ 0.1174,  0.0990, -0.6570,  0.8533]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3686, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 669\tAverage Score: 31.27\tScore: 19.85\tLossActor: 0.00085247 \tLossCritic : 0.00071912(tensor([[ 0.6425, -0.0434,  0.4337, -0.7354]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3680, 0.3680]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 670\tAverage Score: 31.31\tScore: 21.80\tLossActor: 0.00091151 \tLossCritic : 0.00072013(tensor([[-0.1008, -0.0697, -0.8727, -0.2321]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3685, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 671\tAverage Score: 31.18\tScore: 21.01\tLossActor: 0.00097400 \tLossCritic : 0.00072097(tensor([[ 0.3528,  0.0084,  0.4284, -0.2734]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3684, 0.3687, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 672\tAverage Score: 31.19\tScore: 32.01\tLossActor: 0.00097588 \tLossCritic : 0.00072106(tensor([[-0.1043,  0.1900,  0.1464,  0.1249]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3682, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 673\tAverage Score: 31.15\tScore: 34.85\tLossActor: 0.00097239 \tLossCritic : 0.00072104(tensor([[-0.2185,  0.0444,  0.5465,  0.1480]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3681, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 674\tAverage Score: 31.13\tScore: 37.17\tLossActor: 0.00095921 \tLossCritic : 0.00072069(tensor([[-0.4394, -0.0070, -0.0914,  0.6566]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3682, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 675\tAverage Score: 31.19\tScore: 38.85\tLossActor: 0.00094262 \tLossCritic : 0.00072003(tensor([[-0.5538, -0.2255,  0.2070, -0.4169]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3685, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 676\tAverage Score: 31.18\tScore: 38.18\tLossActor: 0.00094023 \tLossCritic : 0.00071943(tensor([[-0.0919,  0.4034, -0.1288,  0.2088]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3686, 0.3688, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 677\tAverage Score: 31.18\tScore: 32.12\tLossActor: 0.00095159 \tLossCritic : 0.00071949(tensor([[-0.1255,  0.0072, -0.1003,  0.2727]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3682, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 678\tAverage Score: 31.23\tScore: 19.78\tLossActor: 0.00099783 \tLossCritic : 0.00072011(tensor([[ 0.0611, -0.2268,  0.5654, -0.2926]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3682, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 679\tAverage Score: 31.49\tScore: 39.40\tLossActor: 0.00101829 \tLossCritic : 0.00071945(tensor([[-0.1352,  0.3751, -0.3391, -0.1970]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3687, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 680\tAverage Score: 31.48\tScore: 26.30\tLossActor: 0.00104754 \tLossCritic : 0.00071974(tensor([[-0.1513, -0.1971, -0.6618,  0.2053]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3690, 0.3696, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 681\tAverage Score: 31.34\tScore: 20.48\tLossActor: 0.00108939 \tLossCritic : 0.00072062(tensor([[ 0.0006,  0.1700,  0.4416, -0.1639]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3688, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 682\tAverage Score: 31.22\tScore: 12.01\tLossActor: 0.00117387 \tLossCritic : 0.00072229(tensor([[-0.0088, -0.4719,  0.1537, -0.1880]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3681, 0.3684, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 683\tAverage Score: 31.09\tScore: 15.95\tLossActor: 0.00122594 \tLossCritic : 0.00072349(tensor([[0.1642, 0.0138, 0.2925, 0.8059]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3692, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 684\tAverage Score: 31.14\tScore: 34.73\tLossActor: 0.00121788 \tLossCritic : 0.00072367(tensor([[-0.3498, -0.4975, -0.4082,  0.5785]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3694, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 685\tAverage Score: 31.17\tScore: 33.91\tLossActor: 0.00120778 \tLossCritic : 0.00072382(tensor([[0.0202, 0.0339, 0.5743, 0.1643]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3689, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 686\tAverage Score: 31.20\tScore: 37.37\tLossActor: 0.00118855 \tLossCritic : 0.00072354(tensor([[ 0.1613, -0.0129,  0.5936, -0.2058]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3687, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 687\tAverage Score: 31.36\tScore: 37.18\tLossActor: 0.00117488 \tLossCritic : 0.00072320(tensor([[-0.2077, -0.0682, -0.3872, -0.0998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3693, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 688\tAverage Score: 31.36\tScore: 39.42\tLossActor: 0.00115266 \tLossCritic : 0.00072252(tensor([[-0.5233, -0.5718, -0.1446,  0.0313]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3688, 0.3694, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 689\tAverage Score: 31.37\tScore: 38.73\tLossActor: 0.00113638 \tLossCritic : 0.00072177(tensor([[-0.2492, -0.4506, -0.1569,  0.0937]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3690, 0.3696, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 690\tAverage Score: 31.40\tScore: 39.27\tLossActor: 0.00111701 \tLossCritic : 0.00072103(tensor([[ 0.0974, -0.5430,  0.2519, -0.0214]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3681, 0.3683, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 691\tAverage Score: 31.39\tScore: 38.16\tLossActor: 0.00110110 \tLossCritic : 0.00072035(tensor([[0.3594, 0.1092, 0.7218, 0.0956]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 692\tAverage Score: 31.45\tScore: 38.83\tLossActor: 0.00108350 \tLossCritic : 0.00071961(tensor([[ 0.2927, -0.1839,  0.1244, -0.4456]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 693\tAverage Score: 31.46\tScore: 39.46\tLossActor: 0.00107069 \tLossCritic : 0.00071879(tensor([[ 0.3196,  0.0714, -0.2713,  0.5174]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 694\tAverage Score: 31.57\tScore: 38.97\tLossActor: 0.00105548 \tLossCritic : 0.00071797(tensor([[ 0.1464,  0.4390, -0.2305,  0.0789]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 695\tAverage Score: 31.77\tScore: 39.23\tLossActor: 0.00104033 \tLossCritic : 0.00071714(tensor([[0.2895, 0.3786, 0.0041, 0.3215]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 696\tAverage Score: 31.87\tScore: 22.63\tLossActor: 0.00108089 \tLossCritic : 0.00071741(tensor([[-0.0712, -0.1136, -0.4989,  0.0838]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3683, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 697\tAverage Score: 32.22\tScore: 37.44\tLossActor: 0.00107525 \tLossCritic : 0.00071686(tensor([[-0.1199, -0.2773,  0.4516, -0.4986]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3681, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 698\tAverage Score: 32.54\tScore: 37.31\tLossActor: 0.00107610 \tLossCritic : 0.00071623(tensor([[-0.0932, -0.1315, -0.1139,  0.3511]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 699\tAverage Score: 32.56\tScore: 19.49\tLossActor: 0.00114829 \tLossCritic : 0.00071695(tensor([[ 0.1352,  0.1328,  0.0122, -0.6154]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3682, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 700\tAverage Score: 32.65\tScore: 27.45\tLossActor: 0.00116483 \tLossCritic : 0.00071714(tensor([[-0.1859,  0.0223, -0.0839, -0.2093]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3695, 0.3696, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 700\tAverage Score: 32.65\n",
      "Episode 701\tAverage Score: 32.82\tScore: 37.58\tLossActor: 0.00123739 \tLossCritic : 0.00071651(tensor([[0.3546, 0.1326, 0.8424, 0.0034]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3682, 0.3682, 0.3681]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 702\tAverage Score: 32.92\tScore: 34.99\tLossActor: 0.00123205 \tLossCritic : 0.00071640(tensor([[ 0.0389, -0.0341,  0.5614,  0.3044]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3685, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 703\tAverage Score: 33.16\tScore: 38.86\tLossActor: 0.00121782 \tLossCritic : 0.00071590(tensor([[ 0.5104, -0.1443,  0.4986,  0.0095]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 704\tAverage Score: 33.32\tScore: 38.37\tLossActor: 0.00121238 \tLossCritic : 0.00071517(tensor([[ 0.3255, -0.0692,  0.3024,  0.4002]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3684, 0.3686, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 705\tAverage Score: 33.34\tScore: 38.94\tLossActor: 0.00119876 \tLossCritic : 0.00071442(tensor([[ 0.0231, -0.0020, -0.2507,  0.4376]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3700, 0.3699, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 706\tAverage Score: 33.64\tScore: 38.03\tLossActor: 0.00119091 \tLossCritic : 0.00071367(tensor([[ 0.1758, -0.1201,  0.0798, -0.2974]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3696, 0.3697, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 707\tAverage Score: 33.65\tScore: 39.29\tLossActor: 0.00117658 \tLossCritic : 0.00071282(tensor([[-0.5977, -0.1332, -0.0387,  0.2069]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3694, 0.3692, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 708\tAverage Score: 33.71\tScore: 37.14\tLossActor: 0.00117135 \tLossCritic : 0.00071219(tensor([[ 0.1840, -0.1569,  0.3669, -0.1523]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3688, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 709\tAverage Score: 33.73\tScore: 37.83\tLossActor: 0.00116638 \tLossCritic : 0.00071156(tensor([[-0.1229,  0.1791, -0.1949,  0.7356]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3687, 0.3685, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 710\tAverage Score: 33.73\tScore: 39.46\tLossActor: 0.00115132 \tLossCritic : 0.00071074(tensor([[ 0.0859, -0.1553, -0.2767, -0.6428]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3686, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 711\tAverage Score: 33.78\tScore: 37.99\tLossActor: 0.00114235 \tLossCritic : 0.00071003(tensor([[-0.1628,  0.0156, -0.2092,  0.4135]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3690, 0.3687, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 712\tAverage Score: 33.77\tScore: 38.66\tLossActor: 0.00250032 \tLossCritic : 0.00070925(tensor([[ 0.7618, -0.0863,  0.9122,  0.6893]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 713\tAverage Score: 33.42\tScore: 3.10\tLossActor: 0.00267616 \tLossCritic : 0.00071134(tensor([[ 0.1988, -0.5483, -0.2374,  0.6926]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3691, 0.3686, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 714\tAverage Score: 33.15\tScore: 6.41\tLossActor: 0.00276534 \tLossCritic : 0.00071295(tensor([[ 0.3485, -0.3298, -0.7915, -0.3798]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3690, 0.3684, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 715\tAverage Score: 33.01\tScore: 23.07\tLossActor: 0.00279388 \tLossCritic : 0.00071337(tensor([[ 0.1564,  0.2209, -0.2423, -0.3604]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3713, 0.3698, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 716\tAverage Score: 32.83\tScore: 21.04\tLossActor: 0.00283367 \tLossCritic : 0.00071396(tensor([[-0.1282,  0.3374,  0.1133, -0.0218]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3699, 0.3690, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 717\tAverage Score: 33.02\tScore: 24.55\tLossActor: 0.00289401 \tLossCritic : 0.00071444(tensor([[-0.1709,  0.1557, -0.0424, -0.6550]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3713, 0.3693, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 718\tAverage Score: 33.18\tScore: 28.19\tLossActor: 0.00290590 \tLossCritic : 0.00071474(tensor([[-0.5137,  0.0158, -0.4941,  0.0821]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3717, 0.3693, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 719\tAverage Score: 33.01\tScore: 11.78\tLossActor: 0.00296780 \tLossCritic : 0.00071606(tensor([[ 0.2016,  0.2700, -0.1651, -0.1672]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3695, 0.3685, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 720\tAverage Score: 32.98\tScore: 23.58\tLossActor: 0.00299467 \tLossCritic : 0.00071642(tensor([[-0.1905, -0.4397,  0.0839, -0.0910]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3704, 0.3693, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 721\tAverage Score: 32.99\tScore: 33.78\tLossActor: 0.00298884 \tLossCritic : 0.00071635(tensor([[ 0.1114, -0.0395,  0.7849, -0.4771]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3697, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 722\tAverage Score: 33.02\tScore: 30.23\tLossActor: 0.00300786 \tLossCritic : 0.00071665(tensor([[-0.1384,  0.1096, -0.6341,  0.0915]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3695, 0.3686, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 723\tAverage Score: 32.96\tScore: 25.95\tLossActor: 0.00301274 \tLossCritic : 0.00071765(tensor([[-0.2808, -0.0802, -0.1214, -0.2483]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3702, 0.3688, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 724\tAverage Score: 32.97\tScore: 34.98\tLossActor: 0.00299828 \tLossCritic : 0.00071799(tensor([[-0.2899, -0.3149, -0.2248, -0.1310]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3705, 0.3691, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 725\tAverage Score: 32.78\tScore: 14.35\tLossActor: 0.00307341 \tLossCritic : 0.00071916(tensor([[ 0.4798, -0.4529, -0.9132, -0.8192]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3682, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 726\tAverage Score: 32.73\tScore: 30.03\tLossActor: 0.00311118 \tLossCritic : 0.00072005(tensor([[-0.1726,  0.2126, -0.5423, -0.6520]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3696, 0.3686, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 727\tAverage Score: 32.64\tScore: 30.07\tLossActor: 0.00310723 \tLossCritic : 0.00072059(tensor([[-0.0012, -0.2667,  0.4378, -0.5468]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 728\tAverage Score: 32.65\tScore: 36.87\tLossActor: 0.00308273 \tLossCritic : 0.00072044(tensor([[-0.3308, -0.6420,  0.5465, -0.1981]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3695, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 729\tAverage Score: 32.66\tScore: 36.96\tLossActor: 0.00306262 \tLossCritic : 0.00072030(tensor([[-0.4506, -0.2084,  0.6559, -0.4591]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3693, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 730\tAverage Score: 32.60\tScore: 31.90\tLossActor: 0.00306410 \tLossCritic : 0.00072078(tensor([[-0.0931, -0.2297,  0.2908, -0.4111]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3691, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 731\tAverage Score: 32.60\tScore: 38.38\tLossActor: 0.00304064 \tLossCritic : 0.00072032(tensor([[0.1659, 0.1247, 0.1292, 0.1494]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3687, 0.3684, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 732\tAverage Score: 32.60\tScore: 39.04\tLossActor: 0.00301537 \tLossCritic : 0.00071977(tensor([[-0.0456, -0.2416,  0.4602, -0.3206]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3692, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 733\tAverage Score: 32.61\tScore: 39.10\tLossActor: 0.00299382 \tLossCritic : 0.00071905(tensor([[-0.3042, -0.2355, -0.3205,  0.0038]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3704, 0.3694, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 734\tAverage Score: 32.72\tScore: 39.48\tLossActor: 0.00297127 \tLossCritic : 0.00071837(tensor([[ 0.1175,  0.3386, -0.3311, -0.0433]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3694, 0.3688, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 735\tAverage Score: 32.77\tScore: 39.50\tLossActor: 0.00294683 \tLossCritic : 0.00071772(tensor([[-0.1685,  0.0138, -0.5991, -0.2566]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3696, 0.3688, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 736\tAverage Score: 32.87\tScore: 34.51\tLossActor: 0.00295416 \tLossCritic : 0.00071737(tensor([[-0.2305,  0.2905, -0.2562,  0.3157]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3698, 0.3689, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 737\tAverage Score: 33.06\tScore: 38.57\tLossActor: 0.00293969 \tLossCritic : 0.00071686(tensor([[ 1.1094e-04, -4.5426e-01, -1.2458e-01,  1.3624e-01]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3696, 0.3689, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 738\tAverage Score: 33.16\tScore: 38.08\tLossActor: 0.00293951 \tLossCritic : 0.00071634(tensor([[0.5959, 0.1164, 0.1359, 0.1939]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3686, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 739\tAverage Score: 33.26\tScore: 39.45\tLossActor: 0.00291895 \tLossCritic : 0.00071566(tensor([[-0.5831, -0.3929, -0.3191,  0.4034]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3697, 0.3688, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 740\tAverage Score: 33.28\tScore: 36.72\tLossActor: 0.00290650 \tLossCritic : 0.00071526(tensor([[-0.3189,  0.1432,  0.2124, -0.2091]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3703, 0.3688, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 741\tAverage Score: 33.11\tScore: 19.41\tLossActor: 0.00295051 \tLossCritic : 0.00071625(tensor([[-0.3777, -0.2530,  0.1117, -0.1513]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3689, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 742\tAverage Score: 33.12\tScore: 39.51\tLossActor: 0.00293023 \tLossCritic : 0.00071553(tensor([[ 0.1484,  0.1753,  0.1549, -0.0108]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3695, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 743\tAverage Score: 33.13\tScore: 39.16\tLossActor: 0.00291175 \tLossCritic : 0.00071479(tensor([[0.2459, 0.2878, 0.1861, 0.5864]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 744\tAverage Score: 33.12\tScore: 37.72\tLossActor: 0.00289958 \tLossCritic : 0.00071421(tensor([[-0.1975, -0.3026, -0.4922, -0.5102]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3689, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 745\tAverage Score: 33.14\tScore: 36.24\tLossActor: 0.00289037 \tLossCritic : 0.00071385(tensor([[-0.1954, -0.1143, -0.4473, -0.6282]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3695, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 746\tAverage Score: 33.13\tScore: 38.31\tLossActor: 0.00287996 \tLossCritic : 0.00071330(tensor([[0.1117, 0.0033, 0.3569, 0.6357]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3690, 0.3686, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 747\tAverage Score: 33.12\tScore: 37.72\tLossActor: 0.00286708 \tLossCritic : 0.00071271(tensor([[ 0.0393, -0.2386, -0.1017, -0.1333]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3693, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 748\tAverage Score: 33.12\tScore: 37.62\tLossActor: 0.00285584 \tLossCritic : 0.00071220(tensor([[ 0.3022, -0.3608, -0.1635, -0.5471]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3692, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 749\tAverage Score: 33.11\tScore: 38.08\tLossActor: 0.00284626 \tLossCritic : 0.00071153(tensor([[ 0.4214,  0.2887, -0.5068,  0.1875]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3692, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 750\tAverage Score: 33.14\tScore: 39.09\tLossActor: 0.00283044 \tLossCritic : 0.00071081(tensor([[-0.0898,  0.0352,  0.2075, -0.0742]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3697, 0.3686, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 751\tAverage Score: 33.16\tScore: 39.09\tLossActor: 0.00281723 \tLossCritic : 0.00071007(tensor([[ 0.1180, -0.4579,  0.3235, -0.2516]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3684, 0.3681, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 752\tAverage Score: 33.26\tScore: 38.56\tLossActor: 0.00280522 \tLossCritic : 0.00070931(tensor([[ 0.2640, -0.4352,  0.0102, -0.2268]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3687, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 753\tAverage Score: 33.43\tScore: 38.63\tLossActor: 0.00279474 \tLossCritic : 0.00070852(tensor([[-0.0705,  0.2595,  0.1247,  0.2167]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3700, 0.3688, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 754\tAverage Score: 33.48\tScore: 39.20\tLossActor: 0.00278646 \tLossCritic : 0.00070774(tensor([[ 0.0073,  0.0606, -0.3762,  0.7841]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3695, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 755\tAverage Score: 33.52\tScore: 39.22\tLossActor: 0.00277476 \tLossCritic : 0.00070698(tensor([[ 0.0749, -0.0575,  0.6399, -0.0237]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3693, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 756\tAverage Score: 33.55\tScore: 38.03\tLossActor: 0.00276596 \tLossCritic : 0.00070631(tensor([[-0.3244,  0.2257, -0.1526,  0.3073]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3706, 0.3692, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 757\tAverage Score: 33.56\tScore: 38.42\tLossActor: 0.00275576 \tLossCritic : 0.00070558(tensor([[-0.2037, -0.1532, -0.3323, -0.0009]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3700, 0.3689, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 758\tAverage Score: 33.57\tScore: 38.83\tLossActor: 0.00274599 \tLossCritic : 0.00070497(tensor([[ 0.3981,  0.0261,  0.1680, -0.0540]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 759\tAverage Score: 33.56\tScore: 37.89\tLossActor: 0.00274069 \tLossCritic : 0.00070439(tensor([[0.1652, 0.4483, 0.1044, 0.3389]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3702, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 760\tAverage Score: 33.58\tScore: 38.72\tLossActor: 0.00273135 \tLossCritic : 0.00070360(tensor([[-0.2255,  0.2269, -0.1118,  0.3839]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3716, 0.3699, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 761\tAverage Score: 33.57\tScore: 38.28\tLossActor: 0.00272277 \tLossCritic : 0.00070291(tensor([[-0.1749, -0.1394, -0.4993, -0.7954]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 762\tAverage Score: 33.56\tScore: 37.93\tLossActor: 0.00271657 \tLossCritic : 0.00070231(tensor([[ 0.5404,  0.1379,  0.0718, -0.0412]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 763\tAverage Score: 33.54\tScore: 36.59\tLossActor: 0.00271222 \tLossCritic : 0.00070175(tensor([[-0.2735,  0.1339,  0.4036,  0.4000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3695, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 764\tAverage Score: 33.53\tScore: 38.66\tLossActor: 0.00270196 \tLossCritic : 0.00070105(tensor([[0.2401, 0.4026, 0.0990, 0.2862]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3695, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 765\tAverage Score: 33.53\tScore: 39.30\tLossActor: 0.00268978 \tLossCritic : 0.00070031(tensor([[-0.5179, -0.3613, -0.0097, -0.0638]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3700, 0.3690, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 766\tAverage Score: 33.49\tScore: 35.08\tLossActor: 0.00271478 \tLossCritic : 0.00069971(tensor([[-0.2715,  0.3501, -0.0150,  0.5930]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3706, 0.3689, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 767\tAverage Score: 33.33\tScore: 22.48\tLossActor: 0.00276065 \tLossCritic : 0.00069985(tensor([[0.1562, 0.1221, 0.6455, 0.6097]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3688, 0.3683, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 768\tAverage Score: 33.21\tScore: 26.94\tLossActor: 0.00278873 \tLossCritic : 0.00070053(tensor([[-0.5420,  0.0039,  0.1473,  0.1384]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3683, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 769\tAverage Score: 33.30\tScore: 28.85\tLossActor: 0.00280353 \tLossCritic : 0.00070058(tensor([[0.1374, 0.1800, 0.6028, 0.1356]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3681, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 770\tAverage Score: 33.47\tScore: 39.07\tLossActor: 0.00279235 \tLossCritic : 0.00070002(tensor([[-0.1059, -0.1866,  0.6482, -0.5708]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 771\tAverage Score: 33.62\tScore: 36.31\tLossActor: 0.00278997 \tLossCritic : 0.00069958(tensor([[ 0.0166,  0.3727, -0.3743,  0.3037]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3688, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 772\tAverage Score: 33.69\tScore: 38.61\tLossActor: 0.00277595 \tLossCritic : 0.00069891(tensor([[ 0.2507, -0.1195,  0.3262,  0.0569]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3689, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 773\tAverage Score: 33.68\tScore: 34.26\tLossActor: 0.00277991 \tLossCritic : 0.00069857(tensor([[-0.2559,  0.0330, -0.6877, -0.0461]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3691, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 774\tAverage Score: 33.70\tScore: 39.07\tLossActor: 0.00276876 \tLossCritic : 0.00069789(tensor([[-0.1819, -0.2661, -0.6068, -0.4390]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3685, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 775\tAverage Score: 33.69\tScore: 37.77\tLossActor: 0.00277328 \tLossCritic : 0.00069740(tensor([[0.3328, 0.3085, 0.7082, 0.1177]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3693, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 776\tAverage Score: 33.44\tScore: 12.91\tLossActor: 0.00286111 \tLossCritic : 0.00069873(tensor([[-0.4039,  0.5916, -0.3768, -0.3191]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3682, 0.3685, 0.3682, 0.3682]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 777\tAverage Score: 33.36\tScore: 23.95\tLossActor: 0.00290757 \tLossCritic : 0.00069926(tensor([[-0.4864,  0.6053,  0.9131, -0.1576]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3691, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 778\tAverage Score: 33.46\tScore: 30.27\tLossActor: 0.00291742 \tLossCritic : 0.00069904(tensor([[ 0.4991,  0.1106, -0.1702,  0.2014]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3700, 0.3689, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 779\tAverage Score: 33.32\tScore: 25.48\tLossActor: 0.00294024 \tLossCritic : 0.00069902(tensor([[ 0.0731, -0.3656, -0.5534, -0.1300]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3708, 0.3690, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 780\tAverage Score: 33.43\tScore: 36.86\tLossActor: 0.00294497 \tLossCritic : 0.00069865(tensor([[ 0.4272,  0.0591,  0.0817, -0.0791]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3696, 0.3686, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 781\tAverage Score: 33.43\tScore: 20.36\tLossActor: 0.00300562 \tLossCritic : 0.00069905(tensor([[ 0.3177,  0.0813, -0.2414,  0.3149]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3712, 0.3730, 0.3708, 0.3721]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 782\tAverage Score: 33.50\tScore: 19.63\tLossActor: 0.00304641 \tLossCritic : 0.00069951(tensor([[ 0.2423, -0.1932,  0.0780, -0.5116]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3695, 0.3691, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 783\tAverage Score: 33.65\tScore: 30.46\tLossActor: 0.00305039 \tLossCritic : 0.00069956(tensor([[ 0.0630, -0.2944,  0.6075,  0.0805]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3688, 0.3687, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 784\tAverage Score: 33.68\tScore: 37.64\tLossActor: 0.00303955 \tLossCritic : 0.00069918(tensor([[ 0.0555,  0.5653, -0.1070, -0.1015]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3711, 0.3708, 0.3717]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 785\tAverage Score: 33.69\tScore: 34.73\tLossActor: 0.00303543 \tLossCritic : 0.00069895(tensor([[ 0.3880,  0.2011, -0.0325, -0.1393]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3691, 0.3688, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 786\tAverage Score: 33.59\tScore: 27.36\tLossActor: 0.00305825 \tLossCritic : 0.00069890(tensor([[-0.0300, -0.2642,  0.1918, -0.0881]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3692, 0.3691, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 787\tAverage Score: 33.60\tScore: 38.98\tLossActor: 0.00304161 \tLossCritic : 0.00069828(tensor([[-0.0326,  0.4154, -0.2216, -0.1692]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3699, 0.3702, 0.3710]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 788\tAverage Score: 33.51\tScore: 30.43\tLossActor: 0.00305253 \tLossCritic : 0.00069797(tensor([[-0.3943,  0.1670, -0.3748, -0.1010]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3691, 0.3692, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 789\tAverage Score: 33.44\tScore: 31.65\tLossActor: 0.00306494 \tLossCritic : 0.00069762(tensor([[-0.1758,  0.2152, -0.6059, -0.1967]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3695, 0.3698, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 790\tAverage Score: 33.42\tScore: 37.06\tLossActor: 0.00305311 \tLossCritic : 0.00069746(tensor([[ 0.1739, -0.4035, -0.1647, -0.5349]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3686, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 791\tAverage Score: 33.43\tScore: 38.74\tLossActor: 0.00303794 \tLossCritic : 0.00069688(tensor([[ 0.3629, -0.1163,  0.4581,  0.2942]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3689, 0.3691, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 792\tAverage Score: 33.40\tScore: 36.27\tLossActor: 0.00303401 \tLossCritic : 0.00069640(tensor([[-0.4200,  0.1747, -0.6756, -0.0461]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 793\tAverage Score: 33.40\tScore: 39.05\tLossActor: 0.00301829 \tLossCritic : 0.00069574(tensor([[-0.3704,  0.0644, -0.4542,  0.1049]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3696, 0.3699, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 794\tAverage Score: 33.40\tScore: 38.81\tLossActor: 0.00300435 \tLossCritic : 0.00069514(tensor([[ 0.1208, -0.4574,  0.2997, -0.0739]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3689, 0.3690, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 795\tAverage Score: 33.38\tScore: 37.93\tLossActor: 0.00299261 \tLossCritic : 0.00069455(tensor([[ 0.0816,  0.0868, -0.1635,  0.4535]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3693, 0.3694, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 796\tAverage Score: 33.55\tScore: 38.92\tLossActor: 0.00298042 \tLossCritic : 0.00069385(tensor([[0.1124, 0.3693, 0.8786, 0.2780]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3683, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 797\tAverage Score: 33.55\tScore: 38.23\tLossActor: 0.00298061 \tLossCritic : 0.00069324(tensor([[ 0.1626,  0.4533, -0.4925,  0.7192]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3696, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 798\tAverage Score: 33.45\tScore: 27.30\tLossActor: 0.00299680 \tLossCritic : 0.00069328(tensor([[-0.0788, -0.4302,  0.2543,  0.2163]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3683, 0.3682, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 799\tAverage Score: 33.64\tScore: 38.05\tLossActor: 0.00298517 \tLossCritic : 0.00069274(tensor([[-0.4289, -0.3526,  0.0015, -0.3093]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3700, 0.3696, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 800\tAverage Score: 33.75\tScore: 38.04\tLossActor: 0.00297217 \tLossCritic : 0.00069216(tensor([[0.2412, 0.2354, 0.4568, 0.4255]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3685, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 800\tAverage Score: 33.75\n",
      "Episode 801\tAverage Score: 33.73\tScore: 35.99\tLossActor: 0.00296408 \tLossCritic : 0.00069182(tensor([[ 0.1336, -0.0637,  0.5636, -0.2096]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 802\tAverage Score: 33.77\tScore: 38.87\tLossActor: 0.00295090 \tLossCritic : 0.00069121(tensor([[-0.1347,  0.0772, -0.1646,  0.0696]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3694, 0.3690, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 803\tAverage Score: 33.77\tScore: 39.19\tLossActor: 0.00293593 \tLossCritic : 0.00069049(tensor([[ 0.4154,  0.2086, -0.2910,  0.5648]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3692, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 804\tAverage Score: 33.77\tScore: 37.85\tLossActor: 0.00292381 \tLossCritic : 0.00068989(tensor([[ 0.1074, -0.3197,  0.6721, -0.2683]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3688, 0.3685, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 805\tAverage Score: 33.77\tScore: 38.88\tLossActor: 0.00290652 \tLossCritic : 0.00068918(tensor([[-0.1454,  0.3521,  0.1395, -0.3069]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3698, 0.3694, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 806\tAverage Score: 33.78\tScore: 39.07\tLossActor: 0.00289367 \tLossCritic : 0.00068856(tensor([[-0.4733, -0.0206, -0.3389, -0.3558]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3686, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 807\tAverage Score: 33.77\tScore: 39.07\tLossActor: 0.00288039 \tLossCritic : 0.00068784(tensor([[ 0.1158, -0.2194,  0.1767, -0.2634]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3686, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 808\tAverage Score: 33.78\tScore: 37.73\tLossActor: 0.00287124 \tLossCritic : 0.00068731(tensor([[-0.3426, -0.0096,  0.1506, -0.5428]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3692, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 809\tAverage Score: 33.79\tScore: 38.93\tLossActor: 0.00286021 \tLossCritic : 0.00068658(tensor([[-0.5549,  0.4045, -0.2129, -0.2080]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3695, 0.3692, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 810\tAverage Score: 33.79\tScore: 39.04\tLossActor: 0.00284783 \tLossCritic : 0.00068587(tensor([[ 0.1564,  0.4610, -0.2757,  0.4272]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3691, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 811\tAverage Score: 33.78\tScore: 37.53\tLossActor: 0.00284027 \tLossCritic : 0.00068536(tensor([[ 0.1428,  0.4056,  0.6989, -0.3280]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 812\tAverage Score: 33.79\tScore: 39.34\tLossActor: 0.00282907 \tLossCritic : 0.00068465(tensor([[-0.3108,  0.1521,  0.0245, -0.1876]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3702, 0.3694, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 813\tAverage Score: 34.15\tScore: 39.07\tLossActor: 0.00281899 \tLossCritic : 0.00068391(tensor([[-0.0343, -0.4263, -0.3259, -0.0733]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3700, 0.3692, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 814\tAverage Score: 34.47\tScore: 38.05\tLossActor: 0.00280926 \tLossCritic : 0.00068324(tensor([[ 0.1369, -0.0036,  0.1042, -0.3225]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3688, 0.3685, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 815\tAverage Score: 34.63\tScore: 39.39\tLossActor: 0.00279787 \tLossCritic : 0.00068248(tensor([[-0.1120, -0.0437, -0.4390,  0.2032]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3703, 0.3694, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 816\tAverage Score: 34.81\tScore: 39.22\tLossActor: 0.00278445 \tLossCritic : 0.00068174(tensor([[-0.1990,  0.3320, -0.2598,  0.1630]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3706, 0.3699, 0.3705]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 817\tAverage Score: 34.93\tScore: 36.83\tLossActor: 0.00278036 \tLossCritic : 0.00068128(tensor([[ 0.1197, -0.1970,  0.3184,  0.3078]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3685, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 818\tAverage Score: 35.04\tScore: 39.15\tLossActor: 0.00277010 \tLossCritic : 0.00068057(tensor([[ 0.1605, -0.1414, -0.1873,  0.0415]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 819\tAverage Score: 35.32\tScore: 39.11\tLossActor: 0.00276280 \tLossCritic : 0.00067983(tensor([[0.3694, 0.2608, 0.2911, 0.6230]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3690, 0.3687, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 820\tAverage Score: 35.47\tScore: 39.21\tLossActor: 0.00275237 \tLossCritic : 0.00067915(tensor([[0.1073, 0.3323, 0.0110, 0.2703]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 821\tAverage Score: 35.52\tScore: 39.02\tLossActor: 0.00274362 \tLossCritic : 0.00067844(tensor([[-0.4698,  0.4026, -0.1654,  0.3511]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3698, 0.3693, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 822\tAverage Score: 35.61\tScore: 38.89\tLossActor: 0.00273495 \tLossCritic : 0.00067776(tensor([[0.0353, 0.4311, 0.4420, 0.3489]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3692, 0.3689, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 823\tAverage Score: 35.72\tScore: 36.96\tLossActor: 0.00273676 \tLossCritic : 0.00067733(tensor([[ 0.0932, -0.0999,  0.1694,  0.2664]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3686, 0.3685, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 824\tAverage Score: 35.74\tScore: 36.76\tLossActor: 0.00274213 \tLossCritic : 0.00067684(tensor([[ 0.1720,  0.1923, -0.6084,  0.4648]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3693, 0.3691, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 825\tAverage Score: 35.98\tScore: 38.11\tLossActor: 0.00274069 \tLossCritic : 0.00067625(tensor([[0.1310, 0.5276, 0.1368, 0.0536]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3707, 0.3701, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 826\tAverage Score: 36.06\tScore: 38.63\tLossActor: 0.00273184 \tLossCritic : 0.00067556(tensor([[ 0.3257,  0.1782,  0.3044, -0.1758]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3690, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 827\tAverage Score: 36.13\tScore: 36.47\tLossActor: 0.00272878 \tLossCritic : 0.00067499(tensor([[0.1511, 0.5627, 0.4360, 0.3459]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3687, 0.3686, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 828\tAverage Score: 36.11\tScore: 35.57\tLossActor: 0.00272977 \tLossCritic : 0.00067461(tensor([[ 0.1133, -0.0906,  0.7252, -0.2341]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3683, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 829\tAverage Score: 36.10\tScore: 35.75\tLossActor: 0.00273078 \tLossCritic : 0.00067424(tensor([[-0.0808, -0.3339, -0.6616, -0.1380]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3686, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 830\tAverage Score: 36.17\tScore: 39.15\tLossActor: 0.00272155 \tLossCritic : 0.00067358(tensor([[-0.5130,  0.2408, -0.0695,  0.4186]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3695, 0.3693, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 831\tAverage Score: 36.14\tScore: 35.07\tLossActor: 0.00272333 \tLossCritic : 0.00067328(tensor([[-0.1641,  0.0428, -0.5154, -0.2140]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3691, 0.3688, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 832\tAverage Score: 36.15\tScore: 39.49\tLossActor: 0.00271314 \tLossCritic : 0.00067260(tensor([[-0.1469, -0.2746, -0.0948, -0.4663]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3693, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 833\tAverage Score: 36.13\tScore: 38.02\tLossActor: 0.00270698 \tLossCritic : 0.00067203(tensor([[ 0.1399,  0.0656,  0.5713, -0.2139]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3687, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 834\tAverage Score: 36.13\tScore: 39.50\tLossActor: 0.00269728 \tLossCritic : 0.00067133(tensor([[-0.1714, -0.3952,  0.2215, -0.2726]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3692, 0.3689, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 835\tAverage Score: 36.11\tScore: 37.26\tLossActor: 0.00269396 \tLossCritic : 0.00067072(tensor([[ 0.0106,  0.1406, -0.2893, -0.0394]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3708, 0.3702, 0.3710]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 836\tAverage Score: 36.15\tScore: 37.95\tLossActor: 0.00268913 \tLossCritic : 0.00067021(tensor([[-0.1397, -0.1426, -0.1312, -0.2745]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3699, 0.3694, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 837\tAverage Score: 36.14\tScore: 38.30\tLossActor: 0.00268398 \tLossCritic : 0.00066967(tensor([[ 0.2856,  0.4054,  0.4828, -0.2728]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 838\tAverage Score: 36.15\tScore: 38.26\tLossActor: 0.00267754 \tLossCritic : 0.00066900(tensor([[-0.1107,  0.3140, -0.1264,  0.2931]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3693, 0.3691, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 839\tAverage Score: 36.14\tScore: 39.20\tLossActor: 0.00266874 \tLossCritic : 0.00066827(tensor([[-0.2353, -0.1007, -0.0883, -0.3209]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3699, 0.3695, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 840\tAverage Score: 36.17\tScore: 38.91\tLossActor: 0.00266250 \tLossCritic : 0.00066756(tensor([[-0.2154,  0.2511, -0.5038,  0.0411]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3696, 0.3693, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 841\tAverage Score: 36.36\tScore: 38.98\tLossActor: 0.00265583 \tLossCritic : 0.00066694(tensor([[-0.5491,  0.5505, -0.3718,  0.0759]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3695, 0.3693, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 842\tAverage Score: 36.35\tScore: 38.54\tLossActor: 0.00265012 \tLossCritic : 0.00066632(tensor([[ 0.0357, -0.4221,  0.4811,  0.1719]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3696, 0.3692, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 843\tAverage Score: 36.34\tScore: 37.66\tLossActor: 0.00264950 \tLossCritic : 0.00066580(tensor([[0.5227, 0.0798, 0.1844, 0.5175]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3685, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 844\tAverage Score: 36.35\tScore: 39.08\tLossActor: 0.00264358 \tLossCritic : 0.00066509(tensor([[ 0.1502, -0.2083,  0.0161,  0.5725]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3702, 0.3696, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 845\tAverage Score: 36.38\tScore: 39.29\tLossActor: 0.00263587 \tLossCritic : 0.00066438(tensor([[-0.1335,  0.2383,  0.0431,  0.3800]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3697, 0.3693, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 846\tAverage Score: 36.38\tScore: 38.32\tLossActor: 0.00263440 \tLossCritic : 0.00066382(tensor([[-0.0680, -0.4979, -0.5645, -0.2715]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3689, 0.3687, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 847\tAverage Score: 36.40\tScore: 39.26\tLossActor: 0.00263704 \tLossCritic : 0.00066321(tensor([[-0.1902,  0.5662,  0.2931, -0.0302]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3696, 0.3693, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 848\tAverage Score: 36.37\tScore: 34.90\tLossActor: 0.00264342 \tLossCritic : 0.00066314(tensor([[-0.0222,  0.2106, -0.4518, -0.3386]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3688, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 849\tAverage Score: 36.37\tScore: 37.86\tLossActor: 0.00264014 \tLossCritic : 0.00066269(tensor([[ 0.2092, -0.3320, -0.4103,  0.2600]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3691, 0.3689, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 850\tAverage Score: 36.32\tScore: 34.64\tLossActor: 0.00264631 \tLossCritic : 0.00066238(tensor([[-0.2643,  0.0682,  0.1361,  0.1465]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3698, 0.3695, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 851\tAverage Score: 36.32\tScore: 38.71\tLossActor: 0.00264189 \tLossCritic : 0.00066181(tensor([[ 0.2409,  0.0234, -0.3589,  0.0541]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3689, 0.3687, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 852\tAverage Score: 36.32\tScore: 38.58\tLossActor: 0.00263456 \tLossCritic : 0.00066134(tensor([[-0.4424,  0.5699, -0.2381,  0.0425]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3692, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 853\tAverage Score: 36.32\tScore: 38.47\tLossActor: 0.00263045 \tLossCritic : 0.00066073(tensor([[-0.0601, -0.0922, -0.4225,  0.5389]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3699, 0.3692, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 854\tAverage Score: 36.31\tScore: 38.68\tLossActor: 0.00262608 \tLossCritic : 0.00066006(tensor([[ 0.3010, -0.0043, -0.2997,  0.4707]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3698, 0.3691, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 855\tAverage Score: 36.31\tScore: 39.22\tLossActor: 0.00261805 \tLossCritic : 0.00065937(tensor([[ 0.4175, -0.0124, -0.0190, -0.6101]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3687, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 856\tAverage Score: 36.32\tScore: 38.90\tLossActor: 0.00261157 \tLossCritic : 0.00065869(tensor([[ 0.1005, -0.1093,  0.3955, -0.0034]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3688, 0.3686, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 857\tAverage Score: 36.31\tScore: 37.66\tLossActor: 0.00260789 \tLossCritic : 0.00065815(tensor([[-0.4370,  0.1960, -0.4515,  0.0509]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3692, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 858\tAverage Score: 36.31\tScore: 38.39\tLossActor: 0.00260905 \tLossCritic : 0.00065752(tensor([[ 0.4584, -0.0033,  0.5145, -0.4584]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3686, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 859\tAverage Score: 36.29\tScore: 36.18\tLossActor: 0.00261608 \tLossCritic : 0.00065711(tensor([[-0.0817,  0.5428,  0.7960, -0.1752]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3691, 0.3686, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 860\tAverage Score: 36.28\tScore: 37.52\tLossActor: 0.00265651 \tLossCritic : 0.00065669(tensor([[ 0.1755, -0.3940, -0.7542,  0.5745]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3686, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 861\tAverage Score: 36.08\tScore: 18.04\tLossActor: 0.00272576 \tLossCritic : 0.00065774(tensor([[-0.3389, -0.5998,  0.3720,  0.6225]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3687, 0.3684, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 862\tAverage Score: 35.90\tScore: 19.98\tLossActor: 0.00278105 \tLossCritic : 0.00065869(tensor([[ 0.5580, -0.8689, -0.9808, -0.3457]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3681, 0.3680, 0.3679, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 863\tAverage Score: 35.83\tScore: 29.60\tLossActor: 0.00280553 \tLossCritic : 0.00065886(tensor([[ 0.0410,  0.4380,  0.5507, -0.4569]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3685, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 864\tAverage Score: 35.71\tScore: 26.54\tLossActor: 0.00283792 \tLossCritic : 0.00065954(tensor([[-0.1114,  0.2256,  0.5639, -0.0842]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3696, 0.3690, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 865\tAverage Score: 35.58\tScore: 26.27\tLossActor: 0.00287249 \tLossCritic : 0.00066016(tensor([[-0.2530, -0.1740,  0.7054, -0.8482]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3685, 0.3684, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 866\tAverage Score: 35.44\tScore: 21.78\tLossActor: 0.00290326 \tLossCritic : 0.00066143(tensor([[-0.0101, -0.0516, -0.6692, -0.2760]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3687, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 867\tAverage Score: 35.46\tScore: 24.53\tLossActor: 0.00292588 \tLossCritic : 0.00066217(tensor([[-0.1858,  0.0987,  0.2098, -0.0761]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3709, 0.3702, 0.3697, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 868\tAverage Score: 35.52\tScore: 32.35\tLossActor: 0.00293296 \tLossCritic : 0.00066222(tensor([[-0.4653, -0.3461, -0.2252, -0.3253]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3688, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 869\tAverage Score: 35.57\tScore: 34.04\tLossActor: 0.00293109 \tLossCritic : 0.00066241(tensor([[-0.0026, -0.1550, -0.0433, -0.4231]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3690, 0.3687, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 870\tAverage Score: 35.48\tScore: 29.62\tLossActor: 0.00293865 \tLossCritic : 0.00066238(tensor([[ 0.2700, -0.1895,  0.0503, -0.0930]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3690, 0.3687, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 871\tAverage Score: 35.47\tScore: 35.57\tLossActor: 0.00293242 \tLossCritic : 0.00066206(tensor([[-0.0906, -0.3268, -0.0553,  0.1042]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3715, 0.3704, 0.3698, 0.3708]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 872\tAverage Score: 35.46\tScore: 38.00\tLossActor: 0.00291955 \tLossCritic : 0.00066172(tensor([[-0.3183,  0.0227, -0.7791,  0.0312]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3687, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 873\tAverage Score: 35.48\tScore: 36.22\tLossActor: 0.00290859 \tLossCritic : 0.00066146(tensor([[ 0.2579, -0.5815, -0.0712,  0.1430]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3697, 0.3693, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 874\tAverage Score: 35.45\tScore: 36.31\tLossActor: 0.00290713 \tLossCritic : 0.00066125(tensor([[-0.1662, -0.2211,  0.1743, -0.3590]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3690, 0.3688, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 875\tAverage Score: 35.47\tScore: 39.43\tLossActor: 0.00289274 \tLossCritic : 0.00066068(tensor([[-0.1982, -0.5263, -0.4057,  0.0138]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3694, 0.3691, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 876\tAverage Score: 35.74\tScore: 39.44\tLossActor: 0.00288132 \tLossCritic : 0.00066007(tensor([[-0.3284,  0.3968, -0.0459, -0.1799]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3697, 0.3693, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 877\tAverage Score: 35.88\tScore: 38.22\tLossActor: 0.00286991 \tLossCritic : 0.00065965(tensor([[-0.1891, -0.1988, -0.5287,  0.0219]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3692, 0.3688, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 878\tAverage Score: 35.94\tScore: 36.61\tLossActor: 0.00286478 \tLossCritic : 0.00065938(tensor([[-0.2456, -0.5029, -0.2221, -0.5103]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3694, 0.3690, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 879\tAverage Score: 36.07\tScore: 38.64\tLossActor: 0.00285444 \tLossCritic : 0.00065882(tensor([[ 0.1100, -0.1419,  0.5539, -0.2207]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3690, 0.3686, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 880\tAverage Score: 36.10\tScore: 39.37\tLossActor: 0.00284186 \tLossCritic : 0.00065819(tensor([[-0.0343, -0.5457,  0.4398, -0.2905]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3695, 0.3690, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 881\tAverage Score: 36.27\tScore: 37.85\tLossActor: 0.00283703 \tLossCritic : 0.00065769(tensor([[-0.4447,  0.2234, -0.1123, -0.2146]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3695, 0.3690, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 882\tAverage Score: 36.44\tScore: 36.51\tLossActor: 0.00283484 \tLossCritic : 0.00065742(tensor([[ 0.0807,  0.2679,  0.0316, -0.5264]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3686, 0.3683, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 883\tAverage Score: 36.53\tScore: 39.32\tLossActor: 0.00282527 \tLossCritic : 0.00065679(tensor([[-0.1572, -0.2278,  0.1931, -0.2664]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3703, 0.3693, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 884\tAverage Score: 36.52\tScore: 36.87\tLossActor: 0.00282368 \tLossCritic : 0.00065641(tensor([[ 0.6237,  0.1399,  0.1908, -0.1263]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3684, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 885\tAverage Score: 36.57\tScore: 39.11\tLossActor: 0.00281542 \tLossCritic : 0.00065577(tensor([[0.3278, 0.5301, 0.1065, 0.3326]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3706, 0.3693, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 886\tAverage Score: 36.63\tScore: 33.30\tLossActor: 0.00282248 \tLossCritic : 0.00065549(tensor([[-0.3997,  0.1586, -0.4048,  0.4660]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3697, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 887\tAverage Score: 36.63\tScore: 39.19\tLossActor: 0.00281312 \tLossCritic : 0.00065484(tensor([[-0.5852, -0.1283,  0.0260, -0.0523]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3696, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 888\tAverage Score: 36.72\tScore: 39.40\tLossActor: 0.00280225 \tLossCritic : 0.00065421(tensor([[-0.4399,  0.4409, -0.4194,  0.5910]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3697, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 889\tAverage Score: 36.79\tScore: 38.97\tLossActor: 0.00279308 \tLossCritic : 0.00065357(tensor([[-0.1351, -0.0626, -0.6741,  0.1628]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3698, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 890\tAverage Score: 36.78\tScore: 36.36\tLossActor: 0.00279045 \tLossCritic : 0.00065311(tensor([[0.1060, 0.1678, 0.5077, 0.4808]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3694, 0.3686, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 891\tAverage Score: 36.78\tScore: 38.41\tLossActor: 0.00278493 \tLossCritic : 0.00065255(tensor([[-0.1887, -0.0044, -0.3318,  0.2460]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3707, 0.3710, 0.3696, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 892\tAverage Score: 36.80\tScore: 38.29\tLossActor: 0.00278493 \tLossCritic : 0.00065200(tensor([[-0.1948, -0.0952,  0.0697,  0.3270]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3700, 0.3693, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 893\tAverage Score: 36.73\tScore: 32.06\tLossActor: 0.00279276 \tLossCritic : 0.00065190(tensor([[ 0.1389, -0.5021, -0.1945, -0.5011]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3684, 0.3684, 0.3683, 0.3683]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 894\tAverage Score: 36.72\tScore: 37.60\tLossActor: 0.00278598 \tLossCritic : 0.00065145(tensor([[ 0.4247,  0.0346,  0.8585, -0.6902]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3689, 0.3685, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 895\tAverage Score: 36.72\tScore: 38.15\tLossActor: 0.00278044 \tLossCritic : 0.00065090(tensor([[0.1876, 0.3346, 0.4777, 0.3475]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3694, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 896\tAverage Score: 36.72\tScore: 39.00\tLossActor: 0.00277396 \tLossCritic : 0.00065026(tensor([[ 0.1605,  0.3362,  0.5210, -0.1445]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3690, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 897\tAverage Score: 36.73\tScore: 39.20\tLossActor: 0.00276756 \tLossCritic : 0.00064964(tensor([[ 0.1055, -0.2246,  0.3840, -0.5498]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3695, 0.3690, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 898\tAverage Score: 36.85\tScore: 38.74\tLossActor: 0.00275969 \tLossCritic : 0.00064912(tensor([[ 0.0873,  0.0716, -0.0811,  0.0217]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3691, 0.3687, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 899\tAverage Score: 36.86\tScore: 39.25\tLossActor: 0.00275212 \tLossCritic : 0.00064852(tensor([[-0.2412, -0.1866, -0.2849,  0.0041]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3690, 0.3688, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 900\tAverage Score: 36.86\tScore: 37.82\tLossActor: 0.00274969 \tLossCritic : 0.00064804(tensor([[-0.4070,  0.2727, -0.4489,  0.2387]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3692, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 900\tAverage Score: 36.86\n",
      "Episode 901\tAverage Score: 36.89\tScore: 39.04\tLossActor: 0.00274480 \tLossCritic : 0.00064746(tensor([[-0.1492, -0.3371,  0.0279, -0.2332]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3694, 0.3691, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 902\tAverage Score: 36.88\tScore: 38.43\tLossActor: 0.00273976 \tLossCritic : 0.00064683(tensor([[-0.1435,  0.2291,  0.2852, -0.3981]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3698, 0.3693, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 903\tAverage Score: 36.88\tScore: 38.68\tLossActor: 0.00273480 \tLossCritic : 0.00064627(tensor([[-0.1622, -0.3866, -0.3633, -0.4886]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3694, 0.3690, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 904\tAverage Score: 36.88\tScore: 38.66\tLossActor: 0.00273120 \tLossCritic : 0.00064572(tensor([[ 0.0622, -0.0619, -0.2085, -0.2973]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3691, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 905\tAverage Score: 36.85\tScore: 35.28\tLossActor: 0.00273776 \tLossCritic : 0.00064549(tensor([[-0.1626,  0.4473, -0.4037,  0.0900]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3694, 0.3689, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 906\tAverage Score: 36.80\tScore: 34.24\tLossActor: 0.00275084 \tLossCritic : 0.00064536(tensor([[-0.4108, -0.2878, -0.1384,  0.7365]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3683, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 907\tAverage Score: 36.77\tScore: 36.08\tLossActor: 0.00275498 \tLossCritic : 0.00064499(tensor([[-0.3431, -0.0104, -0.2025,  0.0904]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3697, 0.3694, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 908\tAverage Score: 36.78\tScore: 39.15\tLossActor: 0.00274679 \tLossCritic : 0.00064446(tensor([[ 0.3558, -0.0644, -0.0118,  0.2120]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3692, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 909\tAverage Score: 36.73\tScore: 33.20\tLossActor: 0.00275321 \tLossCritic : 0.00064427(tensor([[0.3343, 0.3070, 0.7008, 0.2849]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3687, 0.3684, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 910\tAverage Score: 36.73\tScore: 39.14\tLossActor: 0.00274855 \tLossCritic : 0.00064372(tensor([[0.3669, 0.0459, 0.4025, 0.0898]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3692, 0.3689, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 911\tAverage Score: 36.74\tScore: 39.04\tLossActor: 0.00274304 \tLossCritic : 0.00064320(tensor([[ 0.1060, -0.2293,  0.0126, -0.3160]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3690, 0.3688, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 912\tAverage Score: 36.73\tScore: 37.99\tLossActor: 0.00273852 \tLossCritic : 0.00064269(tensor([[0.5062, 0.0123, 0.0914, 0.5642]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3692, 0.3690, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 913\tAverage Score: 36.71\tScore: 36.82\tLossActor: 0.00273738 \tLossCritic : 0.00064223(tensor([[0.2555, 0.0627, 0.8397, 0.0971]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3689, 0.3688, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 914\tAverage Score: 36.72\tScore: 39.39\tLossActor: 0.00272962 \tLossCritic : 0.00064163(tensor([[ 0.6151, -0.0037,  0.0420,  0.2965]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3690, 0.3688, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 915\tAverage Score: 36.72\tScore: 38.83\tLossActor: 0.00272436 \tLossCritic : 0.00064104(tensor([[-0.2364, -0.3615,  0.3273,  0.3436]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3695, 0.3695, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 916\tAverage Score: 36.72\tScore: 39.47\tLossActor: 0.00271597 \tLossCritic : 0.00064044(tensor([[0.3463, 0.0594, 0.4619, 0.2712]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3689, 0.3687, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 917\tAverage Score: 36.74\tScore: 39.35\tLossActor: 0.00271056 \tLossCritic : 0.00063982(tensor([[-0.4940,  0.0037, -0.7883, -0.0282]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3689, 0.3690, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 918\tAverage Score: 36.74\tScore: 38.83\tLossActor: 0.00270602 \tLossCritic : 0.00063925(tensor([[-0.3009, -0.2529, -0.6462,  0.0827]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3687, 0.3687, 0.3688, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 919\tAverage Score: 36.74\tScore: 39.21\tLossActor: 0.00269925 \tLossCritic : 0.00063865(tensor([[-0.0250,  0.3733, -0.0942,  0.3290]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3701, 0.3699, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 920\tAverage Score: 36.74\tScore: 39.29\tLossActor: 0.00269186 \tLossCritic : 0.00063803(tensor([[-0.1677,  0.0410, -0.6093, -0.3001]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3692, 0.3693, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 921\tAverage Score: 36.70\tScore: 34.84\tLossActor: 0.00269592 \tLossCritic : 0.00063778(tensor([[ 0.2307,  0.0781, -0.3494, -0.3653]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3690, 0.3691, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 922\tAverage Score: 36.71\tScore: 39.45\tLossActor: 0.00268944 \tLossCritic : 0.00063717(tensor([[ 0.0617,  0.0562, -0.3738, -0.1042]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3691, 0.3691, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 923\tAverage Score: 36.73\tScore: 39.12\tLossActor: 0.00268443 \tLossCritic : 0.00063657(tensor([[ 0.4547, -0.0080, -0.2108, -0.3094]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3689, 0.3688, 0.3687, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 924\tAverage Score: 36.72\tScore: 35.84\tLossActor: 0.00268887 \tLossCritic : 0.00063629(tensor([[ 0.2102,  0.2127,  0.0935, -0.3104]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3686, 0.3685, 0.3685, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 925\tAverage Score: 36.73\tScore: 39.50\tLossActor: 0.00268267 \tLossCritic : 0.00063568(tensor([[ 0.2365,  0.4329,  0.0738, -0.2684]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3701, 0.3701, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 926\tAverage Score: 36.74\tScore: 39.39\tLossActor: 0.00267588 \tLossCritic : 0.00063504(tensor([[-0.1087,  0.0074, -0.1318, -0.4262]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3697, 0.3699, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 927\tAverage Score: 36.76\tScore: 38.61\tLossActor: 0.00267327 \tLossCritic : 0.00063445(tensor([[-0.0699,  0.3293,  0.0017,  0.2804]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3702, 0.3701, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 928\tAverage Score: 36.78\tScore: 37.21\tLossActor: 0.00267637 \tLossCritic : 0.00063394(tensor([[-0.0993,  0.1152, -0.1828, -0.4480]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3704, 0.3702, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 929\tAverage Score: 36.74\tScore: 31.69\tLossActor: 0.00269337 \tLossCritic : 0.00063389(tensor([[-0.1154,  0.0887, -0.0336, -0.7056]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3689, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 930\tAverage Score: 36.73\tScore: 38.82\tLossActor: 0.00268926 \tLossCritic : 0.00063331(tensor([[ 0.2803, -0.0828, -0.2524, -0.0648]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3693, 0.3691, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 931\tAverage Score: 36.77\tScore: 38.69\tLossActor: 0.00268616 \tLossCritic : 0.00063274(tensor([[-0.4740, -0.2240,  0.2352,  0.2681]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3696, 0.3695, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 932\tAverage Score: 36.77\tScore: 39.18\tLossActor: 0.00268049 \tLossCritic : 0.00063215(tensor([[ 0.2860, -0.2725,  0.6354, -0.0348]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3693, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 933\tAverage Score: 36.77\tScore: 37.95\tLossActor: 0.00267834 \tLossCritic : 0.00063161(tensor([[0.0485, 0.3552, 0.2182, 0.6370]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3698, 0.3692, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 934\tAverage Score: 36.74\tScore: 36.62\tLossActor: 0.00268121 \tLossCritic : 0.00063126(tensor([[0.0628, 0.0484, 0.1330, 0.7159]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3703, 0.3698, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 935\tAverage Score: 36.75\tScore: 38.64\tLossActor: 0.00267935 \tLossCritic : 0.00063067(tensor([[-0.1048, -0.2941,  0.2776,  0.4942]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3700, 0.3695, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 936\tAverage Score: 36.77\tScore: 39.39\tLossActor: 0.00267353 \tLossCritic : 0.00063006(tensor([[ 0.1925, -0.0818,  0.2796, -0.5993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3692, 0.3688, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 937\tAverage Score: 36.76\tScore: 38.21\tLossActor: 0.00267207 \tLossCritic : 0.00062951(tensor([[-0.4217, -0.4563, -0.5173, -0.0440]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3690, 0.3690, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 938\tAverage Score: 36.78\tScore: 39.45\tLossActor: 0.00266553 \tLossCritic : 0.00062890(tensor([[-0.3031, -0.0855, -0.2225, -0.3236]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3701, 0.3700, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 939\tAverage Score: 36.75\tScore: 36.35\tLossActor: 0.00266645 \tLossCritic : 0.00062853(tensor([[-0.1319, -0.1935,  0.1672, -0.2960]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3688, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 940\tAverage Score: 36.72\tScore: 35.99\tLossActor: 0.00266865 \tLossCritic : 0.00062815(tensor([[-0.0657,  0.2939, -0.0256, -0.2794]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3699, 0.3699, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 941\tAverage Score: 36.72\tScore: 39.46\tLossActor: 0.00267173 \tLossCritic : 0.00062756(tensor([[ 0.4483,  0.1898, -0.1073,  0.0091]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3696, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 942\tAverage Score: 36.59\tScore: 25.08\tLossActor: 0.00269869 \tLossCritic : 0.00062772(tensor([[-0.3296, -0.5539, -0.2458, -0.2758]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3695, 0.3689, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 943\tAverage Score: 36.49\tScore: 27.77\tLossActor: 0.00272182 \tLossCritic : 0.00062765(tensor([[ 0.1256, -0.1948,  0.5972, -0.2955]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3689, 0.3685, 0.3685]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 944\tAverage Score: 36.34\tScore: 23.88\tLossActor: 0.00275697 \tLossCritic : 0.00062790(tensor([[-0.1970, -0.0532,  0.2250, -0.1705]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3694, 0.3689, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 945\tAverage Score: 36.22\tScore: 27.83\tLossActor: 0.00277871 \tLossCritic : 0.00062794(tensor([[-0.5143, -0.5375, -0.1056, -0.2038]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3691, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 946\tAverage Score: 36.23\tScore: 38.97\tLossActor: 0.00277122 \tLossCritic : 0.00062746(tensor([[-0.2076, -0.3789, -0.5495, -0.1660]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3702, 0.3693, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 947\tAverage Score: 36.17\tScore: 33.40\tLossActor: 0.00277743 \tLossCritic : 0.00062732(tensor([[-0.1102, -0.1954, -0.1432, -0.5994]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3698, 0.3691, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 948\tAverage Score: 36.21\tScore: 38.78\tLossActor: 0.00277097 \tLossCritic : 0.00062680(tensor([[-0.1455,  0.0789, -0.5260, -0.0416]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3708, 0.3700, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 949\tAverage Score: 36.21\tScore: 38.10\tLossActor: 0.00276664 \tLossCritic : 0.00062631(tensor([[ 0.1246, -0.2771, -0.5641,  0.1502]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3701, 0.3693, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 950\tAverage Score: 36.26\tScore: 39.20\tLossActor: 0.00275873 \tLossCritic : 0.00062576(tensor([[ 0.1591,  0.3773,  0.3398, -0.2327]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3703, 0.3693, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 951\tAverage Score: 36.25\tScore: 38.05\tLossActor: 0.00275446 \tLossCritic : 0.00062530(tensor([[-0.2192,  0.0336, -0.6569,  0.1511]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3701, 0.3695, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 952\tAverage Score: 36.23\tScore: 36.01\tLossActor: 0.00275394 \tLossCritic : 0.00062502(tensor([[-0.0236, -0.1738,  0.3844, -0.2161]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3709, 0.3700, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 953\tAverage Score: 36.21\tScore: 37.05\tLossActor: 0.00275198 \tLossCritic : 0.00062464(tensor([[ 0.2554, -0.0373,  0.0900, -0.2749]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3691, 0.3686, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 954\tAverage Score: 36.20\tScore: 38.01\tLossActor: 0.00274659 \tLossCritic : 0.00062421(tensor([[ 0.0175, -0.2411,  0.2915,  0.1629]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3695, 0.3689, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 955\tAverage Score: 36.19\tScore: 37.37\tLossActor: 0.00274160 \tLossCritic : 0.00062385(tensor([[ 0.2624,  0.0877, -0.0515,  0.3632]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3701, 0.3693, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 956\tAverage Score: 36.19\tScore: 39.03\tLossActor: 0.00273414 \tLossCritic : 0.00062331(tensor([[ 0.0919, -0.0251,  0.4926, -0.0608]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3695, 0.3689, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 957\tAverage Score: 36.20\tScore: 39.02\tLossActor: 0.00272589 \tLossCritic : 0.00062277(tensor([[-0.1508, -0.1676, -0.2730,  0.1094]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3700, 0.3694, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 958\tAverage Score: 36.21\tScore: 38.78\tLossActor: 0.00272030 \tLossCritic : 0.00062227(tensor([[-0.0113,  0.3412,  0.5508, -0.4117]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3697, 0.3692, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 959\tAverage Score: 36.24\tScore: 39.36\tLossActor: 0.00271401 \tLossCritic : 0.00062171(tensor([[0.1580, 0.1366, 0.5377, 0.1170]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3699, 0.3692, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 960\tAverage Score: 36.23\tScore: 36.76\tLossActor: 0.00271535 \tLossCritic : 0.00062128(tensor([[0.2798, 0.3120, 0.2458, 0.2730]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3705, 0.3696, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 961\tAverage Score: 36.44\tScore: 39.35\tLossActor: 0.00270864 \tLossCritic : 0.00062070(tensor([[-0.3314,  0.1651, -0.4736, -0.1830]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3705, 0.3698, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 962\tAverage Score: 36.64\tScore: 39.30\tLossActor: 0.00270195 \tLossCritic : 0.00062011(tensor([[0.1813, 0.1480, 0.1210, 0.2833]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3709, 0.3698, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 963\tAverage Score: 36.73\tScore: 39.40\tLossActor: 0.00269627 \tLossCritic : 0.00061953(tensor([[-0.2131, -0.4883,  0.2533, -0.6120]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3699, 0.3692, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 964\tAverage Score: 36.86\tScore: 39.55\tLossActor: 0.00268951 \tLossCritic : 0.00061895(tensor([[ 0.2059, -0.0007,  0.2245,  0.0751]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3702, 0.3692, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 965\tAverage Score: 36.99\tScore: 39.15\tLossActor: 0.00268549 \tLossCritic : 0.00061834(tensor([[-0.0718, -0.2504,  0.1395, -0.0673]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3698, 0.3690, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 966\tAverage Score: 37.16\tScore: 38.71\tLossActor: 0.00268283 \tLossCritic : 0.00061779(tensor([[-0.2949,  0.2175, -0.1304, -0.1183]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3707, 0.3710, 0.3699, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 967\tAverage Score: 37.31\tScore: 39.26\tLossActor: 0.00267731 \tLossCritic : 0.00061724(tensor([[ 0.0958, -0.0464, -0.2462,  0.3637]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3698, 0.3689, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 968\tAverage Score: 37.37\tScore: 38.39\tLossActor: 0.00267678 \tLossCritic : 0.00061688(tensor([[0.2204, 0.3160, 0.0087, 0.5855]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3700, 0.3690, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 969\tAverage Score: 37.36\tScore: 33.30\tLossActor: 0.00268604 \tLossCritic : 0.00061671(tensor([[ 0.3915,  0.0113, -0.3007,  0.4744]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3699, 0.3690, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 970\tAverage Score: 37.42\tScore: 35.57\tLossActor: 0.00268999 \tLossCritic : 0.00061646(tensor([[-0.1885, -0.1426, -0.4589, -0.2710]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3694, 0.3692, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 971\tAverage Score: 37.45\tScore: 38.34\tLossActor: 0.00268544 \tLossCritic : 0.00061602(tensor([[ 0.4310,  0.2468,  0.3917, -0.2314]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3690, 0.3686, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 972\tAverage Score: 37.46\tScore: 39.22\tLossActor: 0.00267965 \tLossCritic : 0.00061545(tensor([[0.0714, 0.3507, 0.1063, 0.3290]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3696, 0.3691, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 973\tAverage Score: 37.49\tScore: 39.37\tLossActor: 0.00267372 \tLossCritic : 0.00061486(tensor([[-0.5483,  0.2332, -0.1190, -0.1878]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3709, 0.3701, 0.3698, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 974\tAverage Score: 37.49\tScore: 36.17\tLossActor: 0.00267554 \tLossCritic : 0.00061452(tensor([[0.1208, 0.0629, 0.1788, 0.3891]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 0.3689, 0.3685, 0.3689]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 975\tAverage Score: 37.49\tScore: 38.86\tLossActor: 0.00267119 \tLossCritic : 0.00061404(tensor([[0.4218, 0.0342, 0.1754, 0.2753]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3697, 0.3690, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 976\tAverage Score: 37.48\tScore: 38.80\tLossActor: 0.00266740 \tLossCritic : 0.00061349(tensor([[-0.1048,  0.0122, -0.0588, -0.2052]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3707, 0.3702, 0.3696, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 977\tAverage Score: 37.48\tScore: 38.44\tLossActor: 0.00266457 \tLossCritic : 0.00061298(tensor([[0.1269, 0.1656, 0.1472, 0.5032]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3702, 0.3696, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 978\tAverage Score: 37.51\tScore: 39.22\tLossActor: 0.00265894 \tLossCritic : 0.00061240(tensor([[ 0.5079, -0.0844, -0.0274,  0.0911]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3692, 0.3686, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 979\tAverage Score: 37.49\tScore: 37.36\tLossActor: 0.00266190 \tLossCritic : 0.00061195(tensor([[-0.0157,  0.0691,  0.2735,  0.3442]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3702, 0.3693, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 980\tAverage Score: 37.48\tScore: 38.19\tLossActor: 0.00265974 \tLossCritic : 0.00061152(tensor([[-0.1828,  0.4198,  0.6400,  0.3021]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3707, 0.3703, 0.3693, 0.3702]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 981\tAverage Score: 37.45\tScore: 34.70\tLossActor: 0.00266369 \tLossCritic : 0.00061127(tensor([[ 0.3906, -0.0059,  0.6326, -0.0986]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3700, 0.3689, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 982\tAverage Score: 37.47\tScore: 38.39\tLossActor: 0.00265936 \tLossCritic : 0.00061079(tensor([[-0.1772,  0.0604, -0.2050, -0.4686]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3712, 0.3711, 0.3697, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 983\tAverage Score: 37.47\tScore: 39.43\tLossActor: 0.00265378 \tLossCritic : 0.00061024(tensor([[ 0.3931,  0.1044, -0.1360,  0.0423]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3705, 0.3691, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 984\tAverage Score: 37.49\tScore: 38.82\tLossActor: 0.00265081 \tLossCritic : 0.00060969(tensor([[-0.0428, -0.2186,  0.0073, -0.1772]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3705, 0.3692, 0.3699]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 985\tAverage Score: 37.49\tScore: 39.46\tLossActor: 0.00264497 \tLossCritic : 0.00060913(tensor([[0.2294, 0.4947, 0.6442, 0.4535]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3698, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 986\tAverage Score: 37.55\tScore: 39.18\tLossActor: 0.00264061 \tLossCritic : 0.00060856(tensor([[-0.1527,  0.0625, -0.1063, -0.2372]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3717, 0.3719, 0.3702, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 987\tAverage Score: 37.56\tScore: 39.38\tLossActor: 0.00263520 \tLossCritic : 0.00060799(tensor([[-0.0795,  0.3515, -0.4291,  0.2212]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3705, 0.3695, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 988\tAverage Score: 37.56\tScore: 39.39\tLossActor: 0.00263000 \tLossCritic : 0.00060740(tensor([[0.5064, 0.2767, 0.4493, 0.0555]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3698, 0.3688, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 989\tAverage Score: 37.56\tScore: 39.34\tLossActor: 0.00262547 \tLossCritic : 0.00060681(tensor([[ 0.0129, -0.5635, -0.1964, -0.1816]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3695, 0.3687, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 990\tAverage Score: 37.58\tScore: 38.60\tLossActor: 0.00262406 \tLossCritic : 0.00060632(tensor([[-0.0764, -0.3977, -0.0222, -0.7654]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3688, 0.3689, 0.3684, 0.3687]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 991\tAverage Score: 37.59\tScore: 39.38\tLossActor: 0.00261969 \tLossCritic : 0.00060576(tensor([[ 0.4958, -0.3659,  0.1243,  0.3611]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3695, 0.3686, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 992\tAverage Score: 37.60\tScore: 38.87\tLossActor: 0.00261611 \tLossCritic : 0.00060519(tensor([[0.2521, 0.1962, 0.3052, 0.0152]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3706, 0.3693, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 993\tAverage Score: 37.67\tScore: 39.46\tLossActor: 0.00261120 \tLossCritic : 0.00060462(tensor([[-0.5204,  0.3130,  0.2644,  0.1639]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3717, 0.3711, 0.3700, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 994\tAverage Score: 37.69\tScore: 39.45\tLossActor: 0.00260664 \tLossCritic : 0.00060404(tensor([[ 0.1387,  0.1719, -0.1009, -0.2175]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3707, 0.3707, 0.3693, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 995\tAverage Score: 37.59\tScore: 28.32\tLossActor: 0.00262759 \tLossCritic : 0.00060424(tensor([[ 0.0735, -0.0845,  0.4763,  0.1863]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3711, 0.3716, 0.3696, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 996\tAverage Score: 37.59\tScore: 38.82\tLossActor: 0.00262311 \tLossCritic : 0.00060376(tensor([[ 0.3016,  0.2525,  0.1683, -0.1786]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3718, 0.3694, 0.3708]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 997\tAverage Score: 37.59\tScore: 39.44\tLossActor: 0.00261785 \tLossCritic : 0.00060319(tensor([[0.4740, 0.1834, 0.4987, 0.2242]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3706, 0.3689, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 998\tAverage Score: 37.59\tScore: 38.50\tLossActor: 0.00261587 \tLossCritic : 0.00060273(tensor([[ 0.3339,  0.2835,  0.4703, -0.6293]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3700, 0.3688, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 999\tAverage Score: 37.59\tScore: 39.54\tLossActor: 0.00261092 \tLossCritic : 0.00060215(tensor([[-0.0763,  0.4572, -0.0994,  0.1587]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3713, 0.3704, 0.3698, 0.3708]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1000\tAverage Score: 37.61\tScore: 39.39\tLossActor: 0.00260630 \tLossCritic : 0.00060157(tensor([[-0.2189,  0.3530, -0.3875,  0.3770]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3720, 0.3709, 0.3703, 0.3716]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1000\tAverage Score: 37.61\n",
      "Episode 1001\tAverage Score: 37.61\tScore: 38.86\tLossActor: 0.00261290 \tLossCritic : 0.00060153(tensor([[-0.2346,  0.4173,  0.0144,  0.6896]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3718, 0.3708, 0.3702, 0.3713]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1002\tAverage Score: 37.62\tScore: 39.38\tLossActor: 0.00261598 \tLossCritic : 0.00060155(tensor([[-0.0148,  0.1588,  0.2687,  0.4461]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3696, 0.3691, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1003\tAverage Score: 37.62\tScore: 38.76\tLossActor: 0.00262166 \tLossCritic : 0.00060157(tensor([[ 0.0555,  0.0929, -0.7374, -0.3114]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3712, 0.3702, 0.3698, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1004\tAverage Score: 37.62\tScore: 38.68\tLossActor: 0.00262533 \tLossCritic : 0.00060162(tensor([[-0.1901,  0.3772, -0.2947, -0.2880]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3724, 0.3712, 0.3705, 0.3716]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1005\tAverage Score: 37.66\tScore: 39.37\tLossActor: 0.00262902 \tLossCritic : 0.00060157(tensor([[ 0.4651, -0.2219, -0.1398, -0.2486]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3696, 0.3690, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1006\tAverage Score: 37.71\tScore: 39.25\tLossActor: 0.00263045 \tLossCritic : 0.00060159(tensor([[ 0.2497, -0.4912,  0.2216, -0.4433]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3693, 0.3689, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1007\tAverage Score: 37.71\tScore: 35.96\tLossActor: 0.00264094 \tLossCritic : 0.00060182(tensor([[-0.0331, -0.0688, -0.3205,  0.7354]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3690, 0.3688, 0.3691]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1008\tAverage Score: 37.71\tScore: 39.03\tLossActor: 0.00264529 \tLossCritic : 0.00060180(tensor([[-0.1916,  0.3742,  0.4388, -0.1089]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3735, 0.3713, 0.3707, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1009\tAverage Score: 37.77\tScore: 39.53\tLossActor: 0.00264725 \tLossCritic : 0.00060173(tensor([[ 0.1174,  0.1963, -0.2209,  0.2924]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3720, 0.3704, 0.3698, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1010\tAverage Score: 37.75\tScore: 37.63\tLossActor: 0.00265423 \tLossCritic : 0.00060181(tensor([[ 0.3265,  0.1355,  0.7260, -0.6528]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3690, 0.3687, 0.3688]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1011\tAverage Score: 37.73\tScore: 37.03\tLossActor: 0.00265994 \tLossCritic : 0.00060194(tensor([[0.4724, 0.5406, 0.0125, 0.5829]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3726, 0.3702, 0.3695, 0.3694]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1012\tAverage Score: 37.74\tScore: 38.23\tLossActor: 0.00266235 \tLossCritic : 0.00060199(tensor([[-0.2951,  0.4046, -0.1999,  0.4531]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3724, 0.3696, 0.3691, 0.3690]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1013\tAverage Score: 37.76\tScore: 38.87\tLossActor: 0.00266551 \tLossCritic : 0.00060191(tensor([[-0.1374,  0.0375,  0.0285, -0.2241]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3750, 0.3715, 0.3706, 0.3705]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1014\tAverage Score: 37.75\tScore: 39.01\tLossActor: 0.00266428 \tLossCritic : 0.00060193(tensor([[ 0.1672, -0.1776, -0.0642,  0.5949]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3726, 0.3705, 0.3698, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1015\tAverage Score: 37.76\tScore: 39.42\tLossActor: 0.00266637 \tLossCritic : 0.00060180(tensor([[ 0.0382, -0.3177, -0.1407, -0.5183]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3719, 0.3703, 0.3697, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1016\tAverage Score: 37.75\tScore: 38.92\tLossActor: 0.00266757 \tLossCritic : 0.00060180(tensor([[-0.2185,  0.2694, -0.4937,  0.0818]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3722, 0.3704, 0.3698, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1017\tAverage Score: 37.73\tScore: 37.09\tLossActor: 0.00267020 \tLossCritic : 0.00060195(tensor([[ 0.0288, -0.3633, -0.2953, -0.4598]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3717, 0.3703, 0.3697, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1018\tAverage Score: 37.71\tScore: 36.83\tLossActor: 0.00267943 \tLossCritic : 0.00060208(tensor([[ 0.2135,  0.2770, -0.2206,  0.5187]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3707, 0.3695, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1019\tAverage Score: 37.71\tScore: 39.30\tLossActor: 0.00267922 \tLossCritic : 0.00060205(tensor([[-0.1205, -0.0606, -0.3235,  0.1436]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3726, 0.3719, 0.3704, 0.3715]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1020\tAverage Score: 37.71\tScore: 39.26\tLossActor: 0.00268210 \tLossCritic : 0.00060195(tensor([[ 0.3262, -0.5113,  0.1591, -0.0482]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3709, 0.3712, 0.3697, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1021\tAverage Score: 37.75\tScore: 38.53\tLossActor: 0.00268355 \tLossCritic : 0.00060194(tensor([[-0.2752, -0.1728, -0.0669,  0.1536]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3704, 0.3701, 0.3693, 0.3703]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1022\tAverage Score: 37.74\tScore: 38.59\tLossActor: 0.00268257 \tLossCritic : 0.00060204(tensor([[ 0.1313, -0.0172,  0.2649,  0.1906]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3699, 0.3691, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1023\tAverage Score: 37.74\tScore: 39.20\tLossActor: 0.00268757 \tLossCritic : 0.00060196(tensor([[-0.0464, -0.2290, -0.3181, -0.4676]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3714, 0.3698, 0.3707]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1024\tAverage Score: 37.66\tScore: 27.55\tLossActor: 0.00271335 \tLossCritic : 0.00060243(tensor([[-0.4066, -0.1305,  0.8203,  0.6278]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3705, 0.3691, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1025\tAverage Score: 37.65\tScore: 38.60\tLossActor: 0.00271247 \tLossCritic : 0.00060252(tensor([[0.3225, 0.2204, 0.3113, 0.0441]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3694, 0.3719, 0.3695, 0.3705]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1026\tAverage Score: 37.65\tScore: 39.12\tLossActor: 0.00261856 \tLossCritic : 0.00060251(tensor([[ 0.2180,  0.0809,  0.0092, -0.0605]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3728, 0.3698, 0.3710]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1027\tAverage Score: 37.65\tScore: 39.25\tLossActor: 0.00260869 \tLossCritic : 0.00060252(tensor([[ 0.1998,  0.1108,  0.6700, -0.4707]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3710, 0.3691, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1028\tAverage Score: 37.67\tScore: 39.19\tLossActor: 0.00260435 \tLossCritic : 0.00060241(tensor([[-0.1610,  0.0578,  0.4946,  0.0118]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3725, 0.3700, 0.3718]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1029\tAverage Score: 37.74\tScore: 38.40\tLossActor: 0.00257691 \tLossCritic : 0.00060245(tensor([[ 0.5913,  0.0333, -0.0420, -0.2345]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3691, 0.3708, 0.3692, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1030\tAverage Score: 37.73\tScore: 37.72\tLossActor: 0.00257582 \tLossCritic : 0.00060252(tensor([[ 0.0439,  0.3197, -0.1784,  0.6283]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3712, 0.3694, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1031\tAverage Score: 37.73\tScore: 38.63\tLossActor: 0.00257465 \tLossCritic : 0.00060261(tensor([[-0.0009,  0.3222,  0.2231,  0.3566]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3714, 0.3698, 0.3713]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1032\tAverage Score: 37.73\tScore: 39.44\tLossActor: 0.00257341 \tLossCritic : 0.00060256(tensor([[ 0.2836,  0.5177, -0.3919,  0.0118]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3709, 0.3694, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1033\tAverage Score: 37.74\tScore: 39.48\tLossActor: 0.00256859 \tLossCritic : 0.00060254(tensor([[-0.1184,  0.4389, -0.2150,  0.5024]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3713, 0.3697, 0.3711]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1034\tAverage Score: 37.77\tScore: 38.94\tLossActor: 0.00256594 \tLossCritic : 0.00060251(tensor([[ 0.3041,  0.0142,  0.2417, -0.2729]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3698, 0.3690, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1035\tAverage Score: 37.77\tScore: 39.13\tLossActor: 0.00256495 \tLossCritic : 0.00060250(tensor([[ 0.3058, -0.2802,  0.4123,  0.5033]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3707, 0.3696, 0.3705]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1036\tAverage Score: 37.77\tScore: 39.17\tLossActor: 0.00256203 \tLossCritic : 0.00060251(tensor([[ 0.3353, -0.0779,  0.2299, -0.0537]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3703, 0.3694, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1037\tAverage Score: 37.77\tScore: 37.70\tLossActor: 0.00256506 \tLossCritic : 0.00060258(tensor([[ 0.5368,  0.4621,  0.5294, -0.1539]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3697, 0.3691, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1038\tAverage Score: 37.76\tScore: 39.11\tLossActor: 0.00256439 \tLossCritic : 0.00060254(tensor([[-0.1672,  0.2327, -0.6322, -0.4637]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3707, 0.3697, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1039\tAverage Score: 37.79\tScore: 39.01\tLossActor: 0.00256540 \tLossCritic : 0.00060253(tensor([[ 0.1595,  0.2981, -0.4018,  0.3651]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3698, 0.3703, 0.3694, 0.3698]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1040\tAverage Score: 37.81\tScore: 38.59\tLossActor: 0.00256641 \tLossCritic : 0.00060261(tensor([[0.4500, 0.1917, 0.5363, 0.3217]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3701, 0.3691, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1041\tAverage Score: 37.80\tScore: 38.40\tLossActor: 0.00256898 \tLossCritic : 0.00060258(tensor([[-0.1442,  0.8052,  0.0354,  0.1717]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3702, 0.3707, 0.3697, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1042\tAverage Score: 37.94\tScore: 38.51\tLossActor: 0.00256972 \tLossCritic : 0.00060258(tensor([[ 0.1342, -0.2804, -0.1355, -0.4406]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3698, 0.3691, 0.3693]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1043\tAverage Score: 38.05\tScore: 39.07\tLossActor: 0.00257021 \tLossCritic : 0.00060250(tensor([[ 0.2428, -0.3949, -0.2508, -0.1045]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3706, 0.3716, 0.3703, 0.3710]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1044\tAverage Score: 38.19\tScore: 38.17\tLossActor: 0.00257416 \tLossCritic : 0.00060245(tensor([[ 0.0729,  0.2030,  0.0266, -0.0794]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3705, 0.3706, 0.3698, 0.3703]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1045\tAverage Score: 38.31\tScore: 39.28\tLossActor: 0.00257093 \tLossCritic : 0.00060246(tensor([[0.2448, 0.4011, 0.3037, 0.5902]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3696, 0.3690, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1046\tAverage Score: 38.31\tScore: 39.29\tLossActor: 0.00257013 \tLossCritic : 0.00060244(tensor([[-0.3202,  0.0463,  0.1171,  0.4538]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3709, 0.3706, 0.3698, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1047\tAverage Score: 38.36\tScore: 38.58\tLossActor: 0.00257452 \tLossCritic : 0.00060232(tensor([[ 0.4579,  0.4075,  0.3531, -0.0978]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3697, 0.3697, 0.3691, 0.3696]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1048\tAverage Score: 38.35\tScore: 37.35\tLossActor: 0.00258145 \tLossCritic : 0.00060239(tensor([[-0.3773,  0.2392, -0.6357,  0.4678]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3708, 0.3704, 0.3699, 0.3708]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1049\tAverage Score: 38.36\tScore: 39.37\tLossActor: 0.00258289 \tLossCritic : 0.00060223(tensor([[ 0.2713,  0.2758, -0.2125, -0.0559]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3715, 0.3708, 0.3704, 0.3713]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1050\tAverage Score: 38.35\tScore: 38.34\tLossActor: 0.00258613 \tLossCritic : 0.00060214(tensor([[ 0.1286, -0.3399, -0.3146, -0.5274]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3699, 0.3697, 0.3694, 0.3701]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1051\tAverage Score: 38.35\tScore: 38.04\tLossActor: 0.00259194 \tLossCritic : 0.00060204(tensor([[ 0.2644,  0.1784, -0.1197, -0.2101]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3699, 0.3695, 0.3700]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1052\tAverage Score: 38.39\tScore: 39.30\tLossActor: 0.00259460 \tLossCritic : 0.00060200(tensor([[ 0.2364, -0.5201, -0.1396, -0.4577]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3692, 0.3690, 0.3689, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1053\tAverage Score: 38.41\tScore: 39.41\tLossActor: 0.00259277 \tLossCritic : 0.00060195(tensor([[0.5469, 0.1736, 0.3900, 0.4681]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3700, 0.3696, 0.3693, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1054\tAverage Score: 38.40\tScore: 37.36\tLossActor: 0.00260483 \tLossCritic : 0.00060203(tensor([[-0.3901,  0.3146, -0.2248,  0.9763]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.3694, 0.3693, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1055\tAverage Score: 38.21\tScore: 17.76\tLossActor: 0.00265687 \tLossCritic : 0.00060308(tensor([[-0.4585,  0.4864,  0.5137, -0.7248]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3719, 0.3710, 0.3708, 0.3704]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1056\tAverage Score: 37.88\tScore: 6.50\tLossActor: 0.00273843 \tLossCritic : 0.00060466(tensor([[-0.2593,  0.0434, -0.5704,  0.3704]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3680, 0.3679, 0.3680, 0.3679]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1057\tAverage Score: 37.64\tScore: 14.57\tLossActor: 0.00280095 \tLossCritic : 0.00060623(tensor([[ 0.8828,  0.0935, -0.9866,  0.7415]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3685, 0.3684, 0.3686, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1058\tAverage Score: 37.43\tScore: 18.08\tLossActor: 0.00285221 \tLossCritic : 0.00060765(tensor([[ 0.2796,  0.1127, -0.4384,  0.2194]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3696, 0.3701, 0.3705, 0.3697]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1059\tAverage Score: 37.25\tScore: 21.05\tLossActor: 0.00300262 \tLossCritic : 0.00060923(tensor([[-0.7403, -0.0996,  0.6378, -0.1477]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3695, 0.3698, 0.3703, 0.3695]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1060\tAverage Score: 36.93\tScore: 4.69\tLossActor: 0.00310632 \tLossCritic : 0.00061232(tensor([[-0.8801, -0.0479,  0.9372,  0.3453]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3703, 0.3705, 0.3696, 0.3692]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1061\tAverage Score: 36.56\tScore: 2.96\tLossActor: 0.00388441 \tLossCritic : 0.00061727(tensor([[-0.1058, -0.9832, -0.1362,  0.9673]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3683, 0.3693, 0.3686, 0.3684]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1062\tAverage Score: 36.19\tScore: 1.85\tLossActor: 0.00407923 \tLossCritic : 0.00062203(tensor([[-0.9457,  0.4494, -0.8457,  0.6217]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3693, 0.3734, 0.3696, 0.3686]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1063\tAverage Score: 35.82\tScore: 2.32\tLossActor: 0.00421338 \tLossCritic : 0.00062491(tensor([[-0.7342,  0.5703,  0.0532,  0.4199]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3797, 0.4368, 0.3926, 0.3755]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1064\tAverage Score: 35.44\tScore: 1.38\tLossActor: 0.00447018 \tLossCritic : 0.00062827(tensor([[0.4152, 0.0879, 0.6968, 0.9760]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3701, 0.5296, 0.4137, 0.3795]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1065\tAverage Score: 35.06\tScore: 1.57\tLossActor: 0.00459398 \tLossCritic : 0.00063039(tensor([[ 0.8769, -0.9084, -0.9819,  0.9531]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3690, 1.1012, 0.6305, 0.5000]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1066\tAverage Score: 34.71\tScore: 3.25\tLossActor: 0.00470459 \tLossCritic : 0.00063215(tensor([[ 0.9057, -0.6594,  0.6258,  0.3128]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3722, 1.5976, 0.9754, 0.6070]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1067\tAverage Score: 34.34\tScore: 2.56\tLossActor: 0.00479917 \tLossCritic : 0.00063485(tensor([[-0.3442, -0.4485,  0.5762,  0.0882]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3897, 2.2835, 1.2296, 1.1479]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1068\tAverage Score: 33.97\tScore: 2.02\tLossActor: 0.00505157 \tLossCritic : 0.00063772(tensor([[ 0.9837, -0.3345,  0.9261, -0.5821]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.3988, 2.7008, 2.6731, 2.5216]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1069\tAverage Score: 33.64\tScore: 0.19\tLossActor: 0.00565809 \tLossCritic : 0.00064007(tensor([[ 0.8557,  0.7608, -0.9779,  0.2860]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[0.7377, 2.6995, 2.7071, 2.6624]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1070\tAverage Score: 33.30\tScore: 1.18\tLossActor: 0.00637700 \tLossCritic : 0.00064187(tensor([[-0.6641,  0.5519, -0.6002,  0.9799]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[1.9507, 2.7157, 2.7138, 2.7130]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1071\tAverage Score: 32.94\tScore: 2.59\tLossActor: 0.00807849 \tLossCritic : 0.00064333(tensor([[-0.7487,  0.8479, -0.7265,  0.6849]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.0256, 2.7066, 2.7011, 2.6801]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1072\tAverage Score: 32.55\tScore: 0.36\tLossActor: 0.01003418 \tLossCritic : 0.00064464(tensor([[-0.9578, -0.1767, -0.5538,  0.9907]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.5368, 2.7117, 2.7059, 2.7111]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1073\tAverage Score: 32.16\tScore: 0.09\tLossActor: 0.01270754 \tLossCritic : 0.00064554(tensor([[-0.9996, -0.9640, -0.9998,  0.9917]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.6835, 2.7182, 2.7179, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1074\tAverage Score: 31.82\tScore: 1.60\tLossActor: 0.02222691 \tLossCritic : 0.00064665(tensor([[-0.9733, -0.8273, -0.9579,  0.9962]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7073, 2.7181, 2.7180, 2.7180]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1075\tAverage Score: 31.44\tScore: 1.58\tLossActor: 0.02370104 \tLossCritic : 0.00064742(tensor([[-0.9958, -0.9984, -0.9972,  0.9996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7112, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1076\tAverage Score: 31.06\tScore: 0.53\tLossActor: 0.02455409 \tLossCritic : 0.00064812(tensor([[-0.9851, -0.9998, -0.9943,  0.9992]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7095, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1077\tAverage Score: 30.68\tScore: 0.54\tLossActor: 0.02899485 \tLossCritic : 0.00064853(tensor([[-1.0000, -0.9995, -1.0000,  0.9961]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7115, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1078\tAverage Score: 30.29\tScore: 0.10\tLossActor: 0.03041802 \tLossCritic : 0.00064890(tensor([[-0.9984, -0.9998, -0.9991,  0.9941]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7109, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1079\tAverage Score: 29.92\tScore: 0.00\tLossActor: 0.03597784 \tLossCritic : 0.00064927(tensor([[-0.9794,  0.4623, -1.0000,  0.9995]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1080\tAverage Score: 29.53\tScore: 0.00\tLossActor: 0.03703137 \tLossCritic : 0.00064957(tensor([[-0.9997, -0.9088, -0.9995,  0.9993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7174, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1081\tAverage Score: 29.20\tScore: 1.43\tLossActor: 0.03774713 \tLossCritic : 0.00064994(tensor([[-1.0000, -0.9999, -0.9976,  0.9323]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7142, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1082\tAverage Score: 28.83\tScore: 1.12\tLossActor: 0.03839152 \tLossCritic : 0.00065034(tensor([[-0.8706,  0.0480, -0.9253,  0.9917]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7165, 2.7183, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1083\tAverage Score: 28.45\tScore: 1.52\tLossActor: 0.04009359 \tLossCritic : 0.00065061(tensor([[-0.9962, -0.9998, -0.9800,  0.9980]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7171, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1084\tAverage Score: 28.06\tScore: 0.25\tLossActor: 0.04046192 \tLossCritic : 0.00065069(tensor([[-0.9999, -0.9998, -0.9999,  0.9994]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7177, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1085\tAverage Score: 27.67\tScore: 0.07\tLossActor: 0.04090149 \tLossCritic : 0.00065070(tensor([[-0.9982, -0.2328, -1.0000,  0.9996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1086\tAverage Score: 27.28\tScore: 0.00\tLossActor: 0.04196198 \tLossCritic : 0.00065057(tensor([[-0.9995, -1.0000, -0.9954,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7173, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1087\tAverage Score: 26.89\tScore: 0.99\tLossActor: 0.04295202 \tLossCritic : 0.00065062(tensor([[-0.9971, -0.9796, -0.9997,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7176, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1088\tAverage Score: 26.50\tScore: 0.17\tLossActor: 0.04360916 \tLossCritic : 0.00065076(tensor([[-0.9992, -0.9925, -1.0000,  0.9990]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7174, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1089\tAverage Score: 26.12\tScore: 0.77\tLossActor: 0.04503658 \tLossCritic : 0.00065090(tensor([[-0.9948, -0.9287, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1090\tAverage Score: 25.73\tScore: 0.00\tLossActor: 0.04668167 \tLossCritic : 0.00065096(tensor([[-0.9988, -0.7085, -0.9906,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1091\tAverage Score: 25.34\tScore: 0.83\tLossActor: 0.04704336 \tLossCritic : 0.00065085(tensor([[-0.9925,  0.8164, -1.0000,  0.9995]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7170, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1092\tAverage Score: 24.96\tScore: 0.71\tLossActor: 0.04737767 \tLossCritic : 0.00065087(tensor([[-0.9972, -0.3495, -0.9999,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7120, 2.7182, 2.7182, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1093\tAverage Score: 24.57\tScore: 0.59\tLossActor: 0.04808424 \tLossCritic : 0.00065087(tensor([[-0.9936, -0.7762, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1094\tAverage Score: 24.19\tScore: 0.62\tLossActor: 0.04970225 \tLossCritic : 0.00065096(tensor([[-0.9971, -0.9953, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1095\tAverage Score: 23.91\tScore: 0.79\tLossActor: 0.05003526 \tLossCritic : 0.00065085(tensor([[-0.9976,  0.4675, -1.0000,  0.9995]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1096\tAverage Score: 23.53\tScore: 0.63\tLossActor: 0.05033920 \tLossCritic : 0.00065079(tensor([[-0.9995, -0.9998, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1097\tAverage Score: 23.14\tScore: 0.05\tLossActor: 0.05077150 \tLossCritic : 0.00065050(tensor([[-0.9988, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1098\tAverage Score: 22.77\tScore: 1.57\tLossActor: 0.05165508 \tLossCritic : 0.00065036(tensor([[-1.0000, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1099\tAverage Score: 22.39\tScore: 1.69\tLossActor: 0.05195089 \tLossCritic : 0.00065037(tensor([[-1.0000, -0.9597, -0.9983,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100\tAverage Score: 22.01\tScore: 1.75\tLossActor: 0.05221912 \tLossCritic : 0.00065062(tensor([[-0.9991, -0.9963, -0.9181,  0.9576]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7048, 2.7181, 2.7176, 2.7179]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1100\tAverage Score: 22.01\n",
      "Episode 1101\tAverage Score: 21.63\tScore: 0.51\tLossActor: 0.05454400 \tLossCritic : 0.00065065(tensor([[-0.9942, -0.9995, -0.9999,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1102\tAverage Score: 21.25\tScore: 1.42\tLossActor: 0.05527746 \tLossCritic : 0.00065072(tensor([[-0.9937, -0.9995, -0.9920,  0.9975]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7158, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1103\tAverage Score: 20.87\tScore: 0.82\tLossActor: 0.09787688 \tLossCritic : 0.00065071(tensor([[-1.0000, -0.6723, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1104\tAverage Score: 20.49\tScore: 0.47\tLossActor: 0.09952929 \tLossCritic : 0.00065065(tensor([[-1.0000, -0.9853, -1.0000,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7176, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1105\tAverage Score: 20.09\tScore: 0.00\tLossActor: 0.10098453 \tLossCritic : 0.00065031(tensor([[-1.0000, -0.9998, -0.9997,  0.9992]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1106\tAverage Score: 19.71\tScore: 0.79\tLossActor: 0.10147943 \tLossCritic : 0.00065034(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1107\tAverage Score: 19.35\tScore: 0.20\tLossActor: 0.10176445 \tLossCritic : 0.00065041(tensor([[-1.0000, -1.0000, -0.9997,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1108\tAverage Score: 18.97\tScore: 0.62\tLossActor: 0.10216469 \tLossCritic : 0.00065048(tensor([[-1.0000, -0.9996, -0.9998,  0.9989]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7155, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1109\tAverage Score: 18.59\tScore: 1.42\tLossActor: 0.10239391 \tLossCritic : 0.00065045(tensor([[-0.9903,  0.3144, -1.0000,  0.9993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7161, 2.7182, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1110\tAverage Score: 18.21\tScore: 0.25\tLossActor: 0.10286076 \tLossCritic : 0.00065036(tensor([[-0.9998, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1111\tAverage Score: 17.84\tScore: 0.20\tLossActor: 0.10325998 \tLossCritic : 0.00065029(tensor([[-0.9997, -0.9991, -0.9881,  0.9936]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7170, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1112\tAverage Score: 17.47\tScore: 0.58\tLossActor: 0.10370994 \tLossCritic : 0.00065024(tensor([[-0.9997, -0.9366, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1113\tAverage Score: 17.08\tScore: 0.34\tLossActor: 0.10405693 \tLossCritic : 0.00065010(tensor([[-0.9995, -0.9935, -0.9984,  0.9978]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7141, 2.7182, 2.7181, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1114\tAverage Score: 16.70\tScore: 0.67\tLossActor: 0.10424805 \tLossCritic : 0.00064997(tensor([[-0.9999, -1.0000, -0.9995,  0.9193]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7174, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1115\tAverage Score: 16.31\tScore: 0.55\tLossActor: 0.10480487 \tLossCritic : 0.00064996(tensor([[-0.9998, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1116\tAverage Score: 15.93\tScore: 1.16\tLossActor: 0.10582728 \tLossCritic : 0.00064985(tensor([[-0.9988, -0.9998, -0.9994,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1117\tAverage Score: 15.56\tScore: 0.00\tLossActor: 0.10625245 \tLossCritic : 0.00064973(tensor([[-0.9999, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1118\tAverage Score: 15.20\tScore: 0.43\tLossActor: 0.10641549 \tLossCritic : 0.00064954(tensor([[-0.9995, -0.9999, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1119\tAverage Score: 14.80\tScore: 0.00\tLossActor: 0.10671092 \tLossCritic : 0.00064938(tensor([[-0.9994, -0.9982, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1120\tAverage Score: 14.42\tScore: 0.51\tLossActor: 0.10746697 \tLossCritic : 0.00064915(tensor([[-0.9989, -0.9999, -0.9975,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1121\tAverage Score: 14.04\tScore: 0.59\tLossActor: 0.10779916 \tLossCritic : 0.00064898(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1122\tAverage Score: 13.67\tScore: 1.50\tLossActor: 0.10820986 \tLossCritic : 0.00064891(tensor([[-0.9999, -1.0000, -0.9877,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1123\tAverage Score: 13.29\tScore: 1.52\tLossActor: 0.10836504 \tLossCritic : 0.00064888(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1124\tAverage Score: 13.02\tScore: 0.79\tLossActor: 0.10852294 \tLossCritic : 0.00064867(tensor([[-0.9999, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1125\tAverage Score: 12.64\tScore: 0.00\tLossActor: 0.10888183 \tLossCritic : 0.00064851(tensor([[-0.9900, -0.9566, -1.0000,  0.9967]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1126\tAverage Score: 12.26\tScore: 1.20\tLossActor: 0.10911080 \tLossCritic : 0.00064841(tensor([[-0.9999, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1127\tAverage Score: 11.87\tScore: 1.09\tLossActor: 0.10933813 \tLossCritic : 0.00064823(tensor([[-0.9865, -0.9981, -0.9971,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1128\tAverage Score: 11.49\tScore: 0.31\tLossActor: 0.11021762 \tLossCritic : 0.00064792(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1129\tAverage Score: 11.13\tScore: 2.44\tLossActor: 0.11067176 \tLossCritic : 0.00064771(tensor([[-0.9976, -0.9982, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1130\tAverage Score: 10.76\tScore: 0.68\tLossActor: 0.11100032 \tLossCritic : 0.00064746(tensor([[-1.0000, -1.0000, -1.0000,  0.9994]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1131\tAverage Score: 10.38\tScore: 1.21\tLossActor: 0.11136902 \tLossCritic : 0.00064725(tensor([[-1.0000, -1.0000, -0.9999,  0.9994]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7177, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1132\tAverage Score: 9.99\tScore: 0.39\tLossActor: 0.11160216 \tLossCritic : 0.00064698(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1133\tAverage Score: 9.62\tScore: 2.09\tLossActor: 0.11171836 \tLossCritic : 0.00064678(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1134\tAverage Score: 9.23\tScore: 0.49\tLossActor: 0.11188039 \tLossCritic : 0.00064634(tensor([[-0.9950, -0.9986, -0.9996,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1135\tAverage Score: 8.84\tScore: 0.27\tLossActor: 0.11216687 \tLossCritic : 0.00064594(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1136\tAverage Score: 8.46\tScore: 0.48\tLossActor: 0.11231771 \tLossCritic : 0.00064570(tensor([[-0.9982,  0.5567, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1137\tAverage Score: 8.08\tScore: 0.31\tLossActor: 0.11245018 \tLossCritic : 0.00064551(tensor([[-0.9999, -1.0000, -0.9986,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1138\tAverage Score: 7.69\tScore: 0.14\tLossActor: 0.11257172 \tLossCritic : 0.00064526(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1139\tAverage Score: 7.31\tScore: 0.80\tLossActor: 0.11279038 \tLossCritic : 0.00064499(tensor([[-0.9992, -1.0000, -0.9972,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1140\tAverage Score: 6.93\tScore: 0.82\tLossActor: 0.11339348 \tLossCritic : 0.00064476(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1141\tAverage Score: 6.56\tScore: 1.11\tLossActor: 0.11352472 \tLossCritic : 0.00064437(tensor([[-0.9986, -0.9427, -0.9999,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1142\tAverage Score: 6.19\tScore: 1.75\tLossActor: 0.11367711 \tLossCritic : 0.00064404(tensor([[-0.9998, -0.9871, -0.9994,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7163, 2.7183, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1143\tAverage Score: 5.81\tScore: 0.29\tLossActor: 0.11384557 \tLossCritic : 0.00064366(tensor([[-0.9944, -0.9773, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1144\tAverage Score: 5.44\tScore: 1.82\tLossActor: 0.11410977 \tLossCritic : 0.00064331(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1145\tAverage Score: 5.06\tScore: 0.61\tLossActor: 0.11442384 \tLossCritic : 0.00064290(tensor([[-0.9995, -0.9998, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1146\tAverage Score: 4.67\tScore: 0.29\tLossActor: 0.11492367 \tLossCritic : 0.00064255(tensor([[-0.9997, -0.9997, -0.9987,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7177, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1147\tAverage Score: 4.28\tScore: 0.23\tLossActor: 0.12249693 \tLossCritic : 0.00064223(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1148\tAverage Score: 3.91\tScore: 0.55\tLossActor: 0.12270426 \tLossCritic : 0.00064183(tensor([[-0.9999, -0.9443, -1.0000,  0.9966]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1149\tAverage Score: 3.52\tScore: 0.34\tLossActor: 0.12292175 \tLossCritic : 0.00064143(tensor([[-0.9994, -0.4296, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1150\tAverage Score: 3.16\tScore: 2.06\tLossActor: 0.12328526 \tLossCritic : 0.00064116(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1151\tAverage Score: 2.78\tScore: 0.45\tLossActor: 0.12341540 \tLossCritic : 0.00064074(tensor([[-1.0000, -1.0000, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1152\tAverage Score: 2.40\tScore: 1.29\tLossActor: 0.12358941 \tLossCritic : 0.00064031(tensor([[-1.0000, -0.9995, -1.0000,  0.9988]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7167, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1153\tAverage Score: 2.01\tScore: 0.31\tLossActor: 0.12373012 \tLossCritic : 0.00063980(tensor([[-0.9994, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1154\tAverage Score: 1.64\tScore: 0.47\tLossActor: 0.12383218 \tLossCritic : 0.00063927(tensor([[-1.0000, -0.9987, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1155\tAverage Score: 1.48\tScore: 1.05\tLossActor: 0.12509933 \tLossCritic : 0.00063894(tensor([[-0.9999, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1156\tAverage Score: 1.43\tScore: 1.43\tLossActor: 0.12516305 \tLossCritic : 0.00063882(tensor([[-0.9992, -1.0000, -0.9995,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1157\tAverage Score: 1.28\tScore: 0.00\tLossActor: 0.12523293 \tLossCritic : 0.00063846(tensor([[-0.9999, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1158\tAverage Score: 1.10\tScore: 0.35\tLossActor: 0.13012691 \tLossCritic : 0.00063814(tensor([[-0.9996, -0.9704, -1.0000,  0.9990]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1159\tAverage Score: 0.91\tScore: 1.18\tLossActor: 0.13018714 \tLossCritic : 0.00063777(tensor([[-0.9997, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1160\tAverage Score: 0.86\tScore: 0.00\tLossActor: 0.13026787 \tLossCritic : 0.00063743(tensor([[-1.0000, -0.9999, -0.9979,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7168, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1161\tAverage Score: 0.83\tScore: 0.47\tLossActor: 0.13042130 \tLossCritic : 0.00063713(tensor([[-1.0000, -1.0000, -0.9987,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1162\tAverage Score: 0.82\tScore: 0.29\tLossActor: 0.13059615 \tLossCritic : 0.00063666(tensor([[-0.9994, -0.9999, -0.9992,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7174, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1163\tAverage Score: 0.80\tScore: 0.68\tLossActor: 0.13066131 \tLossCritic : 0.00063632(tensor([[-1.0000, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1164\tAverage Score: 0.80\tScore: 0.74\tLossActor: 0.13072114 \tLossCritic : 0.00063601(tensor([[-1.0000, -1.0000, -0.9989,  0.9964]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1165\tAverage Score: 0.79\tScore: 1.52\tLossActor: 0.13080698 \tLossCritic : 0.00063589(tensor([[-0.9998, -0.9873, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1166\tAverage Score: 0.76\tScore: 0.14\tLossActor: 0.13089330 \tLossCritic : 0.00063564(tensor([[-1.0000, -0.9969, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1167\tAverage Score: 0.75\tScore: 0.70\tLossActor: 0.13101046 \tLossCritic : 0.00063539(tensor([[-1.0000, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1168\tAverage Score: 0.73\tScore: 0.71\tLossActor: 0.13138945 \tLossCritic : 0.00063513(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1169\tAverage Score: 0.73\tScore: 0.18\tLossActor: 0.13202511 \tLossCritic : 0.00063473(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1170\tAverage Score: 0.73\tScore: 0.65\tLossActor: 0.13216506 \tLossCritic : 0.00063432(tensor([[-0.9998, -0.9996, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1171\tAverage Score: 0.70\tScore: 0.41\tLossActor: 0.13290016 \tLossCritic : 0.00063386(tensor([[-1.0000, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1172\tAverage Score: 0.70\tScore: 0.00\tLossActor: 0.13298470 \tLossCritic : 0.00063350(tensor([[-0.9998, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1173\tAverage Score: 0.70\tScore: 0.22\tLossActor: 0.13302286 \tLossCritic : 0.00063306(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1174\tAverage Score: 0.69\tScore: 0.15\tLossActor: 0.13343056 \tLossCritic : 0.00063269(tensor([[-1.0000, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1175\tAverage Score: 0.67\tScore: 0.00\tLossActor: 0.13354303 \tLossCritic : 0.00063212(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1176\tAverage Score: 0.67\tScore: 0.71\tLossActor: 0.13361777 \tLossCritic : 0.00063166(tensor([[-0.9995, -0.9718, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1177\tAverage Score: 0.67\tScore: 0.25\tLossActor: 0.13369298 \tLossCritic : 0.00063123(tensor([[-1.0000, -0.9999, -1.0000,  0.9996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1178\tAverage Score: 0.68\tScore: 0.86\tLossActor: 0.13380887 \tLossCritic : 0.00063097(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1179\tAverage Score: 0.69\tScore: 0.89\tLossActor: 0.13418585 \tLossCritic : 0.00063053(tensor([[-1.0000, -0.9997, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1180\tAverage Score: 0.69\tScore: 0.23\tLossActor: 0.13426669 \tLossCritic : 0.00063024(tensor([[-1.0000, -1.0000, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1181\tAverage Score: 0.68\tScore: 0.33\tLossActor: 0.13454233 \tLossCritic : 0.00062977(tensor([[-0.9961, -0.9855, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1182\tAverage Score: 0.69\tScore: 1.82\tLossActor: 0.13465957 \tLossCritic : 0.00062940(tensor([[-0.9987, -0.9996, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1183\tAverage Score: 0.68\tScore: 0.95\tLossActor: 0.13480192 \tLossCritic : 0.00062901(tensor([[-0.9999, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1184\tAverage Score: 0.68\tScore: 0.58\tLossActor: 0.13500094 \tLossCritic : 0.00062879(tensor([[-0.9999, -1.0000, -1.0000,  0.9996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1185\tAverage Score: 0.68\tScore: 0.18\tLossActor: 0.13511035 \tLossCritic : 0.00062847(tensor([[-0.9997, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1186\tAverage Score: 0.68\tScore: 0.00\tLossActor: 0.13518660 \tLossCritic : 0.00062792(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1187\tAverage Score: 0.68\tScore: 0.74\tLossActor: 0.13523181 \tLossCritic : 0.00062764(tensor([[-0.9999, -0.9995, -0.9983,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1188\tAverage Score: 0.68\tScore: 0.02\tLossActor: 0.13533612 \tLossCritic : 0.00062720(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1189\tAverage Score: 0.68\tScore: 0.45\tLossActor: 0.13574158 \tLossCritic : 0.00062678(tensor([[-0.9992, -1.0000, -1.0000,  0.9968]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1190\tAverage Score: 0.68\tScore: 0.00\tLossActor: 0.13580443 \tLossCritic : 0.00062640(tensor([[-1.0000, -0.9999, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1191\tAverage Score: 0.67\tScore: 0.19\tLossActor: 0.13586697 \tLossCritic : 0.00062589(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1192\tAverage Score: 0.66\tScore: 0.00\tLossActor: 0.13604951 \tLossCritic : 0.00062540(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1193\tAverage Score: 0.66\tScore: 0.00\tLossActor: 0.13610804 \tLossCritic : 0.00062485(tensor([[-0.9999, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1194\tAverage Score: 0.65\tScore: 0.31\tLossActor: 0.13620774 \tLossCritic : 0.00062429(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1195\tAverage Score: 0.65\tScore: 0.03\tLossActor: 0.13623776 \tLossCritic : 0.00062363(tensor([[-0.9996, -1.0000, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1196\tAverage Score: 0.65\tScore: 1.00\tLossActor: 0.13628039 \tLossCritic : 0.00062321(tensor([[-1.0000, -0.9995, -1.0000,  0.9971]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7177, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1197\tAverage Score: 0.66\tScore: 1.00\tLossActor: 0.13635470 \tLossCritic : 0.00062286(tensor([[-1.0000, -0.9963, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1198\tAverage Score: 0.65\tScore: 0.40\tLossActor: 0.13645490 \tLossCritic : 0.00062248(tensor([[-0.9959, -0.9862, -1.0000,  0.9991]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1199\tAverage Score: 0.63\tScore: 0.00\tLossActor: 0.13665114 \tLossCritic : 0.00062199(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1200\tAverage Score: 0.62\tScore: 0.30\tLossActor: 0.13669802 \tLossCritic : 0.00062156(tensor([[-1.0000, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1200\tAverage Score: 0.62\n",
      "Episode 1201\tAverage Score: 0.62\tScore: 0.73\tLossActor: 0.13673721 \tLossCritic : 0.00062118(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1202\tAverage Score: 0.61\tScore: 0.20\tLossActor: 0.13680151 \tLossCritic : 0.00062077(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1203\tAverage Score: 0.60\tScore: 0.29\tLossActor: 0.13690238 \tLossCritic : 0.00062050(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1204\tAverage Score: 0.61\tScore: 1.03\tLossActor: 0.13697736 \tLossCritic : 0.00062032(tensor([[-0.9956, -0.7857, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1205\tAverage Score: 0.61\tScore: 0.21\tLossActor: 0.13702010 \tLossCritic : 0.00061967(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1206\tAverage Score: 0.61\tScore: 0.82\tLossActor: 0.13708633 \tLossCritic : 0.00061925(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1207\tAverage Score: 0.61\tScore: 0.00\tLossActor: 0.13715832 \tLossCritic : 0.00061885(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1208\tAverage Score: 0.61\tScore: 0.73\tLossActor: 0.13763784 \tLossCritic : 0.00061828(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1209\tAverage Score: 0.60\tScore: 0.43\tLossActor: 0.13775265 \tLossCritic : 0.00061779(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1210\tAverage Score: 0.61\tScore: 1.16\tLossActor: 0.13812457 \tLossCritic : 0.00061729(tensor([[-0.9989, -0.9998, -1.0000,  0.9859]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7177, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1211\tAverage Score: 0.61\tScore: 0.00\tLossActor: 0.13815621 \tLossCritic : 0.00061671(tensor([[-0.9999, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1212\tAverage Score: 0.61\tScore: 0.54\tLossActor: 0.13822319 \tLossCritic : 0.00061609(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1213\tAverage Score: 0.60\tScore: 0.20\tLossActor: 0.13825563 \tLossCritic : 0.00061545(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1214\tAverage Score: 0.60\tScore: 0.28\tLossActor: 0.13830574 \tLossCritic : 0.00061477(tensor([[-0.9994, -1.0000, -0.9999,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1215\tAverage Score: 0.60\tScore: 0.43\tLossActor: 0.13845876 \tLossCritic : 0.00061422(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1216\tAverage Score: 0.59\tScore: 0.21\tLossActor: 0.13848498 \tLossCritic : 0.00061350(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1217\tAverage Score: 0.60\tScore: 1.12\tLossActor: 0.13853912 \tLossCritic : 0.00061313(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1218\tAverage Score: 0.60\tScore: 0.74\tLossActor: 0.13860153 \tLossCritic : 0.00061261(tensor([[-0.9998, -0.9393, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1219\tAverage Score: 0.62\tScore: 1.21\tLossActor: 0.13866365 \tLossCritic : 0.00061182(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1220\tAverage Score: 0.61\tScore: 0.00\tLossActor: 0.13874802 \tLossCritic : 0.00061093(tensor([[-0.9999, -0.9996, -0.9984,  0.9994]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1221\tAverage Score: 0.61\tScore: 0.15\tLossActor: 0.13877188 \tLossCritic : 0.00061034(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1222\tAverage Score: 0.59\tScore: 0.00\tLossActor: 0.13883656 \tLossCritic : 0.00060971(tensor([[-1.0000, -0.9998, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1223\tAverage Score: 0.58\tScore: 0.81\tLossActor: 0.13888113 \tLossCritic : 0.00060903(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1224\tAverage Score: 0.59\tScore: 0.86\tLossActor: 0.13896830 \tLossCritic : 0.00060838(tensor([[-0.9991, -0.9999, -0.9991,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1225\tAverage Score: 0.59\tScore: 0.79\tLossActor: 0.13902140 \tLossCritic : 0.00060775(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1226\tAverage Score: 0.60\tScore: 2.19\tLossActor: 0.13920002 \tLossCritic : 0.00060713(tensor([[-0.9968, -0.9897, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7176, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1227\tAverage Score: 0.60\tScore: 0.79\tLossActor: 0.13939500 \tLossCritic : 0.00060662(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1228\tAverage Score: 0.60\tScore: 0.00\tLossActor: 0.13944031 \tLossCritic : 0.00060588(tensor([[-1.0000, -0.9999, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1229\tAverage Score: 0.58\tScore: 0.89\tLossActor: 0.13955648 \tLossCritic : 0.00060542(tensor([[-0.9999, -0.9997, -0.9995,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7150, 2.7182, 2.7181, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1230\tAverage Score: 0.57\tScore: 0.00\tLossActor: 0.13959505 \tLossCritic : 0.00060478(tensor([[-0.9988, -1.0000, -0.9998,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1231\tAverage Score: 0.57\tScore: 0.61\tLossActor: 0.13965979 \tLossCritic : 0.00060421(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1232\tAverage Score: 0.57\tScore: 0.36\tLossActor: 0.13972108 \tLossCritic : 0.00060358(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1233\tAverage Score: 0.55\tScore: 0.11\tLossActor: 0.13973930 \tLossCritic : 0.00060294(tensor([[-0.9997, -0.9987, -0.9968,  0.9933]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7151, 2.7182, 2.7181, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1234\tAverage Score: 0.55\tScore: 0.21\tLossActor: 0.13978726 \tLossCritic : 0.00060245(tensor([[-0.9991, -0.9986, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1235\tAverage Score: 0.55\tScore: 0.87\tLossActor: 0.13986762 \tLossCritic : 0.00060172(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1236\tAverage Score: 0.55\tScore: 0.00\tLossActor: 0.13991648 \tLossCritic : 0.00060107(tensor([[-1.0000, -0.9999, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1237\tAverage Score: 0.55\tScore: 0.17\tLossActor: 0.13999648 \tLossCritic : 0.00060038(tensor([[-0.9999, -0.9995, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1238\tAverage Score: 0.56\tScore: 1.14\tLossActor: 0.14004368 \tLossCritic : 0.00059976(tensor([[-1.0000, -0.9999, -0.9971,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7175, 2.7183, 2.7182, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1239\tAverage Score: 0.56\tScore: 0.74\tLossActor: 0.14007819 \tLossCritic : 0.00059904(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1240\tAverage Score: 0.57\tScore: 2.13\tLossActor: 0.14017984 \tLossCritic : 0.00059851(tensor([[-0.9988, -0.8203, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1241\tAverage Score: 0.56\tScore: 0.37\tLossActor: 0.14141412 \tLossCritic : 0.00059804(tensor([[-1.0000, -1.0000, -0.9995,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1242\tAverage Score: 0.55\tScore: 0.22\tLossActor: 0.14145851 \tLossCritic : 0.00059721(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1243\tAverage Score: 0.55\tScore: 0.93\tLossActor: 0.14151739 \tLossCritic : 0.00059672(tensor([[-0.9956, -0.9779, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1244\tAverage Score: 0.54\tScore: 0.36\tLossActor: 0.14164020 \tLossCritic : 0.00059596(tensor([[-0.9992, -0.9907, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1245\tAverage Score: 0.53\tScore: 0.26\tLossActor: 0.14171338 \tLossCritic : 0.00059501(tensor([[-0.9983, -0.9998, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1246\tAverage Score: 0.54\tScore: 0.60\tLossActor: 0.14193735 \tLossCritic : 0.00059432(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1247\tAverage Score: 0.54\tScore: 0.86\tLossActor: 0.14203946 \tLossCritic : 0.00059327(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1248\tAverage Score: 0.54\tScore: 0.20\tLossActor: 0.14207461 \tLossCritic : 0.00059217(tensor([[-0.9982, -0.9999, -0.9997,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7173, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1249\tAverage Score: 0.54\tScore: 0.22\tLossActor: 0.14208734 \tLossCritic : 0.00059119(tensor([[-0.9999, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1250\tAverage Score: 0.52\tScore: 0.61\tLossActor: 0.14212029 \tLossCritic : 0.00059029(tensor([[-1.0000, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1251\tAverage Score: 0.53\tScore: 0.77\tLossActor: 0.14219765 \tLossCritic : 0.00058938(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1252\tAverage Score: 0.51\tScore: 0.00\tLossActor: 0.14233033 \tLossCritic : 0.00058840(tensor([[-0.9999, -0.9993, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1253\tAverage Score: 0.52\tScore: 0.41\tLossActor: 0.14238222 \tLossCritic : 0.00058759(tensor([[-1.0000, -1.0000, -0.9998,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1254\tAverage Score: 0.51\tScore: 0.42\tLossActor: 0.14243647 \tLossCritic : 0.00058659(tensor([[-0.9992, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1255\tAverage Score: 0.51\tScore: 0.78\tLossActor: 0.14247666 \tLossCritic : 0.00058576(tensor([[-0.9997, -1.0000, -0.9984,  0.9996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1256\tAverage Score: 0.50\tScore: 0.38\tLossActor: 0.14250694 \tLossCritic : 0.00058492(tensor([[-1.0000, -0.9997, -0.9984,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1257\tAverage Score: 0.51\tScore: 1.00\tLossActor: 0.14258459 \tLossCritic : 0.00058429(tensor([[-0.9998, -0.9964, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1258\tAverage Score: 0.51\tScore: 0.64\tLossActor: 0.14272787 \tLossCritic : 0.00058351(tensor([[-0.9984, -1.0000, -0.9999,  0.9983]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1259\tAverage Score: 0.51\tScore: 0.23\tLossActor: 0.14278606 \tLossCritic : 0.00058279(tensor([[-0.9999, -1.0000, -0.9999,  0.9992]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7174, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1260\tAverage Score: 0.51\tScore: 0.73\tLossActor: 0.14281169 \tLossCritic : 0.00058225(tensor([[-0.9996, -0.9991, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1261\tAverage Score: 0.51\tScore: 0.48\tLossActor: 0.14283015 \tLossCritic : 0.00058152(tensor([[-1.0000, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1262\tAverage Score: 0.51\tScore: 0.18\tLossActor: 0.14285305 \tLossCritic : 0.00058080(tensor([[-1.0000, -0.9995, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1263\tAverage Score: 0.52\tScore: 1.86\tLossActor: 0.14292267 \tLossCritic : 0.00058038(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1264\tAverage Score: 0.52\tScore: 0.39\tLossActor: 0.14297757 \tLossCritic : 0.00057984(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1265\tAverage Score: 0.51\tScore: 0.60\tLossActor: 0.14300495 \tLossCritic : 0.00057904(tensor([[-1.0000, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1266\tAverage Score: 0.52\tScore: 0.95\tLossActor: 0.14303422 \tLossCritic : 0.00057884(tensor([[-1.0000, -1.0000, -0.9995,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1267\tAverage Score: 0.51\tScore: 0.00\tLossActor: 0.14309894 \tLossCritic : 0.00057841(tensor([[-0.9999, -0.9999, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1268\tAverage Score: 0.51\tScore: 0.37\tLossActor: 0.14313033 \tLossCritic : 0.00057784(tensor([[-0.9998, -0.9991, -0.9998,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1269\tAverage Score: 0.52\tScore: 1.26\tLossActor: 0.14321347 \tLossCritic : 0.00057725(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1270\tAverage Score: 0.52\tScore: 0.73\tLossActor: 0.14324746 \tLossCritic : 0.00057644(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1271\tAverage Score: 0.52\tScore: 0.71\tLossActor: 0.14333567 \tLossCritic : 0.00057554(tensor([[-0.9984, -0.7212, -0.9995,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1272\tAverage Score: 0.53\tScore: 0.87\tLossActor: 0.14340244 \tLossCritic : 0.00057479(tensor([[-1.0000, -0.9990, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1273\tAverage Score: 0.53\tScore: 0.04\tLossActor: 0.14435230 \tLossCritic : 0.00057398(tensor([[-0.9956, -0.9372, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1274\tAverage Score: 0.53\tScore: 0.68\tLossActor: 0.14440390 \tLossCritic : 0.00057360(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1275\tAverage Score: 0.54\tScore: 0.73\tLossActor: 0.14455447 \tLossCritic : 0.00057305(tensor([[-1.0000, -1.0000, -0.9994,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1276\tAverage Score: 0.54\tScore: 0.74\tLossActor: 0.14461920 \tLossCritic : 0.00057263(tensor([[-0.9996, -0.9791, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1277\tAverage Score: 0.54\tScore: 0.36\tLossActor: 0.14467643 \tLossCritic : 0.00057197(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1278\tAverage Score: 0.54\tScore: 0.16\tLossActor: 0.14471853 \tLossCritic : 0.00057154(tensor([[-0.9994, -0.9967, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1279\tAverage Score: 0.54\tScore: 0.86\tLossActor: 0.14473531 \tLossCritic : 0.00057044(tensor([[-0.9922, -0.9996, -0.9994,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7169, 2.7182, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1280\tAverage Score: 0.54\tScore: 0.56\tLossActor: 0.14483334 \tLossCritic : 0.00056976(tensor([[-0.9996, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1281\tAverage Score: 0.54\tScore: 0.68\tLossActor: 0.14487588 \tLossCritic : 0.00056880(tensor([[-0.9999, -0.9943, -0.9998,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7170, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1282\tAverage Score: 0.53\tScore: 0.28\tLossActor: 0.14492266 \tLossCritic : 0.00056809(tensor([[-0.9994, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1283\tAverage Score: 0.52\tScore: 0.00\tLossActor: 0.14496617 \tLossCritic : 0.00056715(tensor([[-1.0000, -1.0000, -1.0000,  0.9993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1284\tAverage Score: 0.52\tScore: 0.32\tLossActor: 0.14505373 \tLossCritic : 0.00056614(tensor([[-0.9993, -0.9817, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1285\tAverage Score: 0.52\tScore: 0.29\tLossActor: 0.14520128 \tLossCritic : 0.00056532(tensor([[-0.9988, -0.9995, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1286\tAverage Score: 0.52\tScore: 0.42\tLossActor: 0.14522655 \tLossCritic : 0.00056434(tensor([[-1.0000, -0.9993, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1287\tAverage Score: 0.53\tScore: 1.17\tLossActor: 0.14525668 \tLossCritic : 0.00056354(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1288\tAverage Score: 0.54\tScore: 1.53\tLossActor: 0.14557335 \tLossCritic : 0.00056291(tensor([[-1.0000, -0.9921, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1289\tAverage Score: 0.55\tScore: 0.96\tLossActor: 0.14560601 \tLossCritic : 0.00056217(tensor([[-0.9999, -0.9734, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1290\tAverage Score: 0.55\tScore: 0.31\tLossActor: 0.14567704 \tLossCritic : 0.00056068(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1291\tAverage Score: 0.56\tScore: 0.88\tLossActor: 0.14579944 \tLossCritic : 0.00055978(tensor([[-0.9992, -0.9989, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1292\tAverage Score: 0.56\tScore: 0.00\tLossActor: 0.14582993 \tLossCritic : 0.00055898(tensor([[-0.9991, -0.9877, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1293\tAverage Score: 0.56\tScore: 0.70\tLossActor: 0.14589652 \tLossCritic : 0.00055805(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1294\tAverage Score: 0.57\tScore: 0.57\tLossActor: 0.14593834 \tLossCritic : 0.00055709(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1295\tAverage Score: 0.57\tScore: 0.07\tLossActor: 0.14597146 \tLossCritic : 0.00055580(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1296\tAverage Score: 0.56\tScore: 0.01\tLossActor: 0.14612296 \tLossCritic : 0.00055476(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1297\tAverage Score: 0.56\tScore: 1.14\tLossActor: 0.14617081 \tLossCritic : 0.00055361(tensor([[-1.0000, -1.0000, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1298\tAverage Score: 0.56\tScore: 0.47\tLossActor: 0.14630556 \tLossCritic : 0.00055269(tensor([[-0.9986, -0.6302, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1299\tAverage Score: 0.57\tScore: 0.80\tLossActor: 0.14632870 \tLossCritic : 0.00055167(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1300\tAverage Score: 0.57\tScore: 0.27\tLossActor: 0.14636739 \tLossCritic : 0.00055055(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1300\tAverage Score: 0.57\n",
      "Episode 1301\tAverage Score: 0.56\tScore: 0.39\tLossActor: 0.14640056 \tLossCritic : 0.00054922(tensor([[-0.9963, -0.8497, -0.9992,  0.9990]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7168, 2.7182, 2.7182, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1302\tAverage Score: 0.57\tScore: 1.34\tLossActor: 0.14655644 \tLossCritic : 0.00054768(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1303\tAverage Score: 0.57\tScore: 0.38\tLossActor: 0.14658312 \tLossCritic : 0.00054643(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1304\tAverage Score: 0.56\tScore: 0.00\tLossActor: 0.14664540 \tLossCritic : 0.00054526(tensor([[-0.9988, -0.9989, -0.9995,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1305\tAverage Score: 0.57\tScore: 0.65\tLossActor: 0.14669496 \tLossCritic : 0.00054414(tensor([[-0.9999, -0.9983, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1306\tAverage Score: 0.57\tScore: 1.40\tLossActor: 0.14674324 \tLossCritic : 0.00054328(tensor([[-0.9999, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1307\tAverage Score: 0.59\tScore: 1.46\tLossActor: 0.14680220 \tLossCritic : 0.00054224(tensor([[-1.0000, -0.9993, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1308\tAverage Score: 0.59\tScore: 0.54\tLossActor: 0.14685050 \tLossCritic : 0.00054107(tensor([[-0.9999, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1309\tAverage Score: 0.58\tScore: 0.05\tLossActor: 0.14687780 \tLossCritic : 0.00053976(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1310\tAverage Score: 0.58\tScore: 0.43\tLossActor: 0.14698912 \tLossCritic : 0.00053874(tensor([[-0.9952, -0.7698, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1311\tAverage Score: 0.59\tScore: 1.05\tLossActor: 0.14703900 \tLossCritic : 0.00053732(tensor([[-0.9983, -0.9981, -0.9998,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1312\tAverage Score: 0.58\tScore: 0.40\tLossActor: 0.14711933 \tLossCritic : 0.00053614(tensor([[-0.9998, -0.9952, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1313\tAverage Score: 0.60\tScore: 1.63\tLossActor: 0.14714788 \tLossCritic : 0.00053470(tensor([[-0.9999, -0.9999, -1.0000,  0.9993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1314\tAverage Score: 0.60\tScore: 0.28\tLossActor: 0.14717838 \tLossCritic : 0.00053333(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1315\tAverage Score: 0.60\tScore: 0.50\tLossActor: 0.14726707 \tLossCritic : 0.00053166(tensor([[-0.9998, -0.9999, -0.9751,  0.9986]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7155, 2.7182, 2.7179, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1316\tAverage Score: 0.60\tScore: 0.41\tLossActor: 0.14731918 \tLossCritic : 0.00053034(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1317\tAverage Score: 0.59\tScore: 0.35\tLossActor: 0.14735790 \tLossCritic : 0.00052907(tensor([[-1.0000, -0.9988, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1318\tAverage Score: 0.59\tScore: 0.25\tLossActor: 0.14758597 \tLossCritic : 0.00052774(tensor([[-0.9976, -0.9977, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7178, 2.7182, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1319\tAverage Score: 0.58\tScore: 0.63\tLossActor: 0.14771383 \tLossCritic : 0.00052647(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1320\tAverage Score: 0.59\tScore: 0.46\tLossActor: 0.14797921 \tLossCritic : 0.00052520(tensor([[-1.0000, -1.0000, -0.9995,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1321\tAverage Score: 0.59\tScore: 0.59\tLossActor: 0.14802106 \tLossCritic : 0.00052368(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1322\tAverage Score: 0.59\tScore: 0.10\tLossActor: 0.14892997 \tLossCritic : 0.00052234(tensor([[-1.0000, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1323\tAverage Score: 0.59\tScore: 0.56\tLossActor: 0.14899719 \tLossCritic : 0.00052107(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1324\tAverage Score: 0.61\tScore: 2.31\tLossActor: 0.14901249 \tLossCritic : 0.00051911(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1325\tAverage Score: 0.60\tScore: 0.00\tLossActor: 0.15153368 \tLossCritic : 0.00051785(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1326\tAverage Score: 0.58\tScore: 0.26\tLossActor: 0.15157145 \tLossCritic : 0.00051668(tensor([[-0.9997, -1.0000, -0.9988,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1327\tAverage Score: 0.57\tScore: 0.25\tLossActor: 0.15164231 \tLossCritic : 0.00051511(tensor([[-0.9993, -0.9965, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1328\tAverage Score: 0.57\tScore: 0.00\tLossActor: 0.15171656 \tLossCritic : 0.00051333(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1329\tAverage Score: 0.57\tScore: 0.57\tLossActor: 0.15187030 \tLossCritic : 0.00051201(tensor([[-0.9974, -0.9996, -0.9742,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7134, 2.7179, 2.7178, 2.7179]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1330\tAverage Score: 0.58\tScore: 1.00\tLossActor: 0.15197583 \tLossCritic : 0.00051049(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1331\tAverage Score: 0.58\tScore: 0.45\tLossActor: 0.15207924 \tLossCritic : 0.00050890(tensor([[-1.0000, -1.0000, -1.0000,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1332\tAverage Score: 0.58\tScore: 0.53\tLossActor: 0.15252356 \tLossCritic : 0.00050784(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1333\tAverage Score: 0.59\tScore: 0.69\tLossActor: 0.15251297 \tLossCritic : 0.00050616(tensor([[-1.0000, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1334\tAverage Score: 0.59\tScore: 0.31\tLossActor: 0.15262790 \tLossCritic : 0.00050457(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1335\tAverage Score: 0.58\tScore: 0.71\tLossActor: 0.15265708 \tLossCritic : 0.00050282(tensor([[-0.9996, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1336\tAverage Score: 0.59\tScore: 0.14\tLossActor: 0.15270627 \tLossCritic : 0.00050134(tensor([[-0.9996, -0.9961, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1337\tAverage Score: 0.59\tScore: 0.47\tLossActor: 0.15273489 \tLossCritic : 0.00049997(tensor([[-0.9990, -1.0000, -0.9997,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1338\tAverage Score: 0.58\tScore: 0.08\tLossActor: 0.15276068 \tLossCritic : 0.00049822(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1339\tAverage Score: 0.57\tScore: 0.24\tLossActor: 0.15516903 \tLossCritic : 0.00049686(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1340\tAverage Score: 0.56\tScore: 0.87\tLossActor: 0.15521282 \tLossCritic : 0.00049557(tensor([[-0.9993, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1341\tAverage Score: 0.57\tScore: 0.76\tLossActor: 0.15530366 \tLossCritic : 0.00049385(tensor([[-1.0000, -0.9998, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1342\tAverage Score: 0.57\tScore: 0.40\tLossActor: 0.15538681 \tLossCritic : 0.00049265(tensor([[-0.9983, -1.0000, -0.9990,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1343\tAverage Score: 0.57\tScore: 0.93\tLossActor: 0.15541162 \tLossCritic : 0.00049104(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1344\tAverage Score: 0.57\tScore: 0.39\tLossActor: 0.15542494 \tLossCritic : 0.00048891(tensor([[-1.0000, -0.9995, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1345\tAverage Score: 0.57\tScore: 0.49\tLossActor: 0.15555646 \tLossCritic : 0.00048697(tensor([[-0.9991, -0.9997, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1346\tAverage Score: 0.57\tScore: 1.11\tLossActor: 0.15556058 \tLossCritic : 0.00048541(tensor([[-0.9988, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1347\tAverage Score: 0.57\tScore: 0.63\tLossActor: 0.15566170 \tLossCritic : 0.00048407(tensor([[-0.9987, -0.9687, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1348\tAverage Score: 0.58\tScore: 0.98\tLossActor: 0.15575184 \tLossCritic : 0.00048307(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1349\tAverage Score: 0.58\tScore: 0.37\tLossActor: 0.15579940 \tLossCritic : 0.00048153(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1350\tAverage Score: 0.58\tScore: 0.72\tLossActor: 0.15585826 \tLossCritic : 0.00048011(tensor([[-0.9991, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7176, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1351\tAverage Score: 0.57\tScore: 0.00\tLossActor: 0.15613306 \tLossCritic : 0.00047903(tensor([[-0.9997, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1352\tAverage Score: 0.58\tScore: 0.26\tLossActor: 0.15616488 \tLossCritic : 0.00047709(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1353\tAverage Score: 0.58\tScore: 0.24\tLossActor: 0.15621373 \tLossCritic : 0.00047525(tensor([[-0.9993, -0.9996, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1354\tAverage Score: 0.57\tScore: 0.31\tLossActor: 0.15627582 \tLossCritic : 0.00047364(tensor([[-1.0000, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1355\tAverage Score: 0.57\tScore: 0.41\tLossActor: 0.15632020 \tLossCritic : 0.00047206(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1356\tAverage Score: 0.57\tScore: 0.03\tLossActor: 0.15637900 \tLossCritic : 0.00047057(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1357\tAverage Score: 0.56\tScore: 0.00\tLossActor: 0.15646583 \tLossCritic : 0.00046870(tensor([[-0.9987, -0.9995, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1358\tAverage Score: 0.55\tScore: 0.30\tLossActor: 0.15649743 \tLossCritic : 0.00046682(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1359\tAverage Score: 0.55\tScore: 0.00\tLossActor: 0.15654221 \tLossCritic : 0.00046546(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1360\tAverage Score: 0.55\tScore: 0.20\tLossActor: 0.15665552 \tLossCritic : 0.00046410(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1361\tAverage Score: 0.55\tScore: 0.61\tLossActor: 0.15673792 \tLossCritic : 0.00046311(tensor([[-0.9997, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1362\tAverage Score: 0.55\tScore: 0.00\tLossActor: 0.15681851 \tLossCritic : 0.00046219(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1363\tAverage Score: 0.53\tScore: 0.00\tLossActor: 0.15685043 \tLossCritic : 0.00046047(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1364\tAverage Score: 0.53\tScore: 0.99\tLossActor: 0.15702282 \tLossCritic : 0.00045871(tensor([[-0.9985, -0.9999, -0.9995,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1365\tAverage Score: 0.53\tScore: 0.17\tLossActor: 0.15707174 \tLossCritic : 0.00045749(tensor([[-0.9999, -0.9928, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1366\tAverage Score: 0.52\tScore: 0.22\tLossActor: 0.15712249 \tLossCritic : 0.00045618(tensor([[-0.9997, -0.9999, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1367\tAverage Score: 0.52\tScore: 0.29\tLossActor: 0.15716328 \tLossCritic : 0.00045523(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1368\tAverage Score: 0.52\tScore: 0.19\tLossActor: 0.15720665 \tLossCritic : 0.00045389(tensor([[-1.0000, -0.9993, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1369\tAverage Score: 0.52\tScore: 0.49\tLossActor: 0.15724990 \tLossCritic : 0.00045255(tensor([[-0.9995, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1370\tAverage Score: 0.52\tScore: 0.73\tLossActor: 0.15730505 \tLossCritic : 0.00045169(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1371\tAverage Score: 0.51\tScore: 0.20\tLossActor: 0.15742625 \tLossCritic : 0.00045091(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1372\tAverage Score: 0.51\tScore: 0.92\tLossActor: 0.15746833 \tLossCritic : 0.00045001(tensor([[-0.9995, -0.9976, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1373\tAverage Score: 0.51\tScore: 0.13\tLossActor: 0.15747058 \tLossCritic : 0.00044809(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1374\tAverage Score: 0.51\tScore: 0.56\tLossActor: 0.15751749 \tLossCritic : 0.00044682(tensor([[-1.0000, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1375\tAverage Score: 0.52\tScore: 1.67\tLossActor: 0.15754433 \tLossCritic : 0.00044530(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1376\tAverage Score: 0.52\tScore: 0.27\tLossActor: 0.15760489 \tLossCritic : 0.00044389(tensor([[-0.9786, -0.8886, -0.9973,  0.9993]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7172, 2.7182, 2.7182, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1377\tAverage Score: 0.51\tScore: 0.07\tLossActor: 0.15770066 \tLossCritic : 0.00044238(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1378\tAverage Score: 0.52\tScore: 0.55\tLossActor: 0.15778837 \tLossCritic : 0.00044096(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1379\tAverage Score: 0.51\tScore: 0.23\tLossActor: 0.15800267 \tLossCritic : 0.00044029(tensor([[-1.0000, -0.9996, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1380\tAverage Score: 0.52\tScore: 1.14\tLossActor: 0.15802179 \tLossCritic : 0.00043878(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1381\tAverage Score: 0.52\tScore: 0.67\tLossActor: 0.15805723 \tLossCritic : 0.00043755(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1382\tAverage Score: 0.52\tScore: 0.68\tLossActor: 0.15894045 \tLossCritic : 0.00043668(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1383\tAverage Score: 0.53\tScore: 0.94\tLossActor: 0.15900142 \tLossCritic : 0.00043585(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1384\tAverage Score: 0.53\tScore: 0.45\tLossActor: 0.15902518 \tLossCritic : 0.00043426(tensor([[-1.0000, -1.0000, -0.9987,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1385\tAverage Score: 0.54\tScore: 1.70\tLossActor: 0.15909703 \tLossCritic : 0.00043360(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1386\tAverage Score: 0.54\tScore: 0.11\tLossActor: 0.15919974 \tLossCritic : 0.00043230(tensor([[-0.9999, -0.9997, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1387\tAverage Score: 0.53\tScore: 0.32\tLossActor: 0.15925252 \tLossCritic : 0.00043147(tensor([[-0.9996, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1388\tAverage Score: 0.53\tScore: 1.57\tLossActor: 0.15932101 \tLossCritic : 0.00043071(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1389\tAverage Score: 0.53\tScore: 0.87\tLossActor: 0.15941890 \tLossCritic : 0.00043023(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1390\tAverage Score: 0.53\tScore: 0.08\tLossActor: 0.15958340 \tLossCritic : 0.00042956(tensor([[-0.9997, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1391\tAverage Score: 0.53\tScore: 1.33\tLossActor: 0.15962113 \tLossCritic : 0.00042932(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1392\tAverage Score: 0.54\tScore: 0.37\tLossActor: 0.15964946 \tLossCritic : 0.00042759(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1393\tAverage Score: 0.53\tScore: 0.11\tLossActor: 0.15992032 \tLossCritic : 0.00042600(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1394\tAverage Score: 0.53\tScore: 0.54\tLossActor: 0.15995443 \tLossCritic : 0.00042470(tensor([[-0.9995, -0.9999, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1395\tAverage Score: 0.54\tScore: 0.47\tLossActor: 0.15996954 \tLossCritic : 0.00042343(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1396\tAverage Score: 0.54\tScore: 0.00\tLossActor: 0.16002057 \tLossCritic : 0.00042209(tensor([[-0.9998, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1397\tAverage Score: 0.52\tScore: 0.00\tLossActor: 0.16002467 \tLossCritic : 0.00042040(tensor([[-1.0000, -0.9999, -0.9996,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1398\tAverage Score: 0.53\tScore: 0.61\tLossActor: 0.16006365 \tLossCritic : 0.00041949(tensor([[-0.9995, -0.9993, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1399\tAverage Score: 0.52\tScore: 0.33\tLossActor: 0.16006622 \tLossCritic : 0.00041828(tensor([[-1.0000, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1400\tAverage Score: 0.53\tScore: 0.84\tLossActor: 0.16011620 \tLossCritic : 0.00041760(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1400\tAverage Score: 0.53\n",
      "Episode 1401\tAverage Score: 0.53\tScore: 0.25\tLossActor: 0.16015758 \tLossCritic : 0.00041717(tensor([[-1.0000, -0.9993, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1402\tAverage Score: 0.51\tScore: 0.00\tLossActor: 0.16018182 \tLossCritic : 0.00041659(tensor([[-0.9988, -0.9990, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1403\tAverage Score: 0.51\tScore: 0.56\tLossActor: 0.16020457 \tLossCritic : 0.00041594(tensor([[-1.0000, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1404\tAverage Score: 0.52\tScore: 0.98\tLossActor: 0.16027398 \tLossCritic : 0.00041549(tensor([[-0.9995, -1.0000, -0.9991,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1405\tAverage Score: 0.52\tScore: 0.46\tLossActor: 0.16032211 \tLossCritic : 0.00041496(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1406\tAverage Score: 0.51\tScore: 0.34\tLossActor: 0.16041228 \tLossCritic : 0.00041442(tensor([[-0.9984, -0.9929, -0.9981,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1407\tAverage Score: 0.50\tScore: 0.79\tLossActor: 0.16050343 \tLossCritic : 0.00041398(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1408\tAverage Score: 0.50\tScore: 0.00\tLossActor: 0.16055118 \tLossCritic : 0.00041217(tensor([[-0.9990, -1.0000, -0.9990,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1409\tAverage Score: 0.50\tScore: 0.18\tLossActor: 0.16058832 \tLossCritic : 0.00041107(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1410\tAverage Score: 0.52\tScore: 2.23\tLossActor: 0.16111523 \tLossCritic : 0.00041010(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1411\tAverage Score: 0.51\tScore: 0.21\tLossActor: 0.16118963 \tLossCritic : 0.00040943(tensor([[-0.9991, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1412\tAverage Score: 0.51\tScore: 0.84\tLossActor: 0.16133898 \tLossCritic : 0.00040908(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1413\tAverage Score: 0.50\tScore: 0.00\tLossActor: 0.16136017 \tLossCritic : 0.00040784(tensor([[-0.9997, -0.9967, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1414\tAverage Score: 0.50\tScore: 0.95\tLossActor: 0.16139428 \tLossCritic : 0.00040691(tensor([[-0.9998, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1415\tAverage Score: 0.51\tScore: 0.65\tLossActor: 0.16143472 \tLossCritic : 0.00040657(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1416\tAverage Score: 0.50\tScore: 0.07\tLossActor: 0.16147000 \tLossCritic : 0.00040591(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1417\tAverage Score: 0.51\tScore: 0.75\tLossActor: 0.16147506 \tLossCritic : 0.00040447(tensor([[-0.9999, -0.9998, -0.9983,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7168, 2.7181, 2.7180, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1418\tAverage Score: 0.51\tScore: 0.35\tLossActor: 0.16153274 \tLossCritic : 0.00040407(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1419\tAverage Score: 0.51\tScore: 0.55\tLossActor: 0.16157471 \tLossCritic : 0.00040354(tensor([[-0.9997, -0.9972, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1420\tAverage Score: 0.51\tScore: 0.31\tLossActor: 0.16162015 \tLossCritic : 0.00040227(tensor([[-0.9998, -0.9996, -1.0000,  0.9996]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1421\tAverage Score: 0.51\tScore: 0.85\tLossActor: 0.16167381 \tLossCritic : 0.00040163(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1422\tAverage Score: 0.51\tScore: 0.00\tLossActor: 0.16190135 \tLossCritic : 0.00040132(tensor([[-0.9999, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1423\tAverage Score: 0.51\tScore: 0.85\tLossActor: 0.16193296 \tLossCritic : 0.00040039(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1424\tAverage Score: 0.49\tScore: 0.18\tLossActor: 0.16215111 \tLossCritic : 0.00039977(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1425\tAverage Score: 0.49\tScore: 0.00\tLossActor: 0.16223718 \tLossCritic : 0.00039894(tensor([[-0.9997, -1.0000, -0.9997,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1426\tAverage Score: 0.50\tScore: 1.05\tLossActor: 0.16227894 \tLossCritic : 0.00039869(tensor([[-0.9999, -0.9998, -0.9996,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1427\tAverage Score: 0.50\tScore: 0.22\tLossActor: 0.16266823 \tLossCritic : 0.00039833(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1428\tAverage Score: 0.50\tScore: 0.65\tLossActor: 0.16271864 \tLossCritic : 0.00039808(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1429\tAverage Score: 0.51\tScore: 1.63\tLossActor: 0.16276728 \tLossCritic : 0.00039766(tensor([[-1.0000, -1.0000, -0.9997,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1430\tAverage Score: 0.50\tScore: 0.00\tLossActor: 0.16283904 \tLossCritic : 0.00039723(tensor([[-0.9953, -0.9970, -0.9998,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1431\tAverage Score: 0.50\tScore: 0.00\tLossActor: 0.16286612 \tLossCritic : 0.00039688(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1432\tAverage Score: 0.50\tScore: 0.59\tLossActor: 0.16289650 \tLossCritic : 0.00039652(tensor([[-0.9999, -0.9991, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1433\tAverage Score: 0.50\tScore: 0.42\tLossActor: 0.16292939 \tLossCritic : 0.00039596(tensor([[-0.9992, -0.9996, -0.9993,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7171, 2.7182, 2.7181, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1434\tAverage Score: 0.50\tScore: 0.59\tLossActor: 0.16296612 \tLossCritic : 0.00039576(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1435\tAverage Score: 0.49\tScore: 0.00\tLossActor: 0.16301307 \tLossCritic : 0.00039529(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1436\tAverage Score: 0.49\tScore: 0.31\tLossActor: 0.16314773 \tLossCritic : 0.00039482(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1437\tAverage Score: 0.49\tScore: 0.40\tLossActor: 0.16316922 \tLossCritic : 0.00039451(tensor([[-0.9994, -0.9918, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1438\tAverage Score: 0.50\tScore: 0.86\tLossActor: 0.16320643 \tLossCritic : 0.00039396(tensor([[-0.9998, -1.0000, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1439\tAverage Score: 0.51\tScore: 0.64\tLossActor: 0.16355933 \tLossCritic : 0.00039371(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1440\tAverage Score: 0.50\tScore: 0.75\tLossActor: 0.16358633 \tLossCritic : 0.00039344(tensor([[-0.9999, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1441\tAverage Score: 0.50\tScore: 0.00\tLossActor: 0.16358054 \tLossCritic : 0.00039203(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1442\tAverage Score: 0.50\tScore: 0.34\tLossActor: 0.16359589 \tLossCritic : 0.00039116(tensor([[-1.0000, -0.9998, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1443\tAverage Score: 0.49\tScore: 0.69\tLossActor: 0.16361007 \tLossCritic : 0.00039031(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1444\tAverage Score: 0.50\tScore: 0.71\tLossActor: 0.16362855 \tLossCritic : 0.00038996(tensor([[-0.9992, -0.9998, -0.9998,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7183, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1445\tAverage Score: 0.50\tScore: 1.27\tLossActor: 0.16365570 \tLossCritic : 0.00038967(tensor([[-0.9992, -0.9380, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1446\tAverage Score: 0.50\tScore: 0.69\tLossActor: 0.16371144 \tLossCritic : 0.00038873(tensor([[-0.9999, -0.9999, -0.9999,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1447\tAverage Score: 0.51\tScore: 1.27\tLossActor: 0.16373448 \tLossCritic : 0.00038756(tensor([[-0.9996, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1448\tAverage Score: 0.51\tScore: 1.09\tLossActor: 0.16428824 \tLossCritic : 0.00038617(tensor([[-0.9997, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1449\tAverage Score: 0.52\tScore: 1.18\tLossActor: 0.16452695 \tLossCritic : 0.00038590(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1450\tAverage Score: 0.52\tScore: 0.81\tLossActor: 0.16458854 \tLossCritic : 0.00038582(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1451\tAverage Score: 0.52\tScore: 0.37\tLossActor: 0.16463636 \tLossCritic : 0.00038519(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1452\tAverage Score: 0.53\tScore: 1.08\tLossActor: 0.16467607 \tLossCritic : 0.00038433(tensor([[-0.9997, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1453\tAverage Score: 0.53\tScore: 0.35\tLossActor: 0.16471423 \tLossCritic : 0.00038384(tensor([[-0.9998, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1454\tAverage Score: 0.53\tScore: 0.40\tLossActor: 0.16477336 \tLossCritic : 0.00038364(tensor([[-0.9983, -0.9999, -0.9996,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7177, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1455\tAverage Score: 0.53\tScore: 0.24\tLossActor: 0.16486268 \tLossCritic : 0.00038291(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1456\tAverage Score: 0.54\tScore: 1.22\tLossActor: 0.16499349 \tLossCritic : 0.00038268(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1457\tAverage Score: 0.55\tScore: 0.98\tLossActor: 0.16528462 \tLossCritic : 0.00038247(tensor([[-0.9997, -0.9999, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1458\tAverage Score: 0.56\tScore: 1.37\tLossActor: 0.16538224 \tLossCritic : 0.00038214(tensor([[-0.9999, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1459\tAverage Score: 0.58\tScore: 1.84\tLossActor: 0.16542944 \tLossCritic : 0.00038198(tensor([[-0.9994, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1460\tAverage Score: 0.58\tScore: 0.26\tLossActor: 0.16564856 \tLossCritic : 0.00038171(tensor([[-0.9994, -0.9999, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1461\tAverage Score: 0.58\tScore: 0.41\tLossActor: 0.16584153 \tLossCritic : 0.00038063(tensor([[-0.9980, -0.9991, -0.9997,  0.9995]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7162, 2.7178, 2.7180, 2.7180]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1462\tAverage Score: 0.58\tScore: 0.25\tLossActor: 0.16588588 \tLossCritic : 0.00038006(tensor([[-0.9999, -1.0000, -0.9995,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1463\tAverage Score: 0.59\tScore: 0.42\tLossActor: 0.16635381 \tLossCritic : 0.00037952(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1464\tAverage Score: 0.58\tScore: 0.92\tLossActor: 0.16649877 \tLossCritic : 0.00037895(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1465\tAverage Score: 0.58\tScore: 0.00\tLossActor: 0.16660418 \tLossCritic : 0.00037829(tensor([[-0.9996, -0.9992, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1466\tAverage Score: 0.59\tScore: 0.53\tLossActor: 0.16669986 \tLossCritic : 0.00037774(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1467\tAverage Score: 0.59\tScore: 0.60\tLossActor: 0.16674468 \tLossCritic : 0.00037744(tensor([[-0.9996, -0.9981, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1468\tAverage Score: 0.59\tScore: 0.26\tLossActor: 0.16736850 \tLossCritic : 0.00037681(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1469\tAverage Score: 0.59\tScore: 0.11\tLossActor: 0.16856636 \tLossCritic : 0.00037648(tensor([[-0.9996, -0.9986, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1470\tAverage Score: 0.59\tScore: 1.53\tLossActor: 0.16867806 \tLossCritic : 0.00037568(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1471\tAverage Score: 0.60\tScore: 0.76\tLossActor: 0.16880493 \tLossCritic : 0.00037541(tensor([[-0.9993, -0.9999, -0.9999,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1472\tAverage Score: 0.60\tScore: 0.64\tLossActor: 0.16883570 \tLossCritic : 0.00037497(tensor([[-0.9941, -0.9705, -0.9993,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1473\tAverage Score: 0.60\tScore: 0.87\tLossActor: 0.16899876 \tLossCritic : 0.00037462(tensor([[-0.9971, -0.9996, -0.9994,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7182, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1474\tAverage Score: 0.60\tScore: 0.33\tLossActor: 0.16905357 \tLossCritic : 0.00037422(tensor([[-0.9997, -1.0000, -1.0000,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1475\tAverage Score: 0.60\tScore: 1.42\tLossActor: 0.16909470 \tLossCritic : 0.00037310(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1476\tAverage Score: 0.60\tScore: 0.16\tLossActor: 0.17151073 \tLossCritic : 0.00037241(tensor([[-0.9993, -0.9921, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1477\tAverage Score: 0.60\tScore: 0.17\tLossActor: 0.17157294 \tLossCritic : 0.00037219(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1478\tAverage Score: 0.60\tScore: 0.38\tLossActor: 0.17159329 \tLossCritic : 0.00037195(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1479\tAverage Score: 0.60\tScore: 0.51\tLossActor: 0.17161477 \tLossCritic : 0.00037168(tensor([[-0.9997, -0.9998, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1480\tAverage Score: 0.60\tScore: 0.72\tLossActor: 0.17164700 \tLossCritic : 0.00037077(tensor([[-0.9997, -1.0000, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7181, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1481\tAverage Score: 0.60\tScore: 1.15\tLossActor: 0.17165495 \tLossCritic : 0.00037013(tensor([[-1.0000, -1.0000, -1.0000,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1482\tAverage Score: 0.59\tScore: 0.00\tLossActor: 0.17191999 \tLossCritic : 0.00036917(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1483\tAverage Score: 0.59\tScore: 0.65\tLossActor: 0.17197138 \tLossCritic : 0.00036839(tensor([[-0.9998, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1484\tAverage Score: 0.59\tScore: 0.40\tLossActor: 0.17203611 \tLossCritic : 0.00036758(tensor([[-0.9985, -0.9999, -0.9993,  0.9998]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7174, 2.7181, 2.7181, 2.7181]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1485\tAverage Score: 0.58\tScore: 0.17\tLossActor: 0.17206912 \tLossCritic : 0.00036705(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1486\tAverage Score: 0.57\tScore: 0.08\tLossActor: 0.17222936 \tLossCritic : 0.00036664(tensor([[-0.9999, -1.0000, -0.9998,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1487\tAverage Score: 0.58\tScore: 0.60\tLossActor: 0.17231661 \tLossCritic : 0.00036634(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1488\tAverage Score: 0.56\tScore: 0.28\tLossActor: 0.17232725 \tLossCritic : 0.00036586(tensor([[-0.9997, -0.9997, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1489\tAverage Score: 0.56\tScore: 0.31\tLossActor: 0.17235692 \tLossCritic : 0.00036564(tensor([[-0.9711, -0.9551, -0.9964,  0.9965]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7063, 2.7134, 2.7156, 2.7138]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1490\tAverage Score: 0.56\tScore: 0.00\tLossActor: 0.17244294 \tLossCritic : 0.00036414(tensor([[-0.9997, -0.9993, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1491\tAverage Score: 0.55\tScore: 0.62\tLossActor: 0.17245562 \tLossCritic : 0.00036174(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1492\tAverage Score: 0.55\tScore: 0.43\tLossActor: 0.17245223 \tLossCritic : 0.00035982(tensor([[-1.0000, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1493\tAverage Score: 0.56\tScore: 0.54\tLossActor: 0.17245854 \tLossCritic : 0.00035789(tensor([[-0.9995, -0.9961, -1.0000,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1494\tAverage Score: 0.55\tScore: 0.11\tLossActor: 0.17250128 \tLossCritic : 0.00035723(tensor([[-0.9996, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7183, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1495\tAverage Score: 0.55\tScore: 0.60\tLossActor: 0.17249912 \tLossCritic : 0.00035555(tensor([[-0.9991, -0.9999, -0.9996,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1496\tAverage Score: 0.56\tScore: 0.58\tLossActor: 0.17257458 \tLossCritic : 0.00035472(tensor([[-0.9997, -0.9988, -0.9999,  0.9999]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1497\tAverage Score: 0.56\tScore: 0.47\tLossActor: 0.17258513 \tLossCritic : 0.00035397(tensor([[-0.9996, -0.9997, -0.9990,  0.9994]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7179, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1498\tAverage Score: 0.56\tScore: 0.23\tLossActor: 0.17263457 \tLossCritic : 0.00035332(tensor([[-0.9991, -0.9992, -0.9999,  0.9997]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7180, 2.7182, 2.7182, 2.7182]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n",
      "Episode 1499\tAverage Score: 0.58\tScore: 1.91\tLossActor: 0.17264307 \tLossCritic : 0.00035287(tensor([[-0.9999, -1.0000, -1.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>), tensor([[2.7182, 2.7183, 2.7183, 2.7183]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ppo(n_episodes=1500, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "     \n",
    "    max_score = -np.Inf\n",
    "    first=False\n",
    "    for i_episode in range(1, n_episodes):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        \n",
    "        agent.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            actions, distributions,log_probs = agent.act(states)#choose an action \n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards_ = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done\n",
    "            agent.step(states, actions, rewards_, next_states,\n",
    "                       dones, distributions, log_probs)#collect events\n",
    "            \n",
    "            states = next_states\n",
    "            score += np.mean(rewards_)\n",
    "            \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        \n",
    "        agent.learn(next_states, GAMMA)\n",
    "        \n",
    "        mean_score_paral = score.mean()\n",
    "        scores_deque.append(mean_score_paral)\n",
    "        scores.append(mean_score_paral)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}\\tLossActor: {:.8f} \\tLossCritic : {:.8f}'.format(i_episode,\n",
    "                                                                                                                   np.mean(scores_deque),\n",
    "                                                                                                                   mean_score_paral,\n",
    "                                                                                                                   np.mean(agent.actor_loss_history),\n",
    "                                                                                                                   np.mean(agent.critic_loss_history)), end=\"\")\n",
    "        \n",
    "        print(agent.actor_local.get_params(torch.FloatTensor(states).to(device)))\n",
    "        agent.memory.clear_memory()\n",
    "        if i_episode % 100 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_ppo_20agent.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_ppo_20agent.pth')\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque)>30:\n",
    "            if first==True:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}, '.format(\n",
    "                    i_episode-100, \n",
    "                    np.mean(scores_deque)))\n",
    "                torch.save(agent.actor_local.state_dict(), 'model_actor_ppo_20agent.pth')\n",
    "                torch.save(agent.critic_local.state_dict(), 'model_critic_ppo_20agent.pth')\n",
    "                first=True\n",
    "                #break\n",
    "    return scores\n",
    "\n",
    "scores = ppo()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking the variance of the actor distribution helps to adjust hyperparameters (especially the entropy coeficient loss). We want to penalize a low variance but having maximum of variance can stop the learning. <br>\n",
    "So I decided to decrease my hyperparameter \"entropy_coef\" from 0.01 to 0.001<br>\n",
    "I also decided to reduce the LAMBDA hyperparameter to reduce the Variance from Generalized Advantage Estimation (GAE) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.axhline(y=30, color='r', linestyle='--')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
